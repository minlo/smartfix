/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:data_train: (1488, 106), data_test: (1493, 106)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 1
INFO:__main__:Tuning models, 20180106: 
INFO:__main__:x_train: (1458, 105), y_train: (1458,), x_val: (30, 105), y_val: (30,)
INFO:__main__:




model: random_forest

Fitting 3 folds for each of 4 candidates, totalling 12 fits
INFO:feature_selecting.feature_select:There are in total 1133 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: invalid value encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:feature_selecting.feature_select:
In total, it takes 74.01 seconds to run regression for 1133 columns
INFO:feature_selecting.feature_select:There are in total 1111 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:feature_selecting.feature_select:
In total, it takes 99.74 seconds to run regression for 1144 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:feature_selecting.feature_select:
In total, it takes 102.67 seconds to run regression for 1144 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:feature_selecting.feature_select:
In total, it takes 104.65 seconds to run regression for 1144 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:feature_selecting.feature_select:
In total, it takes 113.50 seconds to run regression for 1144 columns
INFO:feature_selecting.feature_select:There are in total 1133 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: invalid value encountered in double_scalars
  return self.ess/self.df_model
INFO:feature_selecting.feature_select:
In total, it takes 69.91 seconds to run regression for 1111 columns
INFO:feature_selecting.feature_select:There are in total 1133 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:feature_selecting.feature_select:
In total, it takes 73.43 seconds to run regression for 1133 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:
In total, it takes 77.78 seconds to run regression for 1133 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:feature_selecting.feature_select:
In total, it takes 251.60 seconds to run regression for 1144 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:feature_selecting.feature_select:
In total, it takes 261.04 seconds to run regression for 1144 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:feature_selecting.feature_select:
In total, it takes 262.51 seconds to run regression for 1144 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:feature_selecting.feature_select:
In total, it takes 260.03 seconds to run regression for 1144 columns
INFO:feature_selecting.feature_select:There are in total 1122 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:
In total, it takes 68.01 seconds to run regression for 1144 columns
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:feature_selecting.feature_select:
In total, it takes 21.37 seconds to run regression for 1122 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
INFO:feature_selecting.feature_select:
In total, it takes 105.04 seconds to run regression for 1144 columns
[CV] engineer__lag=10, imputer__method=cubic, model__n_estimators=1000, selector__k=10, selector__select_method=hard 
before imputation (366, 105) (0, 105)
[CV] engineer__lag=10, imputer__method=slinear, model__n_estimators=1000, selector__k=10, selector__select_method=hard 
before imputation (366, 105) (0, 105)

Joblib's exception reporting continues...

[CV] engineer__lag=10, imputer__method=zero, model__n_estimators=1000, selector__k=10, selector__select_method=hard 
before imputation (366, 105) (0, 105)
[CV] engineer__lag=10, imputer__method=zero, model__n_estimators=1000, selector__k=10, selector__select_method=hard 
before imputation (730, 105) (0, 105)
Before extracting,  (730, 105) (730, 105)
before imputation (364, 105) (0, 105)
[CV] engineer__lag=10, imputer__method=cubic, model__n_estimators=1000, selector__k=10, selector__select_method=hard 
before imputation (730, 105) (0, 105)
Before extracting,  (730, 105) (730, 105)
before imputation (364, 105) (0, 105)
[CV] engineer__lag=10, imputer__method=slinear, model__n_estimators=1000, selector__k=10, selector__select_method=hard 
before imputation (730, 105) (0, 105)
Before extracting,  (730, 105) (730, 105)
before imputation (364, 105) (0, 105)
[CV] engineer__lag=10, imputer__method=zero, model__n_estimators=1000, selector__k=10, selector__select_method=hard 
before imputation (1094, 105) (0, 105)
Before extracting,  (1094, 105) (1094, 105)
before imputation (364, 105) (0, 105)
[CV] engineer__lag=10, imputer__method=cubic, model__n_estimators=1000, selector__k=10, selector__select_method=hard 
before imputation (1094, 105) (0, 105)
Before extracting,  (1094, 105) (1094, 105)
before imputation (364, 105) (0, 105)
[CV] engineer__lag=10, imputer__method=slinear, model__n_estimators=1000, selector__k=10, selector__select_method=hard 
before imputation (1094, 105) (0, 105)
Before extracting,  (1094, 105) (1094, 105)
before imputation (364, 105) (0, 105)
[CV] engineer__lag=10, imputer__method=directly, model__n_estimators=1000, selector__k=10, selector__select_method=hard 
before imputation (1094, 105) (0, 105)
Before extracting,  (1094, 105) (1094, 105)
before imputation (364, 105) (0, 105)
Before extracting,  (364, 103) (364, 103)
before imputation (1094, 105) (0, 105)
Before extracting,  (1094, 105) (1094, 105)
[CV]  engineer__lag=10, imputer__method=directly, model__n_estimators=1000, selector__k=10, selector__select_method=hard, score=-13.171066, total= 5.0min
[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:  6.8min remaining: 20.5min
INFO:__main__:JoblibIndexError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in <module>()
    490         search_regression_ml(
    491             data_train=data_train,
    492             save_k_best=args.save_k_best,
    493             look_ahead_day=args.look_forward_days,
    494             split_date=split_date,
--> 495             validation_period_length=args.validation_period_length
    496         )
    497 
    498     # set the model results path
    499     results_path = os.path.join("./../results/model_history/",

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in search_regression_ml(data_train=                 x1          x2         x3      ...0  3.3518     3.4240  

[1488 rows x 106 columns], save_k_best=1, look_ahead_day=1, split_date=datetime.date(2017, 12, 18), validation_period_length=30)
    351                 reducer=PCA(n_components=10),  # temporarily not in use
    352                 model=model_dict[model_name],
    353                 x_train=x_train,
    354                 y_train=y_train,
    355                 pipeline_mode=model_pipeline_mode_dict[model_name],
--> 356                 pipeline_param_grid=pipeline_param_grid
        pipeline_param_grid = {'engineer__lag': [10], 'imputer__method': ['directly', 'zero', 'slinear', 'cubic'], 'model__n_estimators': [1000], 'selector__k': [10], 'selector__select_method': ['hard']}
    357             )
    358             model_id = str(uuid.uuid4())
    359             y_test_predict = test(
    360                 x_test=x_val,

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in train(imputer=ImputationMethod(method='directly'), engineer=FeatureExtract(changerate=True, diff=True, ind=[...
        look_forward_days=1, ma=[1, 2, 3, 4, 5]), selector=FeatureSelector(alpha=0.05, date_column='date', ...d', select_top_k=True,
        target_column='y'), scaler=MinMaxScaler(copy=True, feature_range=(0, 1)), reducer=PCA(copy=True, iterated_power='auto', n_componen...None,
  svd_solver='auto', tol=0.0, whiten=False), model=RandomForestRegressor(bootstrap=True, criterion=...  random_state=1234, verbose=0, warm_start=False), x_train=                 x1          x2         x3      ...444  1.24322  2.9142  

[1458 rows x 105 columns], y_train=array([ 4.4785,  4.3063,  4.519 , ...,  3.0997,  2.9142,  2.9302]), pipeline_mode='grid', pipeline_param_grid={'engineer__lag': [10], 'imputer__method': ['directly', 'zero', 'slinear', 'cubic'], 'model__n_estimators': [1000], 'selector__k': [10], 'selector__select_method': ['hard']})
    115     pipeline_grid_search = generate_grid_search(
    116         search_pipeline=pipeline,
    117         pipeline_mode=pipeline_mode,
    118         param_grid=pipeline_param_grid
    119     )
--> 120     pipeline_grid_search.fit(x_train, y_train)
        pipeline_grid_search.fit = <bound method GridSearchCV.fit of GridSearchCV(c...    scoring='neg_mean_squared_error', verbose=3)>
        x_train =                  x1          x2         x3      ...444  1.24322  2.9142  

[1458 rows x 105 columns]
        y_train = array([ 4.4785,  4.3063,  4.519 , ...,  3.0997,  2.9142,  2.9302])
    121     logger.info("It takes {:.2f} seconds to train this model.".format(time.time() - time_init))
    122     if pipeline_mode != "single":
    123         pipeline_grid_search = pipeline_grid_search.best_estimator_
    124 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=TimeSeriesSplit(n_splits=3), err...     scoring='neg_mean_squared_error', verbose=3), X=                 x1          x2         x3      ...444  1.24322  2.9142  

[1458 rows x 105 columns], y=array([ 4.4785,  4.3063,  4.519 , ...,  3.0997,  2.9142,  2.9302]), groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...    scoring='neg_mean_squared_error', verbose=3)>
        X =                  x1          x2         x3      ...444  1.24322  2.9142  

[1458 rows x 105 columns]
        y = array([ 4.4785,  4.3063,  4.519 , ...,  3.0997,  2.9142,  2.9302])
        groups = None
        self.param_grid = {'engineer__lag': [10], 'imputer__method': ['directly', 'zero', 'slinear', 'cubic'], 'model__n_estimators': [1000], 'selector__k': [10], 'selector__select_method': ['hard']}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=TimeSeriesSplit(n_splits=3), err...     scoring='neg_mean_squared_error', verbose=3), X=                 x1          x2         x3      ...444  1.24322  2.9142  

[1458 rows x 105 columns], y=array([ 4.4785,  4.3063,  4.519 , ...,  3.0997,  2.9142,  2.9302]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
IndexError                                         Sat Jan  6 01:29:15 2018
PID: 122346                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('imputer', ImputationMethod(met...andom_state=1234, verbose=0, warm_start=False))]),                  x1          x2         x3      ...444  1.24322  2.9142  

[1458 rows x 105 columns], array([ 4.4785,  4.3063,  4.519 , ...,  3.0997,  2.9142,  2.9302]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 358, 359, 360, 361, 362, 363,
       364, 365]), array([366, 367, 368, 369, 370, 371, 372, 373, 3...20, 721, 722, 723, 724, 725, 726, 727, 728, 729]), 3, {'engineer__lag': 10, 'imputer__method': 'zero', 'model__n_estimators': 1000, 'selector__k': 10, 'selector__select_method': 'hard'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('imputer', ImputationMethod(met...andom_state=1234, verbose=0, warm_start=False))]),                  x1          x2         x3      ...444  1.24322  2.9142  

[1458 rows x 105 columns], array([ 4.4785,  4.3063,  4.519 , ...,  3.0997,  2.9142,  2.9302]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 358, 359, 360, 361, 362, 363,
       364, 365]), array([366, 367, 368, 369, 370, 371, 372, 373, 3...20, 721, 722, 723, 724, 725, 726, 727, 728, 729]), 3, {'engineer__lag': 10, 'imputer__method': 'zero', 'model__n_estimators': 1000, 'selector__k': 10, 'selector__select_method': 'hard'})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('imputer', ImputationMethod(met...andom_state=1234, verbose=0, warm_start=False))]), X=                 x1          x2         x3      ...444  1.24322  2.9142  

[1458 rows x 105 columns], y=array([ 4.4785,  4.3063,  4.519 , ...,  3.0997,  2.9142,  2.9302]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 358, 359, 360, 361, 362, 363,
       364, 365]), test=array([366, 367, 368, 369, 370, 371, 372, 373, 3...20, 721, 722, 723, 724, 725, 726, 727, 728, 729]), verbose=3, parameters={'engineer__lag': 10, 'imputer__method': 'zero', 'model__n_estimators': 1000, 'selector__k': 10, 'selector__select_method': 'hard'}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...ndom_state=1234, verbose=0, warm_start=False))])>
        X_train =                  x1         x2         x3       ...001  0.19300   9.2485  

[366 rows x 105 columns]
        y_train = array([  4.4785,   4.3063,   4.519 ,   4.0835,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('imputer', ImputationMethod(met...andom_state=1234, verbose=0, warm_start=False))]), X=                 x1         x2         x3       ...001  0.19300   9.2485  

[366 rows x 105 columns], y=array([  4.4785,   4.3063,   4.519 ,   4.0835,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326]), **fit_params={})
    263         Returns
    264         -------
    265         self : Pipeline
    266             This estimator
    267         """
--> 268         Xt, fit_params = self._fit(X, y, **fit_params)
        Xt = undefined
        fit_params = {}
        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(...ndom_state=1234, verbose=0, warm_start=False))])>
        X =                  x1         x2         x3       ...001  0.19300   9.2485  

[366 rows x 105 columns]
        y = array([  4.4785,   4.3063,   4.519 ,   4.0835,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326])
    269         if self._final_estimator is not None:
    270             self._final_estimator.fit(Xt, y, **fit_params)
    271         return self
    272 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(steps=[('imputer', ImputationMethod(met...andom_state=1234, verbose=0, warm_start=False))]), X=                 x1         x2         x3       ...001  0.19300   9.2485  

[366 rows x 105 columns], y=array([  4.4785,   4.3063,   4.519 ,   4.0835,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326]), **fit_params={})
    229         Xt = X
    230         for name, transform in self.steps[:-1]:
    231             if transform is None:
    232                 pass
    233             elif hasattr(transform, "fit_transform"):
--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])
        Xt =                  x1         x2         x3       ...001  0.19300   9.2485  

[366 rows x 105 columns]
        transform.fit_transform = <bound method TransformerMixin.fit_transform of ImputationMethod(method='zero')>
        y = array([  4.4785,   4.3063,   4.519 ,   4.0835,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326])
        fit_params_steps = {'engineer': {}, 'imputer': {}, 'model': {}, 'reducer': {}, 'scaler': {}, 'selector': {}}
        name = 'imputer'
    235             else:
    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \
    237                               .transform(Xt)
    238         if self._final_estimator is None:

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py in fit_transform(self=ImputationMethod(method='zero'), X=                 x1         x2         x3       ...001  0.19300   9.2485  

[366 rows x 105 columns], y=array([  4.4785,   4.3063,   4.519 ,   4.0835,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326]), **fit_params={})
    492         if y is None:
    493             # fit method of arity 1 (unsupervised transformation)
    494             return self.fit(X, **fit_params).transform(X)
    495         else:
    496             # fit method of arity 2 (supervised transformation)
--> 497             return self.fit(X, y, **fit_params).transform(X)
        self.fit = <bound method ImputationMethod.fit of ImputationMethod(method='zero')>
        X =                  x1         x2         x3       ...001  0.19300   9.2485  

[366 rows x 105 columns]
        y = array([  4.4785,   4.3063,   4.519 ,   4.0835,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326])
        fit_params.transform = undefined
    498 
    499 
    500 class DensityMixin(object):
    501     """Mixin class for all density estimators in scikit-learn."""

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/data_processing/imputation.py in transform(self=ImputationMethod(method='zero'), X=                 x1         x2         x3       ...001  0.19300   9.2485  

[366 rows x 105 columns], y=None)
    109         if self.method == 'directly':
    110             # return self.direct_impute(X), y
    111             X = self.direct_impute(X)
    112         else:
    113             # return self.diffmethod_imputed(X), y
--> 114             X = self.method_imputed(X)
        X =                  x1         x2         x3       ...001  0.19300   9.2485  

[366 rows x 105 columns]
        self.method_imputed = <bound method ImputationMethod.method_imputed of ImputationMethod(method='zero')>
    115         X = X.dropna(axis=1, how="any")      
    116         # print("After imputation", X.shape, X.dropna().shape)
    117         # print("After imputation, X: {}".format(X[X.isnull()].shape))
    118         # print(X[X.isnull()].reset_index().loc[:5])

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/data_processing/imputation.py in method_imputed(self=ImputationMethod(method='zero'), data=                 x1         x2         x3       ...001  0.19300   9.2485  

[366 rows x 105 columns])
     78                     data_filled_position.append(j)
     79 
     80             x = data_filled_position
     81             y = data_filled_value
     82             # f=interpolate.CubicSpline(x,y)
---> 83             xnew = np.linspace(x[0], x[-1], x[-1] - x[0] + 1)
        xnew = array([ 175.,  176.,  177.,  178.,  179.,  180.,... 247.,  248.,  249.,  250.,  251.,  252.,  253.])
        x = []
     84             if self.method == 'cubic':
     85                 f = interpolate.CubicSpline(x, y)
     86             elif self.method == 'quadratic':
     87                 f = interpolate.interp1d(x, y, kind=self.method)

IndexError: list index out of range
___________________________________________________________________________
INFO:__main__:We have run 1 models, with 1 failed, using 410.96 seconds
INFO:__main__:

List all the failed models:

INFO:__main__:failed model_name: random_forest
Traceback (most recent call last):
  File "train_test_utils.py", line 514, in <module>
    raise ValueError("No model left after filtering the best model recently!")
ValueError: No model left after filtering the best model recently!
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:data_train: (1488, 106), data_test: (1493, 106)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 1
INFO:__main__:Tuning models, 20180106: 
INFO:__main__:x_train: (1458, 105), y_train: (1458,), x_val: (30, 105), y_val: (30,)
INFO:__main__:




model: random_forest

Fitting 3 folds for each of 3 candidates, totalling 9 fits
INFO:feature_selecting.feature_select:There are in total 1133 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: invalid value encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:feature_selecting.feature_select:
In total, it takes 71.62 seconds to run regression for 1133 columns
INFO:feature_selecting.feature_select:There are in total 1111 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:feature_selecting.feature_select:
In total, it takes 95.88 seconds to run regression for 1144 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:feature_selecting.feature_select:
In total, it takes 97.31 seconds to run regression for 1144 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:feature_selecting.feature_select:
In total, it takes 101.19 seconds to run regression for 1144 columns
INFO:feature_selecting.feature_select:There are in total 1133 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: invalid value encountered in double_scalars
  return self.ess/self.df_model
INFO:feature_selecting.feature_select:
In total, it takes 54.84 seconds to run regression for 1111 columns
INFO:feature_selecting.feature_select:There are in total 1133 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:feature_selecting.feature_select:
In total, it takes 45.87 seconds to run regression for 1133 columns
INFO:feature_selecting.feature_select:There are in total 1144 columns, while we only need 10 columns
INFO:feature_selecting.feature_select:
In total, it takes 59.74 seconds to run regression for 1133 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:feature_selecting.feature_select:
In total, it takes 227.60 seconds to run regression for 1144 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:feature_selecting.feature_select:
In total, it takes 231.99 seconds to run regression for 1144 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:feature_selecting.feature_select:
In total, it takes 230.67 seconds to run regression for 1144 columns
INFO:feature_selecting.feature_select:
In total, it takes 72.04 seconds to run regression for 1144 columns
INFO:feature_selecting.feature_select:There are in total 1122 columns, while we only need 10 columns
