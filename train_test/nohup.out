/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Index(['y'], dtype='object')
INFO:__main__:Tuning models, 20171223: 
./../feature_engineering/feature_extract.py:111: RuntimeWarning: invalid value encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1493, 639), y: (1493,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:0.0
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.9s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 20.31 seconds to train this model.
INFO:__main__:Model 1, model_id: fddbb35a-50e7-4537-ba91-65dee51722e5,model_name: random_forest, impute_method: directly, model_selector: all_selector, using 20.33 seconds
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py", line 4294, in create_block_manager_from_blocks
    placement=slice(0, len(axes[0])))]
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py", line 2719, in make_block
    return klass(values, ndim=ndim, fastpath=fastpath, placement=placement)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py", line 115, in __init__
    len(self.mgr_locs)))
ValueError: Wrong number of items passed 105, placement implies 86928

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_test_utils.py", line 291, in <module>
    search_regression_ml(5, 1, datetime.date(2017, 12, 24))
  File "train_test_utils.py", line 237, in search_regression_ml
    pipeline_param_grid=pipeline_param_grid
  File "train_test_utils.py", line 75, in train
    X = pipeline_1.fit_transform(X)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 301, in fit_transform
    Xt, fit_params = self._fit(X, y, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 234, in _fit
    Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py", line 494, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File "./../data_processing/imputation.py", line 100, in transform
    X = self.method_imputed(data_after_remove_weekend)
  File "./../data_processing/imputation.py", line 83, in method_imputed
    data_after_imputation = pd.DataFrame(np.array(data_copy), index=data.index, columns=data.columns)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py", line 306, in __init__
    copy=copy)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py", line 483, in _init_ndarray
    return create_block_manager_from_blocks([values], [columns, index])
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py", line 4303, in create_block_manager_from_blocks
    construction_error(tot_items, blocks[0].shape[1:], axes, e)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py", line 4280, in construction_error
    passed, implied))
ValueError: Shape of passed values is (105, 1559), indices imply (86928, 1559)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Index(['y'], dtype='object')
INFO:__main__:Tuning models, 20171224: 
./../feature_engineering/feature_extract.py:111: RuntimeWarning: invalid value encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1493, 639), y: (1493,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:0.0
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.8s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 20.23 seconds to train this model.
INFO:__main__:Model 1, model_id: 45715f3b-4488-4dbf-8691-6a40d4acabb4,model_name: random_forest, impute_method: directly, model_selector: all_selector, using 20.24 seconds
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
./../feature_engineering/feature_extract.py:111: RuntimeWarning: invalid value encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1505, 639), y: (1505,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:0.333333333333
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.056512, total=  13.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.083399, total=  10.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.186615, total=   5.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [ 82 201 305 409 435 436 513 539 540 617] are constant.
  UserWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide
  f = msb / msw
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.6s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 27.71 seconds to train this model.
INFO:__main__:Model 2, model_id: 2fbecc4d-95da-4363-ac3d-1be3b9002797,model_name: random_forest, impute_method: slinear, model_selector: all_selector, using 27.73 seconds
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1528, 639), y: (1528,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:3.06390256154
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   14.6s finished
INFO:__main__:It takes 29.96 seconds to train this model.
INFO:__main__:Model 3, model_id: f55ebe67-233e-4e86-8134-007eba6f6f21,model_name: random_forest, impute_method: cubic, model_selector: all_selector, using 29.98 seconds
./../feature_engineering/feature_extract.py:111: RuntimeWarning: invalid value encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1493, 639), y: (1493,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:0.0
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.8s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 20.86 seconds to train this model.
INFO:__main__:Model 4, model_id: e4345f43-b6df-4fd5-80a6-3130ff0b3035,model_name: random_forest, impute_method: zero, model_selector: all_selector, using 20.87 seconds
INFO:__main__:We have run 5 models, using 98.82 seconds
Traceback (most recent call last):
  File "train_test_utils.py", line 291, in <module>
    search_regression_ml(5, 1, datetime.date(2017, 12, 24))
  File "train_test_utils.py", line 279, in search_regression_ml
    for index_i in range(results.index):
TypeError: 'RangeIndex' object cannot be interpreted as an integer
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Index(['y'], dtype='object')
INFO:__main__:Tuning models, 20171224: 
./../feature_engineering/feature_extract.py:111: RuntimeWarning: invalid value encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1493, 639), y: (1493,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:0.0
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.9s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 20.37 seconds to train this model.
INFO:__main__:Model 1, model_id: aa02c7b2-925d-499c-99b2-30866f7c8f04,model_name: random_forest, impute_method: directly, model_selector: all_selector, using 20.39 seconds
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
./../feature_engineering/feature_extract.py:111: RuntimeWarning: invalid value encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1505, 639), y: (1505,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:0.333333333333
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.4s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 27.22 seconds to train this model.
INFO:__main__:Model 2, model_id: 87d990b7-c263-4e62-b6a3-85236687bcf5,model_name: random_forest, impute_method: slinear, model_selector: all_selector, using 27.24 seconds
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1528, 639), y: (1528,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:3.06390256154
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   14.6s finished
INFO:__main__:It takes 29.56 seconds to train this model.
INFO:__main__:Model 3, model_id: 03eff47c-7941-4fd8-ae01-16068ab18826,model_name: random_forest, impute_method: cubic, model_selector: all_selector, using 29.58 seconds
./../feature_engineering/feature_extract.py:111: RuntimeWarning: invalid value encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1493, 639), y: (1493,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:0.0
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.9s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 21.27 seconds to train this model.
INFO:__main__:Model 4, model_id: c598ccd2-44a5-4180-b82b-596131375cf8,model_name: random_forest, impute_method: zero, model_selector: all_selector, using 21.28 seconds
INFO:__main__:We have run 5 models, using 98.49 seconds
INFO:__main__:Saving aa02c7b2-925d-499c-99b2-30866f7c8f04 to disk...
Traceback (most recent call last):
  File "train_test_utils.py", line 291, in <module>
    search_regression_ml(5, 1, datetime.date(2017, 12, 24))
  File "train_test_utils.py", line 282, in search_regression_ml
    save_pipeline(save_model_dict[model_id_i], model_id_i)
  File "train_test_utils.py", line 125, in save_pipeline
    model_save_path = os.path.join("../results/models/", "model_" + model_id + ".pkl")
TypeError: must be str, not UUID
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Index(['y'], dtype='object')
INFO:__main__:Tuning models, 20171224: 
./../feature_engineering/feature_extract.py:111: RuntimeWarning: invalid value encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1493, 639), y: (1493,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:0.0
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.8s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 20.15 seconds to train this model.
INFO:__main__:Model 1, model_id: 034f048c-e0d7-44aa-bbf3-a9869dc549f1,model_name: random_forest, impute_method: directly, model_selector: all_selector, using 20.16 seconds
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
./../feature_engineering/feature_extract.py:111: RuntimeWarning: invalid value encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1505, 639), y: (1505,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:0.333333333333
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.5s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 27.30 seconds to train this model.
INFO:__main__:Model 2, model_id: 9131d269-e43d-4d92-8b98-c92fe58fc313,model_name: random_forest, impute_method: slinear, model_selector: all_selector, using 27.32 seconds
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1528, 639), y: (1528,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:3.06390256154
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   14.7s finished
INFO:__main__:It takes 29.59 seconds to train this model.
INFO:__main__:Model 3, model_id: fa4659b5-a7de-4d0b-bcaf-d83ac409d0cd,model_name: random_forest, impute_method: cubic, model_selector: all_selector, using 29.60 seconds
./../feature_engineering/feature_extract.py:111: RuntimeWarning: invalid value encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
./../feature_engineering/feature_extract.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  rate_list.append(abs((data[j][i] - data[j-1][i]) / data[j-1][i]))
INFO:__main__:x_columns: 639, unique: 639
INFO:__main__:X_train: (1493, 639), y: (1493,)
INFO:__main__:(array([], dtype=int64), array([], dtype=int64))
INFO:__main__:0.0
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.058482, total=   9.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.070834, total=   8.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [ 77 196 300 404 435 436 506 508 539 540 610 612] are constant.
  UserWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide
  f = msb / msw
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.9s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 21.22 seconds to train this model.
INFO:__main__:Model 4, model_id: b1b3c47f-2a9a-405f-9b53-87538699c32f,model_name: random_forest, impute_method: zero, model_selector: all_selector, using 21.23 seconds
INFO:__main__:We have run 5 models, using 98.31 seconds
INFO:__main__:Saving 034f048c-e0d7-44aa-bbf3-a9869dc549f1 to disk...
INFO:__main__:Model dumped into ../results/models/model_034f048c-e0d7-44aa-bbf3-a9869dc549f1.pkl.
INFO:__main__:Saving 9131d269-e43d-4d92-8b98-c92fe58fc313 to disk...
INFO:__main__:Model dumped into ../results/models/model_9131d269-e43d-4d92-8b98-c92fe58fc313.pkl.
INFO:__main__:Saving fa4659b5-a7de-4d0b-bcaf-d83ac409d0cd to disk...
INFO:__main__:Model dumped into ../results/models/model_fa4659b5-a7de-4d0b-bcaf-d83ac409d0cd.pkl.
INFO:__main__:Saving b1b3c47f-2a9a-405f-9b53-87538699c32f to disk...
INFO:__main__:Model dumped into ../results/models/model_b1b3c47f-2a9a-405f-9b53-87538699c32f.pkl.
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Index(['银行间质押式回购加权利率:7天'], dtype='object')
INFO:__main__:Index(['y'], dtype='object')
INFO:__main__:Tuning models, 20171224: 
INFO:__main__:X_train: (1525, 639), y: (1525,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.0s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 20.58 seconds to train this model.
INFO:__main__:X_test: (24, 639)
train_test_utils.py:170: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 055418e1-c6b8-4a3e-8d6e-9505facdebf4,model_name: random_forest, impute_method: directly, model_selector: all_selector, using 22.98 seconds
INFO:__main__:X_train: (1525, 639), y: (1525,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   13.7s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in square
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
INFO:__main__:It takes 27.88 seconds to train this model.
INFO:__main__:X_test: (24, 639)
train_test_utils.py:170: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: 62e99367-92a5-42e1-9a72-f2d7916be0d6,model_name: random_forest, impute_method: slinear, model_selector: all_selector, using 30.95 seconds
INFO:__main__:X_train: (1525, 639), y: (1525,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   14.8s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
INFO:__main__:It takes 29.78 seconds to train this model.
INFO:__main__:X_test: (24, 639)
train_test_utils.py:170: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: bb0ae734-6ab1-44dd-93ae-7ebd30aa9894,model_name: random_forest, impute_method: cubic, model_selector: all_selector, using 32.85 seconds
INFO:__main__:X_train: (1525, 639), y: (1525,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.2s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:It takes 21.44 seconds to train this model.
INFO:__main__:X_test: (24, 639)
train_test_utils.py:170: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 735d6892-0b44-4c9c-a909-533e44626f34,model_name: random_forest, impute_method: zero, model_selector: all_selector, using 24.51 seconds
INFO:__main__:We have run 5 models, using 111.29 seconds
INFO:__main__:Saving 055418e1-c6b8-4a3e-8d6e-9505facdebf4 to disk...
INFO:__main__:Model dumped into ../results/models/model_055418e1-c6b8-4a3e-8d6e-9505facdebf4.pkl.
INFO:__main__:Saving 735d6892-0b44-4c9c-a909-533e44626f34 to disk...
INFO:__main__:Model dumped into ../results/models/model_735d6892-0b44-4c9c-a909-533e44626f34.pkl.
INFO:__main__:Saving 62e99367-92a5-42e1-9a72-f2d7916be0d6 to disk...
INFO:__main__:Model dumped into ../results/models/model_62e99367-92a5-42e1-9a72-f2d7916be0d6.pkl.
INFO:__main__:Saving bb0ae734-6ab1-44dd-93ae-7ebd30aa9894 to disk...
INFO:__main__:Model dumped into ../results/models/model_bb0ae734-6ab1-44dd-93ae-7ebd30aa9894.pkl.
INFO:__main__:X_train: (1555, 639), y_train: (1555,)
INFO:__main__:model 055418e1-c6b8-4a3e-8d6e-9505facdebf4 does not exists
INFO:__main__:Input contains NaN, infinity or a value too large for dtype('float64').
INFO:__main__:X_train: (1555, 639), y_train: (1555,)
INFO:__main__:model 735d6892-0b44-4c9c-a909-533e44626f34 does not exists
INFO:__main__:Input contains NaN, infinity or a value too large for dtype('float64').
INFO:__main__:X_train: (1555, 639), y_train: (1555,)
INFO:__main__:model 62e99367-92a5-42e1-9a72-f2d7916be0d6 does not exists
INFO:__main__:Input contains NaN, infinity or a value too large for dtype('float64').
INFO:__main__:X_train: (1555, 639), y_train: (1555,)
INFO:__main__:model bb0ae734-6ab1-44dd-93ae-7ebd30aa9894 does not exists
INFO:__main__:Input contains NaN, infinity or a value too large for dtype('float64').
INFO:__main__:Prediction finished!!!
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Index(['银行间质押式回购加权利率:7天'], dtype='object')
INFO:__main__:Index(['y'], dtype='object')
train_test_utils.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  data_train.dropna(inplace=True)
INFO:__main__:X_train: (1545, 639), y_train: (1545,)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:X_test: (4, 639)
train_test_utils.py:171: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model: 055418e1-c6b8-4a3e-8d6e-9505facdebf4, model_name: random_forest, metric: 58.33333333333334
train_test_utils.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  data_train.dropna(inplace=True)
INFO:__main__:X_train: (1545, 639), y_train: (1545,)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:X_test: (4, 639)
train_test_utils.py:171: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model: 735d6892-0b44-4c9c-a909-533e44626f34, model_name: random_forest, metric: 58.33333333333334
train_test_utils.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  data_train.dropna(inplace=True)
INFO:__main__:X_train: (1545, 639), y_train: (1545,)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in square
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
INFO:__main__:X_test: (4, 639)
train_test_utils.py:171: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model: 62e99367-92a5-42e1-9a72-f2d7916be0d6, model_name: random_forest, metric: 50.0
train_test_utils.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  data_train.dropna(inplace=True)
INFO:__main__:X_train: (1545, 639), y_train: (1545,)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
INFO:__main__:X_test: (4, 639)
train_test_utils.py:171: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model: bb0ae734-6ab1-44dd-93ae-7ebd30aa9894, model_name: random_forest, metric: 50.0
INFO:__main__:Prediction finished!!!
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "pandas/_libs/tslib.pyx", line 2469, in pandas._libs.tslib.array_to_datetime (pandas/_libs/tslib.c:44294)
  File "pandas/_libs/src/datetime.pxd", line 132, in datetime._string_to_dts (pandas/_libs/tslib.c:97337)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-3: ordinal not in range(128)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "pandas/_libs/tslib.pyx", line 2491, in pandas._libs.tslib.array_to_datetime (pandas/_libs/tslib.c:44703)
  File "pandas/_libs/tslib.pyx", line 1955, in pandas._libs.tslib.parse_datetime_string (pandas/_libs/tslib.c:35351)
  File "/opt/anaconda3/lib/python3.6/site-packages/dateutil/parser.py", line 1168, in parse
    return DEFAULTPARSER.parse(timestr, **kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/dateutil/parser.py", line 559, in parse
    raise ValueError("Unknown string format")
ValueError: Unknown string format

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_test_utils.py", line 342, in <module>
    refit=True
  File "train_test_utils.py", line 144, in test
    X = pipeline_before_selector.transform(X)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 445, in _transform
    Xt = transform.transform(Xt)
  File "./../data_processing/imputation.py", line 92, in transform
    data_after_remove_weekend = self.remove_weekend(X)
  File "./../data_processing/imputation.py", line 26, in remove_weekend
    data.index = pd.to_datetime(data.index)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/tools/datetimes.py", line 514, in to_datetime
    result = _convert_listlike(arg, box, format, name=arg.name)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/tools/datetimes.py", line 435, in _convert_listlike
    require_iso8601=require_iso8601
  File "pandas/_libs/tslib.pyx", line 2355, in pandas._libs.tslib.array_to_datetime (pandas/_libs/tslib.c:46617)
  File "pandas/_libs/tslib.pyx", line 2583, in pandas._libs.tslib.array_to_datetime (pandas/_libs/tslib.c:46321)
  File "pandas/_libs/tslib.pyx", line 2497, in pandas._libs.tslib.array_to_datetime (pandas/_libs/tslib.c:44803)
TypeError: invalid string coercion to datetime
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 321, in <module>
    data = data.loc[:-2]
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1328, in __getitem__
    return self._getitem_axis(key, axis=0)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1506, in _getitem_axis
    return self._get_slice_axis(key, axis=axis)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1356, in _get_slice_axis
    slice_obj.step, kind=self.name)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3301, in slice_indexer
    kind=kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3495, in slice_locs
    end_slice = self.get_slice_bound(end, 'right', kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3428, in get_slice_bound
    label = self._maybe_cast_slice_bound(label, side, kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3379, in _maybe_cast_slice_bound
    self._invalid_indexer('slice', label)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 1469, in _invalid_indexer
    kind=type(key)))
TypeError: cannot do slice indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [-2] of <class 'int'>
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 321, in <module>
    data = data.loc[:data.shape[0]-2]
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1328, in __getitem__
    return self._getitem_axis(key, axis=0)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1506, in _getitem_axis
    return self._get_slice_axis(key, axis=axis)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1356, in _get_slice_axis
    slice_obj.step, kind=self.name)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3301, in slice_indexer
    kind=kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3495, in slice_locs
    end_slice = self.get_slice_bound(end, 'right', kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3428, in get_slice_bound
    label = self._maybe_cast_slice_bound(label, side, kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3379, in _maybe_cast_slice_bound
    self._invalid_indexer('slice', label)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 1469, in _invalid_indexer
    kind=type(key)))
TypeError: cannot do slice indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [2183] of <class 'int'>
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 321, in <module>
    data = data.loc[:data.shape[0]-2, :]
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1325, in __getitem__
    return self._getitem_tuple(key)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 856, in _getitem_tuple
    retval = getattr(retval, self.name)._getitem_axis(key, axis=i)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1506, in _getitem_axis
    return self._get_slice_axis(key, axis=axis)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1356, in _get_slice_axis
    slice_obj.step, kind=self.name)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3301, in slice_indexer
    kind=kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3495, in slice_locs
    end_slice = self.get_slice_bound(end, 'right', kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3428, in get_slice_bound
    label = self._maybe_cast_slice_bound(label, side, kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3379, in _maybe_cast_slice_bound
    self._invalid_indexer('slice', label)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 1469, in _invalid_indexer
    kind=type(key)))
TypeError: cannot do slice indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [2183] of <class 'int'>
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 321, in <module>
    data = data.loc[:data.shape[0]-2, :]
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1325, in __getitem__
    return self._getitem_tuple(key)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 856, in _getitem_tuple
    retval = getattr(retval, self.name)._getitem_axis(key, axis=i)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1506, in _getitem_axis
    return self._get_slice_axis(key, axis=axis)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1356, in _get_slice_axis
    slice_obj.step, kind=self.name)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/datetimes.py", line 1515, in slice_indexer
    return Index.slice_indexer(self, start, end, step, kind=kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3301, in slice_indexer
    kind=kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3495, in slice_locs
    end_slice = self.get_slice_bound(end, 'right', kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 3428, in get_slice_bound
    label = self._maybe_cast_slice_bound(label, side, kind)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/datetimes.py", line 1462, in _maybe_cast_slice_bound
    self._invalid_indexer('slice', label)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 1469, in _invalid_indexer
    kind=type(key)))
TypeError: cannot do slice indexing on <class 'pandas.core.indexes.datetimes.DatetimeIndex'> with these indexers [2181] of <class 'int'>
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
train_test_utils.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  data_train.dropna(inplace=True)
INFO:__main__:X_train: (1545, 639), y_train: (1545,)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:X_test: (5, 639)
Traceback (most recent call last):
  File "train_test_utils.py", line 343, in <module>
    refit=True
  File "train_test_utils.py", line 170, in test
    X_copy = data_test[["y", "forward_y"]]
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py", line 2056, in __getitem__
    return self._getitem_array(key)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py", line 2100, in _getitem_array
    indexer = self.loc._convert_to_indexer(key, axis=1)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py", line 1231, in _convert_to_indexer
    raise KeyError('%s not in index' % objarr[mask])
KeyError: "['y'] not in index"
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
train_test_utils.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  data_train.dropna(inplace=True)
INFO:__main__:X_train: (1545, 639), y_train: (1545,)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:X_test: (5, 639)
train_test_utils.py:171: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model: 055418e1-c6b8-4a3e-8d6e-9505facdebf4, model_name: random_forest, metric: 58.33333333333334
train_test_utils.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  data_train.dropna(inplace=True)
INFO:__main__:X_train: (1545, 639), y_train: (1545,)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: divide by zero encountered in true_divide
  f = msb / msw
INFO:__main__:X_test: (5, 639)
train_test_utils.py:171: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model: 735d6892-0b44-4c9c-a909-533e44626f34, model_name: random_forest, metric: 58.33333333333334
train_test_utils.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  data_train.dropna(inplace=True)
INFO:__main__:X_train: (1545, 639), y_train: (1545,)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in square
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
INFO:__main__:X_test: (5, 639)
train_test_utils.py:171: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model: 62e99367-92a5-42e1-9a72-f2d7916be0d6, model_name: random_forest, metric: 50.0
train_test_utils.py:156: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  data_train.dropna(inplace=True)
INFO:__main__:X_train: (1545, 639), y_train: (1545,)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:310: RuntimeWarning: overflow encountered in square
  X = X ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:98: RuntimeWarning: overflow encountered in add
  square_of_sums_alldata = sum(sums_args) ** 2
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:99: RuntimeWarning: overflow encountered in square
  square_of_sums_args = [s ** 2 for s in sums_args]
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:100: RuntimeWarning: invalid value encountered in subtract
  sstot = ss_alldata - square_of_sums_alldata / float(n_samples)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:104: RuntimeWarning: invalid value encountered in subtract
  ssbn -= square_of_sums_alldata / float(n_samples)
INFO:__main__:X_test: (5, 639)
train_test_utils.py:171: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model: bb0ae734-6ab1-44dd-93ae-7ebd30aa9894, model_name: random_forest, metric: 50.0
INFO:__main__:Prediction finished!!!
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 381, in <module>
    model_results = pd.read_csv(results_path, encoding="utf-8")
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py", line 655, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py", line 405, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py", line 762, in __init__
    self._make_engine(self.engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py", line 966, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py", line 1582, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas/_libs/parsers.pyx", line 394, in pandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)
  File "pandas/_libs/parsers.pyx", line 710, in pandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)
FileNotFoundError: File b'./../results/model_history/regression_results_1.csv' does not exist
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 1
INFO:__main__:Tuning models, 20171225: 
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.085791, total=   0.9s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.183423, total=   0.8s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished
INFO:__main__:It takes 196.29 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 34e1b05e-8fc2-4954-ac38-404898c3f593,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 20.0using 399.20 seconds
INFO:__main__:




impute_method: slinear

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.132970, total=   1.1s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.053780, total=   0.7s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.065949, total=   1.1s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.3s finished
INFO:__main__:It takes 212.63 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: d53d460b-a211-466b-9375-f0a8cd7ae5b4,model_name: random_forest, impute_method: slinear, model_selector: hard_threshold_20, eval_metric: 28.000000000000004using 438.10 seconds
INFO:__main__:




impute_method: cubic

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.074409, total=   0.7s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.262039, total=   0.6s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished
INFO:__main__:It takes 213.39 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: 34ee0515-ae32-4e48-b6d8-788d613500f2,model_name: random_forest, impute_method: cubic, model_selector: hard_threshold_20, eval_metric: 24.0using 403.60 seconds
INFO:__main__:




impute_method: zero

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.199320, total=   0.7s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.183423, total=   0.8s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.085791, total=   0.8s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished
INFO:__main__:It takes 190.30 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 24ee7e21-da57-4516-8a96-676207aa3b07,model_name: random_forest, impute_method: zero, model_selector: hard_threshold_20, eval_metric: 20.0using 382.46 seconds
INFO:__main__:We have run 5 models, using 1623.37 seconds
INFO:__main__:Saving d53d460b-a211-466b-9375-f0a8cd7ae5b4 to disk...
INFO:__main__:Model dumped into ../results/models/model_d53d460b-a211-466b-9375-f0a8cd7ae5b4.pkl.
INFO:__main__:Saving 34ee0515-ae32-4e48-b6d8-788d613500f2 to disk...
INFO:__main__:Model dumped into ../results/models/model_34ee0515-ae32-4e48-b6d8-788d613500f2.pkl.
INFO:__main__:Saving 34e1b05e-8fc2-4954-ac38-404898c3f593 to disk...
INFO:__main__:Model dumped into ../results/models/model_34e1b05e-8fc2-4954-ac38-404898c3f593.pkl.
Traceback (most recent call last):
  File "train_test_utils.py", line 376, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 328, in search_regression_ml
    json.dump(model_params_dict, fp)
  File "/opt/anaconda3/lib/python3.6/json/__init__.py", line 179, in dump
    for chunk in iterable:
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 430, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 404, in _iterencode_dict
    yield from chunks
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 404, in _iterencode_dict
    yield from chunks
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 325, in _iterencode_list
    yield from chunks
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 325, in _iterencode_list
    yield from chunks
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 437, in _iterencode
    o = _default(o)
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 180, in default
    o.__class__.__name__)
TypeError: Object of type 'Pipeline' is not JSON serializable
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 1
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.183423, total=   1.2s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.4s finished
INFO:__main__:It takes 232.50 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 4ab8cd0c-8bcf-432d-b4b4-e5342f00d311,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 20.0using 464.95 seconds
INFO:__main__:




impute_method: slinear

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.053780, total=   0.9s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.132970, total=   0.8s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.9s finished
INFO:__main__:It takes 229.31 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: b200c54f-f5ae-4f80-a975-5e6bb57318ff,model_name: random_forest, impute_method: slinear, model_selector: hard_threshold_20, eval_metric: 28.000000000000004using 454.66 seconds
INFO:__main__:




impute_method: cubic

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.262039, total=   0.8s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.074409, total=   0.8s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished
INFO:__main__:It takes 234.62 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: 7a1a350d-eff4-4445-ae45-2418ba98cb92,model_name: random_forest, impute_method: cubic, model_selector: hard_threshold_20, eval_metric: 24.0using 478.92 seconds
INFO:__main__:




impute_method: zero

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.199320, total=   1.1s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.183423, total=   1.1s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.085791, total=   1.1s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s finished
INFO:__main__:It takes 231.94 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 917c4c04-4655-4085-9cc6-078863d9d3e1,model_name: random_forest, impute_method: zero, model_selector: hard_threshold_20, eval_metric: 20.0using 452.36 seconds
INFO:__main__:We have run 5 models, using 1850.89 seconds
INFO:__main__:Saving b200c54f-f5ae-4f80-a975-5e6bb57318ff to disk...
INFO:__main__:Model dumped into ../results/models/model_b200c54f-f5ae-4f80-a975-5e6bb57318ff.pkl.
INFO:__main__:Saving 7a1a350d-eff4-4445-ae45-2418ba98cb92 to disk...
INFO:__main__:Model dumped into ../results/models/model_7a1a350d-eff4-4445-ae45-2418ba98cb92.pkl.
INFO:__main__:Saving 4ab8cd0c-8bcf-432d-b4b4-e5342f00d311 to disk...
INFO:__main__:Model dumped into ../results/models/model_4ab8cd0c-8bcf-432d-b4b4-e5342f00d311.pkl.
Traceback (most recent call last):
  File "train_test_utils.py", line 379, in <module>
    data=data.copy(),
  File "train_test_utils.py", line 331, in search_regression_ml
    with open(model_params_json_path, 'w') as fp:
  File "/opt/anaconda3/lib/python3.6/json/__init__.py", line 179, in dump
    for chunk in iterable:
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 430, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 404, in _iterencode_dict
    yield from chunks
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 404, in _iterencode_dict
    yield from chunks
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 404, in _iterencode_dict
    yield from chunks
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 325, in _iterencode_list
    yield from chunks
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 325, in _iterencode_list
    yield from chunks
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 437, in _iterencode
    o = _default(o)
  File "/opt/anaconda3/lib/python3.6/json/encoder.py", line 180, in default
    o.__class__.__name__)
TypeError: Object of type 'ImputationMethod' is not JSON serializable
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 1
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 235, in search_regression_ml
    model_params_dict = json.loads(model_params_json_path)
  File "/opt/anaconda3/lib/python3.6/json/__init__.py", line 354, in loads
    return _default_decoder.decode(s)
  File "/opt/anaconda3/lib/python3.6/json/decoder.py", line 339, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/opt/anaconda3/lib/python3.6/json/decoder.py", line 357, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 1
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.199320, total=   1.0s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.183423, total=   1.1s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.085791, total=   1.1s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s finished
INFO:__main__:It takes 237.23 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 4faea703-d959-4a86-b967-40f18b465b9d,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 20.0using 465.62 seconds
INFO:__main__:




impute_method: slinear

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.065949, total=   1.0s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s finished
INFO:__main__:It takes 240.75 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: 27d34e6c-8f8c-4fdb-8bc8-c0a677c61869,model_name: random_forest, impute_method: slinear, model_selector: hard_threshold_20, eval_metric: 28.000000000000004using 466.20 seconds
INFO:__main__:




impute_method: cubic

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.262039, total=   0.8s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.200399, total=   0.8s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.074409, total=   0.8s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished
INFO:__main__:It takes 229.85 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: 00671e15-8a8e-4016-a633-5f99405a9946,model_name: random_forest, impute_method: cubic, model_selector: hard_threshold_20, eval_metric: 24.0using 455.17 seconds
INFO:__main__:




impute_method: zero

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 21), y: (1530,)
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.199320, total=   0.7s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.183423, total=   0.6s
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV]  model__n_estimators=100, reducer__n_components=10, score=-0.085791, total=   0.7s
[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished
INFO:__main__:It takes 225.78 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 21)
train_test_utils.py:173: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: fd4067a5-1bc0-4f04-85ef-1328a3ea0177,model_name: random_forest, impute_method: zero, model_selector: hard_threshold_20, eval_metric: 20.0using 445.69 seconds
INFO:__main__:We have run 5 models, using 1832.68 seconds
INFO:__main__:Saving 27d34e6c-8f8c-4fdb-8bc8-c0a677c61869 to disk...
INFO:__main__:Model dumped into ../results/models/model_27d34e6c-8f8c-4fdb-8bc8-c0a677c61869.pkl.
INFO:__main__:Saving 00671e15-8a8e-4016-a633-5f99405a9946 to disk...
INFO:__main__:Model dumped into ../results/models/model_00671e15-8a8e-4016-a633-5f99405a9946.pkl.
INFO:__main__:Saving 4faea703-d959-4a86-b967-40f18b465b9d to disk...
INFO:__main__:Model dumped into ../results/models/model_4faea703-d959-4a86-b967-40f18b465b9d.pkl.
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "train_test_utils.py", line 332, in search_regression_ml
    
NameError: name 'model_params_dict' is not defined
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 1
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 11), y: (1530,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=1000, reducer__n_components=10 ..............
[CV] model__n_estimators=1000, reducer__n_components=10 ..............
[CV] model__n_estimators=500, reducer__n_components=10 ...............
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV] model__n_estimators=500, reducer__n_components=10 ...............
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV] model__n_estimators=1000, reducer__n_components=10 ..............
[CV] model__n_estimators=100, reducer__n_components=10 ...............
[CV] model__n_estimators=500, reducer__n_components=10 ...............
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 344, in __call__
    return self.func(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 227, in _fit_and_score
    estimator.set_params(**parameters)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 180, in set_params
    self._set_params('steps', **kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 69, in _set_params
    super(_BasePipeline, self).set_params(**params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py", line 282, in set_params
    (name, self))
ValueError: Invalid parameter reducer for estimator Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('model', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=100, n_jobs=-1, oob_score=False, random_state=1234,
           verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 353, in __call__
    raise TransportableException(text, e_type)
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
ValueError                                         Tue Dec 26 04:59:26 2017
PID: 41174                          Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]]), array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 376,
       377, 378, 379, 380, 381, 382, 383]), array([384, 385, 386, 387, 388, 389, 390, 391, 3..., 758, 759, 760,
       761, 762, 763, 764, 765]), 3, {'model__n_estimators': 100, 'reducer__n_components': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]]), array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 376,
       377, 378, 379, 380, 381, 382, 383]), array([384, 385, 386, 387, 388, 389, 390, 391, 3..., 758, 759, 760,
       761, 762, 763, 764, 765]), 3, {'model__n_estimators': 100, 'reducer__n_components': 10})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), X=array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]]), y=array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 376,
       377, 378, 379, 380, 381, 382, 383]), test=array([384, 385, 386, 387, 388, 389, 390, 391, 3..., 758, 759, 760,
       761, 762, 763, 764, 765]), verbose=3, parameters={'model__n_estimators': 100, 'reducer__n_components': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    222     fit_params = fit_params if fit_params is not None else {}
    223     fit_params = dict([(k, _index_param_value(X, v, train))
    224                       for k, v in fit_params.items()])
    225 
    226     if parameters is not None:
--> 227         estimator.set_params(**parameters)
        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...1234,
           verbose=0, warm_start=False))])>
        parameters = {'model__n_estimators': 100, 'reducer__n_components': 10}
    228 
    229     start_time = time.time()
    230 
    231     X_train, y_train = _safe_split(estimator, X, y, train)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), **kwargs={'model__n_estimators': 100, 'reducer__n_components': 10})
    175 
    176         Returns
    177         -------
    178         self
    179         """
--> 180         self._set_params('steps', **kwargs)
        self._set_params = <bound method _BasePipeline._set_params of Pipel...1234,
           verbose=0, warm_start=False))])>
        kwargs = {'model__n_estimators': 100, 'reducer__n_components': 10}
    181         return self
    182 
    183     def _validate_steps(self):
    184         names, estimators = zip(*self.steps)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), steps_attr='steps', **params={'model__n_estimators': 100, 'reducer__n_components': 10})
     64         step_names, _ = zip(*getattr(self, steps_attr))
     65         for name in list(six.iterkeys(params)):
     66             if '__' not in name and name in step_names:
     67                 self._replace_step(steps_attr, name, params.pop(name))
     68         # 3. Step parameters and other initilisation arguments
---> 69         super(_BasePipeline, self).set_params(**params)
        self.set_params = <bound method Pipeline.set_params of Pipeline(st...1234,
           verbose=0, warm_start=False))])>
        params = {'model__n_estimators': 100, 'reducer__n_components': 10}
     70         return self
     71 
     72     def _validate_names(self, names):
     73         if len(set(names)) != len(names):

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), **params={'model__n_estimators': 100, 'reducer__n_components': 10})
    277                 name, sub_name = split
    278                 if name not in valid_params:
    279                     raise ValueError('Invalid parameter %s for estimator %s. '
    280                                      'Check the list of available parameters '
    281                                      'with `estimator.get_params().keys()`.' %
--> 282                                      (name, self))
        name = 'reducer'
        self = Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))])
    283                 sub_object = valid_params[name]
    284                 sub_object.set_params(**{sub_name: value})
    285             else:
    286                 # simple objects case

ValueError: Invalid parameter reducer for estimator Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('model', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=100, n_jobs=-1, oob_score=False, random_state=1234,
           verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.
___________________________________________________________________________
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 682, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 608, in get
    raise self._value
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
ValueError                                         Tue Dec 26 04:59:26 2017
PID: 41174                          Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]]), array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 376,
       377, 378, 379, 380, 381, 382, 383]), array([384, 385, 386, 387, 388, 389, 390, 391, 3..., 758, 759, 760,
       761, 762, 763, 764, 765]), 3, {'model__n_estimators': 100, 'reducer__n_components': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]]), array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 376,
       377, 378, 379, 380, 381, 382, 383]), array([384, 385, 386, 387, 388, 389, 390, 391, 3..., 758, 759, 760,
       761, 762, 763, 764, 765]), 3, {'model__n_estimators': 100, 'reducer__n_components': 10})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), X=array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]]), y=array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 376,
       377, 378, 379, 380, 381, 382, 383]), test=array([384, 385, 386, 387, 388, 389, 390, 391, 3..., 758, 759, 760,
       761, 762, 763, 764, 765]), verbose=3, parameters={'model__n_estimators': 100, 'reducer__n_components': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    222     fit_params = fit_params if fit_params is not None else {}
    223     fit_params = dict([(k, _index_param_value(X, v, train))
    224                       for k, v in fit_params.items()])
    225 
    226     if parameters is not None:
--> 227         estimator.set_params(**parameters)
        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...1234,
           verbose=0, warm_start=False))])>
        parameters = {'model__n_estimators': 100, 'reducer__n_components': 10}
    228 
    229     start_time = time.time()
    230 
    231     X_train, y_train = _safe_split(estimator, X, y, train)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), **kwargs={'model__n_estimators': 100, 'reducer__n_components': 10})
    175 
    176         Returns
    177         -------
    178         self
    179         """
--> 180         self._set_params('steps', **kwargs)
        self._set_params = <bound method _BasePipeline._set_params of Pipel...1234,
           verbose=0, warm_start=False))])>
        kwargs = {'model__n_estimators': 100, 'reducer__n_components': 10}
    181         return self
    182 
    183     def _validate_steps(self):
    184         names, estimators = zip(*self.steps)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), steps_attr='steps', **params={'model__n_estimators': 100, 'reducer__n_components': 10})
     64         step_names, _ = zip(*getattr(self, steps_attr))
     65         for name in list(six.iterkeys(params)):
     66             if '__' not in name and name in step_names:
     67                 self._replace_step(steps_attr, name, params.pop(name))
     68         # 3. Step parameters and other initilisation arguments
---> 69         super(_BasePipeline, self).set_params(**params)
        self.set_params = <bound method Pipeline.set_params of Pipeline(st...1234,
           verbose=0, warm_start=False))])>
        params = {'model__n_estimators': 100, 'reducer__n_components': 10}
     70         return self
     71 
     72     def _validate_names(self, names):
     73         if len(set(names)) != len(names):

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), **params={'model__n_estimators': 100, 'reducer__n_components': 10})
    277                 name, sub_name = split
    278                 if name not in valid_params:
    279                     raise ValueError('Invalid parameter %s for estimator %s. '
    280                                      'Check the list of available parameters '
    281                                      'with `estimator.get_params().keys()`.' %
--> 282                                      (name, self))
        name = 'reducer'
        self = Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))])
    283                 sub_object = valid_params[name]
    284                 sub_object.set_params(**{sub_name: value})
    285             else:
    286                 # simple objects case

ValueError: Invalid parameter reducer for estimator Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('model', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=100, n_jobs=-1, oob_score=False, random_state=1234,
           verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.
___________________________________________________________________________

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 280, in search_regression_ml
    pipeline_param_grid=pipeline_param_grid
  File "train_test_utils.py", line 133, in train
    pipeline_2.fit(X_train, y_train)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 945, in fit
    return self._fit(X, y, groups, ParameterGrid(self.param_grid))
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 564, in _fit
    for parameters in parameter_iterable
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 768, in __call__
    self.retrieve()
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 719, in retrieve
    raise exception
sklearn.externals.joblib.my_exceptions.JoblibValueError: JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in <module>()
    399         search_regression_ml(
    400             data=data.copy(),
    401             save_k_best=args.save_k_best,
    402             look_ahead_day=args.look_forward_days,
    403             split_date=datetime.datetime.strptime(args.split_date, "%Y%m%d").date(),
--> 404             validation_period_length=args.validation_period_length
    405         )
    406 
    407     # set the model results path
    408     results_path = os.path.join("./../results/model_history/", "regression_results_" + str(args.look_forward_days) + ".csv")

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in search_regression_ml(data=                 x1          x2         x3      ...NaN      NaN  3.0297  

[2183 rows x 105 columns], save_k_best=2, look_ahead_day=1, split_date=datetime.date(2017, 12, 18), validation_period_length=30)
    275                         reducer=PCA(n_components=10),  # temporarily not in use
    276                         model=model_dict[model_name],
    277                         X=data.copy(),
    278                         split_date=split_date - datetime.timedelta(days=validation_period_length),
    279                         pipeline_mode=model_pipeline_mode_dict[model_name],
--> 280                         pipeline_param_grid=pipeline_param_grid
        pipeline_param_grid = {'model__n_estimators': [100, 500, 1000], 'reducer__n_components': [10]}
    281                     )
    282                     model_id = str(uuid.uuid4())
    283                     y_test_predict = test(
    284                         data.copy(),

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in train(imputer=ImputationMethod(method='directly'), engineer=FeatureExtract(changerate=True, diff=True, ind=[...0, log=True,
        look_forward_days=1, ma=[5]), selector=HardThresholdSelector(alpha=0.05, date_column='d...
           select_top_k=True, target_column='y'), scaler=MinMaxScaler(copy=True, feature_range=(0, 1)), reducer=PCA(copy=True, iterated_power='auto', n_componen...None,
  svd_solver='auto', tol=0.0, whiten=False), model=RandomForestRegressor(bootstrap=True, criterion=...  random_state=1234, verbose=0, warm_start=False), X=               x59  x59_ind_2  x59_ma_5     x89 ...07  3.2785     3.3609  

[1530 rows x 12 columns], split_date=datetime.date(2017, 11, 18), pipeline_mode='grid', pipeline_param_grid={'model__n_estimators': [100, 500, 1000], 'reducer__n_components': [10]})
    128         search_pipeline=pipeline_2,
    129         pipeline_mode=pipeline_mode,
    130         param_grid=pipeline_param_grid
    131     )
    132 
--> 133     pipeline_2.fit(X_train, y_train)
        pipeline_2.fit = <bound method GridSearchCV.fit of GridSearchCV(c...    scoring='neg_mean_squared_error', verbose=3)>
        X_train = array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]])
        y_train = array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609])
    134     logger.info("It takes {:.2f} seconds to train this model.".format(time.time() - time_init))
    135     if pipeline_mode != "single":
    136         pipeline_2 = pipeline_2.best_estimator_
    137 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=TimeSeriesSplit(n_splits=3), err...     scoring='neg_mean_squared_error', verbose=3), X=array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]]), y=array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609]), groups=None)
    940 
    941         groups : array-like, with shape (n_samples,), optional
    942             Group labels for the samples used while splitting the dataset into
    943             train/test set.
    944         """
--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))
        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...    scoring='neg_mean_squared_error', verbose=3)>
        X = array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]])
        y = array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609])
        groups = None
        self.param_grid = {'model__n_estimators': [100, 500, 1000], 'reducer__n_components': [10]}
    946 
    947 
    948 class RandomizedSearchCV(BaseSearchCV):
    949     """Randomized search on hyper parameters.

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=TimeSeriesSplit(n_splits=3), err...     scoring='neg_mean_squared_error', verbose=3), X=array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]]), y=array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Tue Dec 26 04:59:26 2017
PID: 41174                          Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]]), array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 376,
       377, 378, 379, 380, 381, 382, 383]), array([384, 385, 386, 387, 388, 389, 390, 391, 3..., 758, 759, 760,
       761, 762, 763, 764, 765]), 3, {'model__n_estimators': 100, 'reducer__n_components': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]]), array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 376,
       377, 378, 379, 380, 381, 382, 383]), array([384, 385, 386, 387, 388, 389, 390, 391, 3..., 758, 759, 760,
       761, 762, 763, 764, 765]), 3, {'model__n_estimators': 100, 'reducer__n_components': 10})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), X=array([[  4.519     ,  20.421361  ,   4.20256   ...7.75956736,
          4.4407    ,   3.2785    ]]), y=array([ 4.0835,  3.9949,  4.1816, ...,  3.4924,  3.2785,  3.3609]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 376,
       377, 378, 379, 380, 381, 382, 383]), test=array([384, 385, 386, 387, 388, 389, 390, 391, 3..., 758, 759, 760,
       761, 762, 763, 764, 765]), verbose=3, parameters={'model__n_estimators': 100, 'reducer__n_components': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    222     fit_params = fit_params if fit_params is not None else {}
    223     fit_params = dict([(k, _index_param_value(X, v, train))
    224                       for k, v in fit_params.items()])
    225 
    226     if parameters is not None:
--> 227         estimator.set_params(**parameters)
        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...1234,
           verbose=0, warm_start=False))])>
        parameters = {'model__n_estimators': 100, 'reducer__n_components': 10}
    228 
    229     start_time = time.time()
    230 
    231     X_train, y_train = _safe_split(estimator, X, y, train)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), **kwargs={'model__n_estimators': 100, 'reducer__n_components': 10})
    175 
    176         Returns
    177         -------
    178         self
    179         """
--> 180         self._set_params('steps', **kwargs)
        self._set_params = <bound method _BasePipeline._set_params of Pipel...1234,
           verbose=0, warm_start=False))])>
        kwargs = {'model__n_estimators': 100, 'reducer__n_components': 10}
    181         return self
    182 
    183     def _validate_steps(self):
    184         names, estimators = zip(*self.steps)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), steps_attr='steps', **params={'model__n_estimators': 100, 'reducer__n_components': 10})
     64         step_names, _ = zip(*getattr(self, steps_attr))
     65         for name in list(six.iterkeys(params)):
     66             if '__' not in name and name in step_names:
     67                 self._replace_step(steps_attr, name, params.pop(name))
     68         # 3. Step parameters and other initilisation arguments
---> 69         super(_BasePipeline, self).set_params(**params)
        self.set_params = <bound method Pipeline.set_params of Pipeline(st...1234,
           verbose=0, warm_start=False))])>
        params = {'model__n_estimators': 100, 'reducer__n_components': 10}
     70         return self
     71 
     72     def _validate_names(self, names):
     73         if len(set(names)) != len(names):

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))]), **params={'model__n_estimators': 100, 'reducer__n_components': 10})
    277                 name, sub_name = split
    278                 if name not in valid_params:
    279                     raise ValueError('Invalid parameter %s for estimator %s. '
    280                                      'Check the list of available parameters '
    281                                      'with `estimator.get_params().keys()`.' %
--> 282                                      (name, self))
        name = 'reducer'
        self = Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru...=1234,
           verbose=0, warm_start=False))])
    283                 sub_object = valid_params[name]
    284                 sub_object.set_params(**{sub_name: value})
    285             else:
    286                 # simple objects case

ValueError: Invalid parameter reducer for estimator Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('model', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=100, n_jobs=-1, oob_score=False, random_state=1234,
           verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.
___________________________________________________________________________
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 1
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 11), y: (1530,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.129227, total=   0.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.042354, total=   0.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.064369, total=   0.6s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.8s remaining:    2.9s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    2.4s remaining:    1.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    4.3s finished
INFO:__main__:It takes 228.26 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 43277782-ab16-4d66-830a-aa394e6273f4,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 48.0using 449.82 seconds
INFO:__main__:




impute_method: slinear

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
INFO:__main__:X_train: (1530, 11), y: (1530,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.032469, total=   0.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.062438, total=   0.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.154918, total=   0.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.153874, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.032096, total=   1.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.062429, total=   1.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.154605, total=   2.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.062217, total=   3.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.032402, total=   3.1s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.8s remaining:    2.8s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    2.2s remaining:    1.1s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    4.0s finished
INFO:__main__:It takes 229.52 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: 02a8bbee-19f9-4280-b6e9-f5e6c8ad1a56,model_name: random_forest, impute_method: slinear, model_selector: hard_threshold_10, eval_metric: 48.0using 458.28 seconds
INFO:__main__:




impute_method: cubic

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 11), y: (1530,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.129227, total=   0.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.042354, total=   0.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.064369, total=   0.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.042454, total=   1.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.063432, total=   2.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.126654, total=   1.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.042783, total=   3.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.127402, total=   3.1s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.7s remaining:    2.4s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    2.4s remaining:    1.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    4.2s finished
INFO:__main__:It takes 236.50 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: c7c58713-7888-4ebd-af22-bfcb7a616dfe,model_name: random_forest, impute_method: cubic, model_selector: hard_threshold_10, eval_metric: 48.0using 466.12 seconds
INFO:__main__:




impute_method: zero

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 11), y: (1530,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.129227, total=   0.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.064369, total=   0.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.042354, total=   0.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.126654, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.042454, total=   1.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.063432, total=   2.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.127402, total=   2.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.042783, total=   2.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.063722, total=   3.7s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.8s remaining:    2.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    2.5s remaining:    1.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    4.3s finished
INFO:__main__:It takes 233.17 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: e73765f8-6471-4663-a972-f6394bb52ffe,model_name: random_forest, impute_method: zero, model_selector: hard_threshold_10, eval_metric: 48.0using 458.40 seconds
INFO:__main__:We have run 5 models, using 1832.62 seconds
INFO:__main__:Saving 43277782-ab16-4d66-830a-aa394e6273f4 to disk...
INFO:__main__:Model dumped into ../results/models/model_43277782-ab16-4d66-830a-aa394e6273f4.pkl.
INFO:__main__:Saving 02a8bbee-19f9-4280-b6e9-f5e6c8ad1a56 to disk...
INFO:__main__:Model dumped into ../results/models/model_02a8bbee-19f9-4280-b6e9-f5e6c8ad1a56.pkl.
INFO:__main__:Saving c7c58713-7888-4ebd-af22-bfcb7a616dfe to disk...
INFO:__main__:Model dumped into ../results/models/model_c7c58713-7888-4ebd-af22-bfcb7a616dfe.pkl.
INFO:__main__:By filtering the best eval_metric, we select the only model 43277782-ab16-4d66-830a-aa394e6273f4, with eval_metric: 48.0
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
INFO:__main__:X_test: (5, 11)
INFO:__main__:Model: 43277782-ab16-4d66-830a-aa394e6273f4, model_name: random_forest, metric: 48.0
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
INFO:__main__:X_test: (5, 11)
INFO:__main__:Model: 02a8bbee-19f9-4280-b6e9-f5e6c8ad1a56, model_name: random_forest, metric: 48.0
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
INFO:__main__:X_test: (5, 11)
INFO:__main__:Model: c7c58713-7888-4ebd-af22-bfcb7a616dfe, model_name: random_forest, metric: 48.0
INFO:__main__:Prediction finished!!!
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 2
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 11), y: (1530,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.394484, total=   0.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.147422, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.112713, total=   0.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.383875, total=   1.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.107836, total=   2.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.147082, total=   2.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.108792, total=   3.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.375465, total=   2.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.146583, total=   4.2s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.9s remaining:    3.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    2.8s remaining:    1.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    4.7s finished
INFO:__main__:It takes 246.51 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: d05c2abb-a2b5-45ec-b73d-9d4796cbc87c,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 56.00000000000001using 472.81 seconds
INFO:__main__:




impute_method: slinear

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
INFO:__main__:X_train: (1530, 11), y: (1530,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.088512, total=   0.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.310264, total=   0.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.127180, total=   0.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.322302, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.089984, total=   1.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.128156, total=   2.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.323961, total=   2.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.085193, total=   2.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.128290, total=   3.4s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.7s remaining:    2.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    2.3s remaining:    1.1s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    3.9s finished
INFO:__main__:It takes 225.15 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1573: RuntimeWarning: overflow encountered in multiply
  tol = S.max(axis=-1, keepdims=True) * max(M.shape[-2:]) * finfo(S.dtype).eps
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1458: RuntimeWarning: overflow encountered in square
  eigvals = self._wexog_singular_values ** 2
/opt/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: divide by zero encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: b62e5ca5-0c83-4e21-af61-4122ecda467c,model_name: random_forest, impute_method: slinear, model_selector: hard_threshold_10, eval_metric: 44.0using 433.94 seconds
INFO:__main__:




impute_method: cubic

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 11), y: (1530,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.394484, total=   0.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.112713, total=   0.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.147422, total=   0.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.383875, total=   1.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.107836, total=   1.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.147082, total=   2.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.375465, total=   2.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.108792, total=   3.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.146583, total=   3.9s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.8s remaining:    2.8s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    2.6s remaining:    1.3s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    4.4s finished
INFO:__main__:It takes 228.80 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: e93bf204-a8bf-47f1-8b6b-db097c4495b0,model_name: random_forest, impute_method: cubic, model_selector: hard_threshold_10, eval_metric: 56.00000000000001using 452.00 seconds
INFO:__main__:




impute_method: zero

INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_train: (1530, 11), y: (1530,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.394484, total=   0.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.112713, total=   0.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.147422, total=   0.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.383875, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.107836, total=   1.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.147082, total=   2.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.375465, total=   2.9s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.8s remaining:    2.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    2.6s remaining:    1.3s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    4.3s finished
INFO:__main__:It takes 233.26 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 642a8324-585e-4434-82e1-dcbab3dfd55a,model_name: random_forest, impute_method: zero, model_selector: hard_threshold_10, eval_metric: 56.00000000000001using 455.23 seconds
INFO:__main__:We have run 5 models, using 1813.99 seconds
INFO:__main__:Saving d05c2abb-a2b5-45ec-b73d-9d4796cbc87c to disk...
INFO:__main__:Model dumped into ../results/models/model_d05c2abb-a2b5-45ec-b73d-9d4796cbc87c.pkl.
INFO:__main__:Saving e93bf204-a8bf-47f1-8b6b-db097c4495b0 to disk...
INFO:__main__:Model dumped into ../results/models/model_e93bf204-a8bf-47f1-8b6b-db097c4495b0.pkl.
INFO:__main__:By filtering the best eval_metric, we select the only model d05c2abb-a2b5-45ec-b73d-9d4796cbc87c, with eval_metric: 56.00000000000001
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
INFO:__main__:X_test: (5, 11)
INFO:__main__:Model: d05c2abb-a2b5-45ec-b73d-9d4796cbc87c, model_name: random_forest, metric: 56.00000000000001
INFO:feature_selecting.hard_thresholding:There are in total 628 columns, while we only need 10 columns
INFO:__main__:X_test: (5, 11)
INFO:__main__:Model: e93bf204-a8bf-47f1-8b6b-db097c4495b0, model_name: random_forest, metric: 56.00000000000001
INFO:__main__:Prediction finished!!!
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222'
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222'
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222'
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222'
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222'
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222'
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222'
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222'
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222.xls'
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222.xls'
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222.xls'
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222.xls'
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222.xls'
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222.xls'
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222.xls'
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
Traceback (most recent call last):
  File "train_test_utils.py", line 383, in <module>
    raw_data_url=os.path.join("./../data/data_live/", args.data_path)
  File "./../data_processing/excel_to_dataframe.py", line 21, in data_to_dataframe
    data = pd.read_excel(self.raw_data_url, index_col='指标名称')
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 200, in read_excel
    io = ExcelFile(io, engine=engine)
  File "/opt/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py", line 257, in __init__
    self.book = xlrd.open_workbook(io)
  File "/opt/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py", line 395, in open_workbook
    with open(filename, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: './../data/data_live/20171222.xls'
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 7
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 8
Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 221, in search_regression_ml
    "xgboost": XGBRegressor(),
NameError: name 'XGBRegressor' is not defined
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 5
Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 221, in search_regression_ml
    "xgboost": XGBRegressor(),
NameError: name 'XGBRegressor' is not defined
Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 221, in search_regression_ml
    "xgboost": XGBRegressor(),
NameError: name 'XGBRegressor' is not defined
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 2
Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 221, in search_regression_ml
    "xgboost": XGBRegressor(),
NameError: name 'XGBRegressor' is not defined
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 1
Traceback (most recent call last):
  File "train_test_utils.py", line 403, in <module>
    split_date=datetime.datetime.strptime(args.split_date, "%Y%m%d").date(),
  File "/opt/anaconda3/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/opt/anaconda3/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data 'raw_data_20171222.xls' does not match format '%Y%m%d'
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 3
Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 221, in search_regression_ml
    "xgboost": XGBRegressor(),
NameError: name 'XGBRegressor' is not defined
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 6
Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 221, in search_regression_ml
    "xgboost": XGBRegressor(),
NameError: name 'XGBRegressor' is not defined
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 4
Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 221, in search_regression_ml
    "xgboost": XGBRegressor(),
NameError: name 'XGBRegressor' is not defined
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 2
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 7
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 3
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 6
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 5
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 8
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 4
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 1
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

Traceback (most recent call last):
  File "train_test_utils.py", line 403, in <module>
    split_date=datetime.datetime.strptime(args.split_date, "%Y%m%d").date(),
  File "/opt/anaconda3/lib/python3.6/_strptime.py", line 565, in _strptime_datetime
    tt, fraction = _strptime(data_string, format)
  File "/opt/anaconda3/lib/python3.6/_strptime.py", line 362, in _strptime
    (data_string, format))
ValueError: time data 'raw_data_20171222.xls' does not match format '%Y%m%d'
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.390356, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.517589, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-9.867802, total=   0.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-9.820324, total=   2.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.539123, total=   3.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.387432, total=   3.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-9.744940, total=   4.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.382976, total=   5.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.535701, total=   5.1s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.1s remaining:    4.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.0s remaining:    2.0s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    6.3s finished
INFO:__main__:It takes 1434.12 seconds to train this model.
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.765477, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.505959, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.369488, total=   1.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.744416, total=   2.5s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.2s remaining:    4.3s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.2s remaining:    2.1s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.0s finished
INFO:__main__:It takes 1444.83 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 11), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-9.362794, total=   0.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.909992, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.337492, total=   1.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-9.433011, total=   2.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.924401, total=   3.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.334703, total=   3.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-9.291427, total=   4.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.187962, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.741772, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.219520, total=   1.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.735062, total=   2.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.188141, total=   3.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.219205, total=   4.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.735305, total=   5.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.191517, total=   6.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.221783, total=   7.1s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.705216, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.260681, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.289847, total=   1.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.713500, total=   3.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.290990, total=   3.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.268720, total=   4.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.720072, total=   5.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.270005, total=   7.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.295841, total=   6.1s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.6s remaining:    5.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.8s remaining:    2.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.2s finished
INFO:__main__:It takes 1468.88 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.4s remaining:    5.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.0s remaining:    2.0s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.6s finished
INFO:__main__:It takes 1469.59 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.6s remaining:    5.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.0s remaining:    2.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.8s finished
INFO:__main__:It takes 1471.19 seconds to train this model.
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.516638, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.096447, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.139024, total=   1.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.536235, total=   2.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.104791, total=   3.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.136444, total=   3.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.530202, total=   4.4s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 11), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.3s remaining:    4.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.1s remaining:    2.0s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    6.6s finished
INFO:__main__:It takes 1475.87 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.904976, total=   0.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.304251, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.313990, total=   1.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.893156, total=   2.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.300949, total=   2.8s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.0s remaining:    3.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    3.3s remaining:    1.7s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    6.0s finished
INFO:__main__:It takes 1488.48 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 57bd642c-d9e0-4e0b-bc27-29e8862b01c9,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 6.896551724137931using 2829.70 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: dc88334c-f24a-4a54-8817-4f2b0e44ab4a,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 3.571428571428571using 2833.80 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 7fa0d28b-c22c-4aca-919c-7c9fe60c710d,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 32.0using 2847.16 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: e61c0b4e-4a2f-4296-a03a-2e110baf0ceb,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 45.83333333333333using 2852.79 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 5d4dcdfd-b48e-4d90-8ef8-38959b42b5c9,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 10.0using 2853.94 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: e4563b67-8522-48bd-9e3f-39e672d9ab20,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 24.0using 2876.42 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 7d6f4ad7-c0aa-482c-a78f-73a9cb75dad1,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 8.0using 2880.01 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-2.350621, total=   3.6s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-2.297087, total=   3.5s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-2.257528, total=   3.9s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.770216, total=   3.9s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.873347, total=   4.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.759497, total=   4.4s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.796308, total=   4.7s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.901389, total=   4.6s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.905338, total=   4.8s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.818428, total=   5.4s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.277774, total=   6.6s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.453735, total=   7.2s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.833527, total=  10.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.7s remaining:   24.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.8s remaining:    4.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   12.6s finished
INFO:__main__:It takes 1318.64 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[11:25:51] dmlc-core/include/dmlc/logging.h:235: [11:25:51] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[11:25:51] dmlc-core/include/dmlc/logging.h:235: [11:25:51] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[11:25:51] dmlc-core/include/dmlc/logging.h:235: [11:25:51] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.661485, total=   2.5s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-4.792111, total=   2.6s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.260814, total=   2.8s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.703776, total=   2.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.554401, total=   3.2s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.232785, total=   3.7s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.618508, total=   4.3s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.888856, total=   5.5s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.276391, total=   7.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.261597, total=   9.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.7s remaining:   17.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.6s remaining:    4.9s
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 344, in __call__
    return self.func(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 238, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 270, in fit
    self._final_estimator.fit(Xt, y, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py", line 251, in fit
    verbose_eval=verbose)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 205, in train
    xgb_model=xgb_model, callbacks=callbacks)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 76, in _train_internal
    bst.update(dtrain, i, obj)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 806, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 127, in _check_call
    raise XGBoostError(_LIB.XGBGetLastError())
xgboost.core.XGBoostError: b'[11:25:51] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 353, in __call__
    raise TransportableException(text, e_type)
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 11:25:51 2017
PID: 85763                          Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]]), array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.01, 'model__max_depth': 4, 'model__min_child_weight': 6, 'model__subsample': 0.6}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]]), array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.01, 'model__max_depth': 4, 'model__min_child_weight': 6, 'model__subsample': 0.6})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]]), y=array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.01, 'model__max_depth': 4, 'model__min_child_weight': 6, 'model__subsample': 0.6}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.6))])>
        X_train = array([[  4.51900000e+00,   1.50829073e+00,   2....586000e+00,   1.66501703e+15,   6.82070000e+00]])
        y_train = array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.51900000e+00,   1.50829073e+00,   2....586000e+00,   1.66501703e+15,   6.82070000e+00]]), y=array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.6)>
        Xt = array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  1.        ,
         1.        ,  0.83722479]])
        y = array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.6), X=array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  1.        ,
         1.        ,  0.83722479]]), y=array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.01, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 6, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.01, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 6, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(47351312)
        iteration = 0
        dtrain.handle = c_void_p(32702448)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[11:25:51] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 682, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 608, in get
    raise self._value
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 11:25:51 2017
PID: 85763                          Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]]), array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.01, 'model__max_depth': 4, 'model__min_child_weight': 6, 'model__subsample': 0.6}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]]), array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.01, 'model__max_depth': 4, 'model__min_child_weight': 6, 'model__subsample': 0.6})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]]), y=array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.01, 'model__max_depth': 4, 'model__min_child_weight': 6, 'model__subsample': 0.6}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.6))])>
        X_train = array([[  4.51900000e+00,   1.50829073e+00,   2....586000e+00,   1.66501703e+15,   6.82070000e+00]])
        y_train = array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.51900000e+00,   1.50829073e+00,   2....586000e+00,   1.66501703e+15,   6.82070000e+00]]), y=array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.6)>
        Xt = array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  1.        ,
         1.        ,  0.83722479]])
        y = array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.6), X=array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  1.        ,
         1.        ,  0.83722479]]), y=array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.01, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 6, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.01, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 6, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(47351312)
        iteration = 0
        dtrain.handle = c_void_p(32702448)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[11:25:51] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 280, in search_regression_ml
    pipeline_param_grid=pipeline_param_grid
  File "train_test_utils.py", line 133, in train
    pipeline_2.fit(X_train, y_train)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 1190, in fit
    return self._fit(X, y, groups, sampled_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 564, in _fit
    for parameters in parameter_iterable
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 768, in __call__
    self.retrieve()
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 719, in retrieve
    raise exception
sklearn.externals.joblib.my_exceptions.JoblibXGBoostError: JoblibXGBoostError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in <module>()
    399         search_regression_ml(
    400             data=data.copy(),
    401             save_k_best=args.save_k_best,
    402             look_ahead_day=args.look_forward_days,
    403             split_date=datetime.datetime.strptime(args.split_date, "%Y%m%d").date(),
--> 404             validation_period_length=args.validation_period_length
    405         )
    406 
    407     # set the model results path
    408     results_path = os.path.join("./../results/model_history/", "regression_results_" + str(args.look_forward_days) + ".csv")

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in search_regression_ml(data=                 x1          x2         x3      ...NaN      NaN  3.0297  

[2183 rows x 105 columns], save_k_best=1, look_ahead_day=6, split_date=datetime.date(2017, 12, 15), validation_period_length=60)
    275                         reducer=PCA(n_components=10),  # temporarily not in use
    276                         model=model_dict[model_name],
    277                         X=data.copy(),
    278                         split_date=split_date - datetime.timedelta(days=validation_period_length),
    279                         pipeline_mode=model_pipeline_mode_dict[model_name],
--> 280                         pipeline_param_grid=pipeline_param_grid
        pipeline_param_grid = {'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]}
    281                     )
    282                     model_id = str(uuid.uuid4())
    283                     y_test_predict = test(
    284                         data.copy(),

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in train(imputer=ImputationMethod(method='directly'), engineer=FeatureExtract(changerate=True, diff=True, ind=[...
        look_forward_days=6, ma=[1, 2, 3, 4, 5]), selector=HardThresholdSelector(alpha=0.05, date_column='d...
           select_top_k=True, target_column='y'), scaler=MinMaxScaler(copy=True, feature_range=(0, 1)), reducer=PCA(copy=True, iterated_power='auto', n_componen...None,
  svd_solver='auto', tol=0.0, whiten=False), model=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), X=               x59   x59_log  x59_ind_2      x2_...16  3.0346     2.9860  

[1505 rows x 12 columns], split_date=datetime.date(2017, 10, 16), pipeline_mode='random', pipeline_param_grid={'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]})
    128         search_pipeline=pipeline_2,
    129         pipeline_mode=pipeline_mode,
    130         param_grid=pipeline_param_grid
    131     )
    132 
--> 133     pipeline_2.fit(X_train, y_train)
        pipeline_2.fit = <bound method RandomizedSearchCV.fit of Randomiz...g='neg_mean_squared_error',
          verbose=3)>
        X_train = array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]])
        y_train = array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ])
    134     logger.info("It takes {:.2f} seconds to train this model.".format(time.time() - time_init))
    135     if pipeline_mode != "single":
    136         pipeline_2 = pipeline_2.best_estimator_
    137 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]]), y=array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ]), groups=None)
   1185             train/test set.
   1186         """
   1187         sampled_params = ParameterSampler(self.param_distributions,
   1188                                           self.n_iter,
   1189                                           random_state=self.random_state)
-> 1190         return self._fit(X, y, groups, sampled_params)
        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...g='neg_mean_squared_error',
          verbose=3)>
        X = array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]])
        y = array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ])
        groups = None
        sampled_params = <sklearn.model_selection._search.ParameterSampler object>
   1191 
   1192 
   1193 
   1194 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]]), y=array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
XGBoostError                                       Tue Dec 26 11:25:51 2017
PID: 85763                          Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]]), array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.01, 'model__max_depth': 4, 'model__min_child_weight': 6, 'model__subsample': 0.6}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]]), array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.01, 'model__max_depth': 4, 'model__min_child_weight': 6, 'model__subsample': 0.6})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.51900000e+00,   1.50829073e+00,   2....434000e+00,   2.10999086e+16,   3.03460000e+00]]), y=array([ 7.1468,  7.7249,  5.9792, ...,  3.0742,  2.9898,  2.986 ]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.01, 'model__max_depth': 4, 'model__min_child_weight': 6, 'model__subsample': 0.6}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.6))])>
        X_train = array([[  4.51900000e+00,   1.50829073e+00,   2....586000e+00,   1.66501703e+15,   6.82070000e+00]])
        y_train = array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.51900000e+00,   1.50829073e+00,   2....586000e+00,   1.66501703e+15,   6.82070000e+00]]), y=array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.6)>
        Xt = array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  1.        ,
         1.        ,  0.83722479]])
        y = array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.6), X=array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  1.        ,
         1.        ,  0.83722479]]), y=array([  7.1468,   7.7249,   5.9792,   5.0065,  ...11.6217,   9.2485,   7.5326,   7.4369,   7.2877]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.01, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 6, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.01, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 6, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(47351312)
        iteration = 0
        dtrain.handle = c_void_p(32702448)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[11:25:51] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.342988, total=   2.4s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.281625, total=   2.7s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.711567, total=   2.9s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.525857, total=   3.1s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-1.206752, total=   3.4s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-6.696766, total=   3.9s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.322450, total=   5.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-7.079949, total=   5.3s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.949260, total=   5.5s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.810438, total=   6.1s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.829197, total=   6.1s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.398528, total=   6.2s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.791786, total=   6.3s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.624220, total=   6.4s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.9s remaining:   18.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.4s remaining:    4.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    6.5s finished
INFO:__main__:It takes 1336.22 seconds to train this model.
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.576435, total=   3.4s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.113053, total=   3.6s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-2.027409, total=   3.5s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.892851, total=   3.9s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.870028, total=   4.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.539011, total=   4.7s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.174745, total=   5.0s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.863898, total=   5.1s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.125237, total=   5.0s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.832057, total=   5.0s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.893359, total=   5.4s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.891496, total=   5.5s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.888576, total=   5.6s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.185840, total=   5.7s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.872568, total=   6.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.7s remaining:   24.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.2s remaining:    4.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    6.5s finished
INFO:__main__:It takes 1354.83 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.080536, total=   2.9s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.371080, total=   3.1s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.097476, total=   3.0s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.823339, total=   3.0s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.887427, total=   3.4s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.115744, total=   3.6s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.876973, total=   3.5s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.118370, total=   3.7s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.694477, total=   3.6s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.419593, total=   3.8s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.944038, total=   4.1s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.824552, total=   4.3s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.861575, total=   4.3s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.860733, total=   5.8s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.1s remaining:   20.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    3.8s remaining:    3.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    5.9s finished
INFO:__main__:It takes 1363.55 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 11), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[11:27:01] dmlc-core/include/dmlc/logging.h:235: [11:27:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[11:27:01] dmlc-core/include/dmlc/logging.h:235: [11:27:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[11:27:01] dmlc-core/include/dmlc/logging.h:235: [11:27:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.616520, total=   2.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.213406, total=   3.3s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.252013, total=   3.5s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-2.125548, total=   3.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.828669, total=   5.6s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.889125, total=   5.9s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.215885, total=   8.6s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.250173, total=   8.8s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.763032, total=   9.3s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.715138, total=  10.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.4s remaining:   22.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.8s remaining:    7.7s
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 344, in __call__
    return self.func(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 238, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 270, in fit
    self._final_estimator.fit(Xt, y, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py", line 251, in fit
    verbose_eval=verbose)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 205, in train
    xgb_model=xgb_model, callbacks=callbacks)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 76, in _train_internal
    bst.update(dtrain, i, obj)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 806, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 127, in _check_call
    raise XGBoostError(_LIB.XGBGetLastError())
xgboost.core.XGBoostError: b'[11:27:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 353, in __call__
    raise TransportableException(text, e_type)
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 11:27:01 2017
PID: 88698                          Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]]), array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...68, 369, 370, 371, 372, 373, 374, 375, 376, 377]), array([378, 379, 380, 381, 382, 383, 384, 385, 3...45, 746, 747, 748, 749, 750, 751, 752, 753, 754]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 8, 'model__subsample': 0.7}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]]), array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...68, 369, 370, 371, 372, 373, 374, 375, 376, 377]), array([378, 379, 380, 381, 382, 383, 384, 385, 3...45, 746, 747, 748, 749, 750, 751, 752, 753, 754]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 8, 'model__subsample': 0.7})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]]), y=array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...68, 369, 370, 371, 372, 373, 374, 375, 376, 377]), test=array([378, 379, 380, 381, 382, 383, 384, 385, 3...45, 746, 747, 748, 749, 750, 751, 752, 753, 754]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 8, 'model__subsample': 0.7}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.7))])>
        X_train = array([[  2.12700000e-01,   4.51900000e+00,   2....130000e+00,   7.93720000e+00,   8.26240000e+00]])
        y_train = array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  2.12700000e-01,   4.51900000e+00,   2....130000e+00,   7.93720000e+00,   8.26240000e+00]]), y=array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.7)>
        Xt = array([[ 0.59778395,  0.38556234,  0.24721315, ....  0.92917236,
         0.84702843,  1.        ]])
        y = array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.7), X=array([[ 0.59778395,  0.38556234,  0.24721315, ....  0.92917236,
         0.84702843,  1.        ]]), y=array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(51002976)
        iteration = 0
        dtrain.handle = c_void_p(49204336)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[11:27:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 682, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 608, in get
    raise self._value
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 11:27:01 2017
PID: 88698                          Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]]), array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...68, 369, 370, 371, 372, 373, 374, 375, 376, 377]), array([378, 379, 380, 381, 382, 383, 384, 385, 3...45, 746, 747, 748, 749, 750, 751, 752, 753, 754]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 8, 'model__subsample': 0.7}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]]), array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...68, 369, 370, 371, 372, 373, 374, 375, 376, 377]), array([378, 379, 380, 381, 382, 383, 384, 385, 3...45, 746, 747, 748, 749, 750, 751, 752, 753, 754]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 8, 'model__subsample': 0.7})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]]), y=array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...68, 369, 370, 371, 372, 373, 374, 375, 376, 377]), test=array([378, 379, 380, 381, 382, 383, 384, 385, 3...45, 746, 747, 748, 749, 750, 751, 752, 753, 754]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 8, 'model__subsample': 0.7}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.7))])>
        X_train = array([[  2.12700000e-01,   4.51900000e+00,   2....130000e+00,   7.93720000e+00,   8.26240000e+00]])
        y_train = array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  2.12700000e-01,   4.51900000e+00,   2....130000e+00,   7.93720000e+00,   8.26240000e+00]]), y=array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.7)>
        Xt = array([[ 0.59778395,  0.38556234,  0.24721315, ....  0.92917236,
         0.84702843,  1.        ]])
        y = array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.7), X=array([[ 0.59778395,  0.38556234,  0.24721315, ....  0.92917236,
         0.84702843,  1.        ]]), y=array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(51002976)
        iteration = 0
        dtrain.handle = c_void_p(49204336)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[11:27:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 280, in search_regression_ml
    pipeline_param_grid=pipeline_param_grid
  File "train_test_utils.py", line 133, in train
    pipeline_2.fit(X_train, y_train)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 1190, in fit
    return self._fit(X, y, groups, sampled_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 564, in _fit
    for parameters in parameter_iterable
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 768, in __call__
    self.retrieve()
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 719, in retrieve
    raise exception
sklearn.externals.joblib.my_exceptions.JoblibXGBoostError: JoblibXGBoostError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in <module>()
    399         search_regression_ml(
    400             data=data.copy(),
    401             save_k_best=args.save_k_best,
    402             look_ahead_day=args.look_forward_days,
    403             split_date=datetime.datetime.strptime(args.split_date, "%Y%m%d").date(),
--> 404             validation_period_length=args.validation_period_length
    405         )
    406 
    407     # set the model results path
    408     results_path = os.path.join("./../results/model_history/", "regression_results_" + str(args.look_forward_days) + ".csv")

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in search_regression_ml(data=                 x1          x2         x3      ...NaN      NaN  3.0297  

[2183 rows x 105 columns], save_k_best=1, look_ahead_day=4, split_date=datetime.date(2017, 12, 19), validation_period_length=60)
    275                         reducer=PCA(n_components=10),  # temporarily not in use
    276                         model=model_dict[model_name],
    277                         X=data.copy(),
    278                         split_date=split_date - datetime.timedelta(days=validation_period_length),
    279                         pipeline_mode=model_pipeline_mode_dict[model_name],
--> 280                         pipeline_param_grid=pipeline_param_grid
        pipeline_param_grid = {'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]}
    281                     )
    282                     model_id = str(uuid.uuid4())
    283                     y_test_predict = test(
    284                         data.copy(),

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in train(imputer=ImputationMethod(method='directly'), engineer=FeatureExtract(changerate=True, diff=True, ind=[...
        look_forward_days=4, ma=[1, 2, 3, 4, 5]), selector=HardThresholdSelector(alpha=0.05, date_column='d...
           select_top_k=True, target_column='y'), scaler=MinMaxScaler(copy=True, feature_range=(0, 1)), reducer=PCA(copy=True, iterated_power='auto', n_componen...None,
  svd_solver='auto', tol=0.0, whiten=False), model=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), X=            x59_diff     x59  x59_ind_2  x59_ma_...64  3.0742     3.5654  

[1509 rows x 12 columns], split_date=datetime.date(2017, 10, 20), pipeline_mode='random', pipeline_param_grid={'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]})
    128         search_pipeline=pipeline_2,
    129         pipeline_mode=pipeline_mode,
    130         param_grid=pipeline_param_grid
    131     )
    132 
--> 133     pipeline_2.fit(X_train, y_train)
        pipeline_2.fit = <bound method RandomizedSearchCV.fit of Randomiz...g='neg_mean_squared_error',
          verbose=3)>
        X_train = array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]])
        y_train = array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654])
    134     logger.info("It takes {:.2f} seconds to train this model.".format(time.time() - time_init))
    135     if pipeline_mode != "single":
    136         pipeline_2 = pipeline_2.best_estimator_
    137 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]]), y=array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654]), groups=None)
   1185             train/test set.
   1186         """
   1187         sampled_params = ParameterSampler(self.param_distributions,
   1188                                           self.n_iter,
   1189                                           random_state=self.random_state)
-> 1190         return self._fit(X, y, groups, sampled_params)
        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...g='neg_mean_squared_error',
          verbose=3)>
        X = array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]])
        y = array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654])
        groups = None
        sampled_params = <sklearn.model_selection._search.ParameterSampler object>
   1191 
   1192 
   1193 
   1194 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]]), y=array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
XGBoostError                                       Tue Dec 26 11:27:01 2017
PID: 88698                          Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]]), array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...68, 369, 370, 371, 372, 373, 374, 375, 376, 377]), array([378, 379, 380, 381, 382, 383, 384, 385, 3...45, 746, 747, 748, 749, 750, 751, 752, 753, 754]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 8, 'model__subsample': 0.7}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]]), array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...68, 369, 370, 371, 372, 373, 374, 375, 376, 377]), array([378, 379, 380, 381, 382, 383, 384, 385, 3...45, 746, 747, 748, 749, 750, 751, 752, 753, 754]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 8, 'model__subsample': 0.7})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  0.2127    ,   4.519     ,  20.421361  ...2.7396    ,
          4.1564    ,   3.0742    ]]), y=array([ 4.8975,  6.1644,  7.1468, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...68, 369, 370, 371, 372, 373, 374, 375, 376, 377]), test=array([378, 379, 380, 381, 382, 383, 384, 385, 3...45, 746, 747, 748, 749, 750, 751, 752, 753, 754]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 8, 'model__subsample': 0.7}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.7))])>
        X_train = array([[  2.12700000e-01,   4.51900000e+00,   2....130000e+00,   7.93720000e+00,   8.26240000e+00]])
        y_train = array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  2.12700000e-01,   4.51900000e+00,   2....130000e+00,   7.93720000e+00,   8.26240000e+00]]), y=array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.7)>
        Xt = array([[ 0.59778395,  0.38556234,  0.24721315, ....  0.92917236,
         0.84702843,  1.        ]])
        y = array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.7), X=array([[ 0.59778395,  0.38556234,  0.24721315, ....  0.92917236,
         0.84702843,  1.        ]]), y=array([  4.8975,   6.1644,   7.1468,   7.7249,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(51002976)
        iteration = 0
        dtrain.handle = c_void_p(49204336)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[11:27:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 11), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.794408, total=   3.1s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-2.251767, total=   3.4s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.826057, total=   3.4s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-2.229722, total=   3.7s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.907383, total=   3.8s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.905828, total=   3.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.242861, total=   3.8s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.239056, total=   3.8s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.768528, total=   3.9s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.225562, total=   3.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.261683, total=   4.0s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-2.307004, total=   4.2s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.859679, total=   4.4s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.895324, total=   4.7s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.4s remaining:   22.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.0s remaining:    3.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    5.1s finished
INFO:__main__:It takes 1402.95 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: c0eca5dc-6164-428b-9b1a-a6d0908c0ed4,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 17.24137931034483using 2473.91 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: 7c26f2e3-d939-452a-ba8f-d1fe04a9e283,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 24.0using 2504.45 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: 28737a0a-6b6e-483f-ba96-d1b74ec94c4c,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 0.0using 2500.39 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: 23521a99-2881-4501-896e-9ea3695d7e96,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 33.33333333333333using 2512.97 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: ae04fb27-0dad-40b9-9dac-7f0bce63528b,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 16.0using 2533.18 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.977577, total=   0.1s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.323253, total=   0.1s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-1.004967, total=   0.2s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.310388, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-1.004934, total=   0.2s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.309039, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-1.004934, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-1.005284, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.309172, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.309037, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.230569, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.230499, total=   0.1s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.230588, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.230592, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.230592, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.2s remaining:    1.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.3s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1117.30 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.322758, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.107998, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.323774, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.101480, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.323773, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.157847, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.101481, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.323762, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.101538, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.323664, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.158684, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.158685, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.158666, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.3s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1120.28 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-2.297674, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] ............. model__alpha=0.001, score=-16.584129, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-3.081659, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............. model__alpha=1e-06, score=-28.286399, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.519036, total=   0.0s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-3.082287, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............. model__alpha=1e-09, score=-28.304504, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.565985, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.567178, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-1.816731, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.440207, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.537980, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-3.082225, total=   0.1s
[CV] model__alpha=1e-07 ..............................................
[CV] ............. model__alpha=1e-07, score=-28.302709, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.567060, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.3s finished
INFO:__main__:It takes 1127.99 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.220702, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.049681, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.220675, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.049699, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.220704, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.108635, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.108626, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.219393, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.093466, total=   0.0s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.220705, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.104611, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.049679, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.049679, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.108636, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.108636, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1136.91 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 11), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.272001, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.500745, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.205746, total=   0.0s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.725194, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.725412, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.684908, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.253698, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.211343, total=   0.0s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.254416, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.725196, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.206088, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.206093, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.254410, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.205600, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.206093, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished
INFO:__main__:It takes 1136.52 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: 11de0fa2-4fcc-47b5-a9a5-bbdaa1c21023,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 10.344827586206897using 2238.17 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: 2d71ad8b-d384-43fb-9eb7-bffe1853a29d,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 24.0using 2251.84 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: 593b65ee-b69b-471e-bf53-e11705eb4a91,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 6.666666666666667using 2255.00 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: 4d7dd8e9-22eb-4116-9fca-bdecc8fd28c0,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 29.166666666666668using 2249.28 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: c4d49855-e9d1-48b3-b20f-6d647d348725,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 20.0using 2284.88 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.4s remaining:    4.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.6s remaining:    2.3s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.4s finished
INFO:__main__:It takes 1120.11 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.586327, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.179345, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.219182, total=   1.2s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.3s remaining:    4.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.4s remaining:    2.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.7s finished
INFO:__main__:It takes 1125.35 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-8.695883, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.150507, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.321461, total=   1.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-8.851927, total=   2.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.603966, total=   0.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.106597, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.129795, total=   1.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.604966, total=   2.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.102737, total=   3.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.128733, total=   4.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.581294, total=   5.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.103884, total=   6.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.128792, total=   7.4s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.2s remaining:    4.1s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.3s remaining:    2.1s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.6s finished
INFO:__main__:It takes 1139.71 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.4s remaining:    4.8s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.5s remaining:    2.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.0s finished
INFO:__main__:It takes 1136.96 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 21), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.168370, total=   0.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.506366, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.330271, total=   1.1s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.1s remaining:    3.9s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.9s remaining:    2.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.6s finished
INFO:__main__:It takes 1155.93 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: e1a472be-72af-4a07-b194-cfb3105b124a,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 13.793103448275861using 2232.45 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 8d8c47c4-4647-48fb-8ba6-638501429a03,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 24.0using 2250.63 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 5da7f149-832a-49c6-b252-ddcf8e194cc6,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 25.0using 2250.92 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: f8520445-35e8-4567-a19d-d1d7a3ac8d5d,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 16.666666666666664using 2261.63 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 02539a0f-2279-4892-928f-ff8b03ac1cec,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 12.0using 2297.83 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[13:18:01] dmlc-core/include/dmlc/logging.h:235: [13:18:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:18:01] dmlc-core/include/dmlc/logging.h:235: [13:18:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:18:01] dmlc-core/include/dmlc/logging.h:235: [13:18:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:18:01] dmlc-core/include/dmlc/logging.h:235: [13:18:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:18:01] dmlc-core/include/dmlc/logging.h:235: [13:18:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:18:01] dmlc-core/include/dmlc/logging.h:235: [13:18:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.702180, total=   2.6s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.812657, total=   3.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.851016, total=   3.9s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.891407, total=   4.9s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.7s remaining:   23.8s
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 344, in __call__
    return self.func(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 238, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 270, in fit
    self._final_estimator.fit(Xt, y, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py", line 251, in fit
    verbose_eval=verbose)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 205, in train
    xgb_model=xgb_model, callbacks=callbacks)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 76, in _train_internal
    bst.update(dtrain, i, obj)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 806, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 127, in _check_call
    raise XGBoostError(_LIB.XGBGetLastError())
xgboost.core.XGBoostError: b'[13:18:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 353, in __call__
    raise TransportableException(text, e_type)
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 13:18:01 2017
PID: 102449                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]]), array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 2, 'model__subsample': 0.8}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]]), array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 2, 'model__subsample': 0.8})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]]), y=array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 2, 'model__subsample': 0.8}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.8))])>
        X_train = array([[  2.12700000e-01,   4.51900000e+00,   2....920000e+00,   7.30995000e+00,   6.82070000e+00]])
        y_train = array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[  2.12700000e-01,   4.51900000e+00,   2....920000e+00,   7.30995000e+00,   6.82070000e+00]]), y=array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.8)>
        Xt = array([[ 0.59778395,  0.4228699 ,  0.28586209, ....  0.61607363,
         0.76011464,  0.83722479]])
        y = array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.8), X=array([[ 0.59778395,  0.4228699 ,  0.28586209, ....  0.61607363,
         0.76011464,  0.83722479]]), y=array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(43008224)
        iteration = 0
        dtrain.handle = c_void_p(45051264)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:18:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 682, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 608, in get
    raise self._value
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 13:18:01 2017
PID: 102449                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]]), array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 2, 'model__subsample': 0.8}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]]), array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 2, 'model__subsample': 0.8})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]]), y=array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 2, 'model__subsample': 0.8}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.8))])>
        X_train = array([[  2.12700000e-01,   4.51900000e+00,   2....920000e+00,   7.30995000e+00,   6.82070000e+00]])
        y_train = array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[  2.12700000e-01,   4.51900000e+00,   2....920000e+00,   7.30995000e+00,   6.82070000e+00]]), y=array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.8)>
        Xt = array([[ 0.59778395,  0.4228699 ,  0.28586209, ....  0.61607363,
         0.76011464,  0.83722479]])
        y = array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.8), X=array([[ 0.59778395,  0.4228699 ,  0.28586209, ....  0.61607363,
         0.76011464,  0.83722479]]), y=array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(43008224)
        iteration = 0
        dtrain.handle = c_void_p(45051264)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:18:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 280, in search_regression_ml
    pipeline_param_grid=pipeline_param_grid
  File "train_test_utils.py", line 133, in train
    pipeline_2.fit(X_train, y_train)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 1190, in fit
    return self._fit(X, y, groups, sampled_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 564, in _fit
    for parameters in parameter_iterable
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 768, in __call__
    self.retrieve()
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 719, in retrieve
    raise exception
sklearn.externals.joblib.my_exceptions.JoblibXGBoostError: JoblibXGBoostError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in <module>()
    399         search_regression_ml(
    400             data=data.copy(),
    401             save_k_best=args.save_k_best,
    402             look_ahead_day=args.look_forward_days,
    403             split_date=datetime.datetime.strptime(args.split_date, "%Y%m%d").date(),
--> 404             validation_period_length=args.validation_period_length
    405         )
    406 
    407     # set the model results path
    408     results_path = os.path.join("./../results/model_history/", "regression_results_" + str(args.look_forward_days) + ".csv")

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in search_regression_ml(data=                 x1          x2         x3      ...NaN      NaN  3.0297  

[2183 rows x 105 columns], save_k_best=1, look_ahead_day=7, split_date=datetime.date(2017, 12, 14), validation_period_length=60)
    275                         reducer=PCA(n_components=10),  # temporarily not in use
    276                         model=model_dict[model_name],
    277                         X=data.copy(),
    278                         split_date=split_date - datetime.timedelta(days=validation_period_length),
    279                         pipeline_mode=model_pipeline_mode_dict[model_name],
--> 280                         pipeline_param_grid=pipeline_param_grid
        pipeline_param_grid = {'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]}
    281                     )
    282                     model_id = str(uuid.uuid4())
    283                     y_test_predict = test(
    284                         data.copy(),

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in train(imputer=ImputationMethod(method='directly'), engineer=FeatureExtract(changerate=True, diff=True, ind=[...
        look_forward_days=7, ma=[1, 2, 3, 4, 5]), selector=HardThresholdSelector(alpha=0.05, date_column='d...
           select_top_k=True, target_column='y'), scaler=MinMaxScaler(copy=True, feature_range=(0, 1)), reducer=PCA(copy=True, iterated_power='auto', n_componen...None,
  svd_solver='auto', tol=0.0, whiten=False), model=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), X=            x59_diff     x59  x59_ind_2  x59_ma_...2017-10-13     3.1493  

[1505 rows x 22 columns], split_date=datetime.date(2017, 10, 15), pipeline_mode='random', pipeline_param_grid={'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]})
    128         search_pipeline=pipeline_2,
    129         pipeline_mode=pipeline_mode,
    130         param_grid=pipeline_param_grid
    131     )
    132 
--> 133     pipeline_2.fit(X_train, y_train)
        pipeline_2.fit = <bound method RandomizedSearchCV.fit of Randomiz...g='neg_mean_squared_error',
          verbose=3)>
        X_train = array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]])
        y_train = array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493])
    134     logger.info("It takes {:.2f} seconds to train this model.".format(time.time() - time_init))
    135     if pipeline_mode != "single":
    136         pipeline_2 = pipeline_2.best_estimator_
    137 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]]), y=array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493]), groups=None)
   1185             train/test set.
   1186         """
   1187         sampled_params = ParameterSampler(self.param_distributions,
   1188                                           self.n_iter,
   1189                                           random_state=self.random_state)
-> 1190         return self._fit(X, y, groups, sampled_params)
        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...g='neg_mean_squared_error',
          verbose=3)>
        X = array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]])
        y = array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493])
        groups = None
        sampled_params = <sklearn.model_selection._search.ParameterSampler object>
   1191 
   1192 
   1193 
   1194 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]]), y=array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
XGBoostError                                       Tue Dec 26 13:18:01 2017
PID: 102449                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]]), array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 2, 'model__subsample': 0.8}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]]), array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 2, 'model__subsample': 0.8})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[  0.2127    ,   4.519     ,  20.421361  ...4.8085    ,
          4.6425    ,   3.0346    ]]), y=array([ 7.7249,  5.9792,  5.0065, ...,  2.9898,  2.986 ,  3.1493]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 2, 'model__subsample': 0.8}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.8))])>
        X_train = array([[  2.12700000e-01,   4.51900000e+00,   2....920000e+00,   7.30995000e+00,   6.82070000e+00]])
        y_train = array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[  2.12700000e-01,   4.51900000e+00,   2....920000e+00,   7.30995000e+00,   6.82070000e+00]]), y=array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.8)>
        Xt = array([[ 0.59778395,  0.4228699 ,  0.28586209, ....  0.61607363,
         0.76011464,  0.83722479]])
        y = array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.8), X=array([[ 0.59778395,  0.4228699 ,  0.28586209, ....  0.61607363,
         0.76011464,  0.83722479]]), y=array([  7.7249,   5.9792,   5.0065,   5.0065,  ... 9.2485,   7.5326,   7.4369,   7.2877,   6.7369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(43008224)
        iteration = 0
        dtrain.handle = c_void_p(45051264)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:18:01] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[13:19:26] dmlc-core/include/dmlc/logging.h:235: [13:19:26] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:19:26] dmlc-core/include/dmlc/logging.h:235: [13:19:26] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:19:26] dmlc-core/include/dmlc/logging.h:235: [13:19:26] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.544578, total=   4.6s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.879012, total=   5.3s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.900043, total=   5.3s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.166547, total=   7.5s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.579577, total=   7.7s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.176440, total=   8.8s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.500033, total=   8.9s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.198060, total=   9.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.538314, total=   9.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.187762, total=  10.7s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.4s remaining:   35.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    9.1s remaining:    8.0s
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 344, in __call__
    return self.func(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 238, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 270, in fit
    self._final_estimator.fit(Xt, y, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py", line 251, in fit
    verbose_eval=verbose)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 205, in train
    xgb_model=xgb_model, callbacks=callbacks)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 76, in _train_internal
    bst.update(dtrain, i, obj)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 806, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 127, in _check_call
    raise XGBoostError(_LIB.XGBGetLastError())
xgboost.core.XGBoostError: b'[13:19:26] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 353, in __call__
    raise TransportableException(text, e_type)
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 13:19:26 2017
PID: 103115                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]]), array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 2, 'model__subsample': 0.6}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]]), array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 2, 'model__subsample': 0.6})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]]), y=array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), test=array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 2, 'model__subsample': 0.6}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.6))])>
        X_train = array([[  4.51900000e+00,   2.12700000e-01,   2....820000e+00,   7.69120000e+00,   1.16217000e+01]])
        y_train = array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.51900000e+00,   2.12700000e-01,   2....820000e+00,   7.69120000e+00,   1.16217000e+01]]), y=array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.6)>
        Xt = array([[ 0.24852672,  0.3836239 ,  0.12053592, ....  0.7191155 ,
         0.8241978 ,  1.        ]])
        y = array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.6), X=array([[ 0.24852672,  0.3836239 ,  0.12053592, ....  0.7191155 ,
         0.8241978 ,  1.        ]]), y=array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(36090000)
        iteration = 0
        dtrain.handle = c_void_p(41069584)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:19:26] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 682, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 608, in get
    raise self._value
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 13:19:26 2017
PID: 103115                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]]), array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 2, 'model__subsample': 0.6}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]]), array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 2, 'model__subsample': 0.6})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]]), y=array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), test=array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 2, 'model__subsample': 0.6}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.6))])>
        X_train = array([[  4.51900000e+00,   2.12700000e-01,   2....820000e+00,   7.69120000e+00,   1.16217000e+01]])
        y_train = array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.51900000e+00,   2.12700000e-01,   2....820000e+00,   7.69120000e+00,   1.16217000e+01]]), y=array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.6)>
        Xt = array([[ 0.24852672,  0.3836239 ,  0.12053592, ....  0.7191155 ,
         0.8241978 ,  1.        ]])
        y = array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.6), X=array([[ 0.24852672,  0.3836239 ,  0.12053592, ....  0.7191155 ,
         0.8241978 ,  1.        ]]), y=array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(36090000)
        iteration = 0
        dtrain.handle = c_void_p(41069584)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:19:26] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 280, in search_regression_ml
    pipeline_param_grid=pipeline_param_grid
  File "train_test_utils.py", line 133, in train
    pipeline_2.fit(X_train, y_train)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 1190, in fit
    return self._fit(X, y, groups, sampled_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 564, in _fit
    for parameters in parameter_iterable
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 768, in __call__
    self.retrieve()
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 719, in retrieve
    raise exception
sklearn.externals.joblib.my_exceptions.JoblibXGBoostError: JoblibXGBoostError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in <module>()
    399         search_regression_ml(
    400             data=data.copy(),
    401             save_k_best=args.save_k_best,
    402             look_ahead_day=args.look_forward_days,
    403             split_date=datetime.datetime.strptime(args.split_date, "%Y%m%d").date(),
--> 404             validation_period_length=args.validation_period_length
    405         )
    406 
    407     # set the model results path
    408     results_path = os.path.join("./../results/model_history/", "regression_results_" + str(args.look_forward_days) + ".csv")

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in search_regression_ml(data=                 x1          x2         x3      ...NaN      NaN  3.0297  

[2183 rows x 105 columns], save_k_best=1, look_ahead_day=3, split_date=datetime.date(2017, 12, 20), validation_period_length=60)
    275                         reducer=PCA(n_components=10),  # temporarily not in use
    276                         model=model_dict[model_name],
    277                         X=data.copy(),
    278                         split_date=split_date - datetime.timedelta(days=validation_period_length),
    279                         pipeline_mode=model_pipeline_mode_dict[model_name],
--> 280                         pipeline_param_grid=pipeline_param_grid
        pipeline_param_grid = {'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]}
    281                     )
    282                     model_id = str(uuid.uuid4())
    283                     y_test_predict = test(
    284                         data.copy(),

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in train(imputer=ImputationMethod(method='directly'), engineer=FeatureExtract(changerate=True, diff=True, ind=[...
        look_forward_days=3, ma=[1, 2, 3, 4, 5]), selector=HardThresholdSelector(alpha=0.05, date_column='d...
           select_top_k=True, target_column='y'), scaler=MinMaxScaler(copy=True, feature_range=(0, 1)), reducer=PCA(copy=True, iterated_power='auto', n_componen...None,
  svd_solver='auto', tol=0.0, whiten=False), model=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), X=               x59  x59_diff  x59_ind_2  x59_ma_...2017-10-20     3.5654  

[1510 rows x 22 columns], split_date=datetime.date(2017, 10, 21), pipeline_mode='random', pipeline_param_grid={'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]})
    128         search_pipeline=pipeline_2,
    129         pipeline_mode=pipeline_mode,
    130         param_grid=pipeline_param_grid
    131     )
    132 
--> 133     pipeline_2.fit(X_train, y_train)
        pipeline_2.fit = <bound method RandomizedSearchCV.fit of Randomiz...g='neg_mean_squared_error',
          verbose=3)>
        X_train = array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]])
        y_train = array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654])
    134     logger.info("It takes {:.2f} seconds to train this model.".format(time.time() - time_init))
    135     if pipeline_mode != "single":
    136         pipeline_2 = pipeline_2.best_estimator_
    137 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]]), y=array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654]), groups=None)
   1185             train/test set.
   1186         """
   1187         sampled_params = ParameterSampler(self.param_distributions,
   1188                                           self.n_iter,
   1189                                           random_state=self.random_state)
-> 1190         return self._fit(X, y, groups, sampled_params)
        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...g='neg_mean_squared_error',
          verbose=3)>
        X = array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]])
        y = array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654])
        groups = None
        sampled_params = <sklearn.model_selection._search.ParameterSampler object>
   1191 
   1192 
   1193 
   1194 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]]), y=array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
XGBoostError                                       Tue Dec 26 13:19:26 2017
PID: 103115                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]]), array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 2, 'model__subsample': 0.6}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]]), array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 2, 'model__subsample': 0.6})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.519     ,   0.2127    ,  20.421361  ...4.9516    ,
          4.2943    ,   2.9898    ]]), y=array([ 4.1816,  4.8975,  6.1644, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), test=array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 2, 'model__subsample': 0.6}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.6))])>
        X_train = array([[  4.51900000e+00,   2.12700000e-01,   2....820000e+00,   7.69120000e+00,   1.16217000e+01]])
        y_train = array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.6))]), X=array([[  4.51900000e+00,   2.12700000e-01,   2....820000e+00,   7.69120000e+00,   1.16217000e+01]]), y=array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.6)>
        Xt = array([[ 0.24852672,  0.3836239 ,  0.12053592, ....  0.7191155 ,
         0.8241978 ,  1.        ]])
        y = array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.6), X=array([[ 0.24852672,  0.3836239 ,  0.12053592, ....  0.7191155 ,
         0.8241978 ,  1.        ]]), y=array([  4.1816,   4.8975,   6.1644,   7.1468,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 2, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(36090000)
        iteration = 0
        dtrain.handle = c_void_p(41069584)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:19:26] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.615369, total=   3.7s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.538351, total=   3.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.608558, total=   4.2s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.358801, total=   4.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.125329, total=   4.3s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.840306, total=   4.5s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.852566, total=   4.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.888881, total=   4.7s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.856792, total=   4.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.876364, total=   4.8s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.884684, total=   5.0s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.098042, total=   5.3s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.119029, total=   7.8s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.412436, total=   8.6s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.0s remaining:   26.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.8s remaining:    4.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   11.1s finished
INFO:__main__:It takes 1139.04 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[13:19:59] dmlc-core/include/dmlc/logging.h:235: [13:19:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:19:59] dmlc-core/include/dmlc/logging.h:235: [13:19:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:19:59] dmlc-core/include/dmlc/logging.h:235: [13:19:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:19:59] dmlc-core/include/dmlc/logging.h:235: [13:19:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:19:59] dmlc-core/include/dmlc/logging.h:235: [13:19:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:19:59] dmlc-core/include/dmlc/logging.h:235: [13:19:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-5.929913, total=   4.2s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.244821, total=   5.2s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.725074, total=   5.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.4s remaining:   34.8s
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 344, in __call__
    return self.func(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 238, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 270, in fit
    self._final_estimator.fit(Xt, y, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py", line 251, in fit
    verbose_eval=verbose)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 205, in train
    xgb_model=xgb_model, callbacks=callbacks)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 76, in _train_internal
    bst.update(dtrain, i, obj)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 806, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 127, in _check_call
    raise XGBoostError(_LIB.XGBGetLastError())
xgboost.core.XGBoostError: b'[13:19:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 353, in __call__
    raise TransportableException(text, e_type)
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 13:19:59 2017
PID: 104379                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]]), array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 4, 'model__subsample': 0.9}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]]), array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 4, 'model__subsample': 0.9})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), X=array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]]), y=array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 4, 'model__subsample': 0.9}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.9))])>
        X_train = array([[  4.519     ,   1.50829073,  20.421361  ...6.7627    ,
         45.73411129,   6.8207    ]])
        y_train = array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), X=array([[  4.519     ,   1.50829073,  20.421361  ...6.7627    ,
         45.73411129,   6.8207    ]]), y=array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.9)>
        Xt = array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  0.47634043,
         0.32503117,  0.83722479]])
        y = array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.9), X=array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  0.47634043,
         0.32503117,  0.83722479]]), y=array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(41177600)
        iteration = 0
        dtrain.handle = c_void_p(46182224)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:19:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 682, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 608, in get
    raise self._value
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 13:19:59 2017
PID: 104379                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]]), array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 4, 'model__subsample': 0.9}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]]), array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 4, 'model__subsample': 0.9})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), X=array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]]), y=array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 4, 'model__subsample': 0.9}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.9))])>
        X_train = array([[  4.519     ,   1.50829073,  20.421361  ...6.7627    ,
         45.73411129,   6.8207    ]])
        y_train = array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), X=array([[  4.519     ,   1.50829073,  20.421361  ...6.7627    ,
         45.73411129,   6.8207    ]]), y=array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.9)>
        Xt = array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  0.47634043,
         0.32503117,  0.83722479]])
        y = array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.9), X=array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  0.47634043,
         0.32503117,  0.83722479]]), y=array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(41177600)
        iteration = 0
        dtrain.handle = c_void_p(46182224)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:19:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 280, in search_regression_ml
    pipeline_param_grid=pipeline_param_grid
  File "train_test_utils.py", line 133, in train
    pipeline_2.fit(X_train, y_train)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 1190, in fit
    return self._fit(X, y, groups, sampled_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 564, in _fit
    for parameters in parameter_iterable
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 768, in __call__
    self.retrieve()
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 719, in retrieve
    raise exception
sklearn.externals.joblib.my_exceptions.JoblibXGBoostError: JoblibXGBoostError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in <module>()
    399         search_regression_ml(
    400             data=data.copy(),
    401             save_k_best=args.save_k_best,
    402             look_ahead_day=args.look_forward_days,
    403             split_date=datetime.datetime.strptime(args.split_date, "%Y%m%d").date(),
--> 404             validation_period_length=args.validation_period_length
    405         )
    406 
    407     # set the model results path
    408     results_path = os.path.join("./../results/model_history/", "regression_results_" + str(args.look_forward_days) + ".csv")

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in search_regression_ml(data=                 x1          x2         x3      ...NaN      NaN  3.0297  

[2183 rows x 105 columns], save_k_best=1, look_ahead_day=8, split_date=datetime.date(2017, 12, 13), validation_period_length=60)
    275                         reducer=PCA(n_components=10),  # temporarily not in use
    276                         model=model_dict[model_name],
    277                         X=data.copy(),
    278                         split_date=split_date - datetime.timedelta(days=validation_period_length),
    279                         pipeline_mode=model_pipeline_mode_dict[model_name],
--> 280                         pipeline_param_grid=pipeline_param_grid
        pipeline_param_grid = {'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]}
    281                     )
    282                     model_id = str(uuid.uuid4())
    283                     y_test_predict = test(
    284                         data.copy(),

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in train(imputer=ImputationMethod(method='directly'), engineer=FeatureExtract(changerate=True, diff=True, ind=[...
        look_forward_days=8, ma=[1, 2, 3, 4, 5]), selector=HardThresholdSelector(alpha=0.05, date_column='d...
           select_top_k=True, target_column='y'), scaler=MinMaxScaler(copy=True, feature_range=(0, 1)), reducer=PCA(copy=True, iterated_power='auto', n_componen...None,
  svd_solver='auto', tol=0.0, whiten=False), model=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), X=               x59   x59_log  x59_ind_2      x2_...33  3.0346     3.5654  

[1505 rows x 22 columns], split_date=datetime.date(2017, 10, 14), pipeline_mode='random', pipeline_param_grid={'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]})
    128         search_pipeline=pipeline_2,
    129         pipeline_mode=pipeline_mode,
    130         param_grid=pipeline_param_grid
    131     )
    132 
--> 133     pipeline_2.fit(X_train, y_train)
        pipeline_2.fit = <bound method RandomizedSearchCV.fit of Randomiz...g='neg_mean_squared_error',
          verbose=3)>
        X_train = array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]])
        y_train = array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654])
    134     logger.info("It takes {:.2f} seconds to train this model.".format(time.time() - time_init))
    135     if pipeline_mode != "single":
    136         pipeline_2 = pipeline_2.best_estimator_
    137 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]]), y=array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654]), groups=None)
   1185             train/test set.
   1186         """
   1187         sampled_params = ParameterSampler(self.param_distributions,
   1188                                           self.n_iter,
   1189                                           random_state=self.random_state)
-> 1190         return self._fit(X, y, groups, sampled_params)
        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...g='neg_mean_squared_error',
          verbose=3)>
        X = array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]])
        y = array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654])
        groups = None
        sampled_params = <sklearn.model_selection._search.ParameterSampler object>
   1191 
   1192 
   1193 
   1194 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]]), y=array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
XGBoostError                                       Tue Dec 26 13:19:59 2017
PID: 104379                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]]), array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 4, 'model__subsample': 0.9}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]]), array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 4, 'model__subsample': 0.9})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), X=array([[  4.519     ,   1.50829073,  20.421361  ...4.3139    ,
         18.60973321,   3.0346    ]]), y=array([ 5.9792,  5.0065,  5.0065, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...43, 744, 745, 746, 747, 748, 749, 750, 751, 752]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 4, 'model__subsample': 0.9}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.9))])>
        X_train = array([[  4.519     ,   1.50829073,  20.421361  ...6.7627    ,
         45.73411129,   6.8207    ]])
        y_train = array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.9))]), X=array([[  4.519     ,   1.50829073,  20.421361  ...6.7627    ,
         45.73411129,   6.8207    ]]), y=array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.9)>
        Xt = array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  0.47634043,
         0.32503117,  0.83722479]])
        y = array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.9), X=array([[ 0.4228699 ,  0.5777357 ,  0.28586209, ....  0.47634043,
         0.32503117,  0.83722479]]), y=array([  5.9792,   5.0065,   5.0065,   5.0065,  ... 7.5326,   7.4369,   7.2877,   6.7369,   6.1622]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(41177600)
        iteration = 0
        dtrain.handle = c_void_p(46182224)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:19:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 21), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[13:21:59] dmlc-core/include/dmlc/logging.h:235: [13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:21:59] dmlc-core/include/dmlc/logging.h:235: [13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:21:59] dmlc-core/include/dmlc/logging.h:235: [13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:21:59] dmlc-core/include/dmlc/logging.h:235: [13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:21:59] dmlc-core/include/dmlc/logging.h:235: [13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:21:59] dmlc-core/include/dmlc/logging.h:235: [13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:21:59] dmlc-core/include/dmlc/logging.h:235: [13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:21:59] dmlc-core/include/dmlc/logging.h:235: [13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[13:21:59] dmlc-core/include/dmlc/logging.h:235: [13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.891621, total=   4.2s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.645220, total=   4.5s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.6s remaining:   29.9s
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 344, in __call__
    return self.func(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 238, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 270, in fit
    self._final_estimator.fit(Xt, y, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py", line 251, in fit
    verbose_eval=verbose)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 205, in train
    xgb_model=xgb_model, callbacks=callbacks)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 76, in _train_internal
    bst.update(dtrain, i, obj)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 806, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 127, in _check_call
    raise XGBoostError(_LIB.XGBGetLastError())
xgboost.core.XGBoostError: b'[13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 353, in __call__
    raise TransportableException(text, e_type)
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 13:21:59 2017
PID: 105114                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]]), array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...44, 745, 746, 747, 748, 749, 750, 751, 752, 753]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 4, 'model__subsample': 0.8}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]]), array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...44, 745, 746, 747, 748, 749, 750, 751, 752, 753]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 4, 'model__subsample': 0.8})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]]), y=array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...44, 745, 746, 747, 748, 749, 750, 751, 752, 753]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 4, 'model__subsample': 0.8}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.8))])>
        X_train = array([[ 0.2127    ,  4.519     ,  1.50829073, ....  5.77      ,
         5.9992    ,  6.8207    ]])
        y_train = array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[ 0.2127    ,  4.519     ,  1.50829073, ....  5.77      ,
         5.9992    ,  6.8207    ]]), y=array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.8)>
        Xt = array([[ 0.59778395,  0.4228699 ,  0.5777357 , ....  0.52129501,
         0.61607363,  0.83722479]])
        y = array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.8), X=array([[ 0.59778395,  0.4228699 ,  0.5777357 , ....  0.52129501,
         0.61607363,  0.83722479]]), y=array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(37970896)
        iteration = 0
        dtrain.handle = c_void_p(30977680)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 682, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 608, in get
    raise self._value
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 13:21:59 2017
PID: 105114                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]]), array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...44, 745, 746, 747, 748, 749, 750, 751, 752, 753]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 4, 'model__subsample': 0.8}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]]), array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...44, 745, 746, 747, 748, 749, 750, 751, 752, 753]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 4, 'model__subsample': 0.8})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]]), y=array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...44, 745, 746, 747, 748, 749, 750, 751, 752, 753]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 4, 'model__subsample': 0.8}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.8))])>
        X_train = array([[ 0.2127    ,  4.519     ,  1.50829073, ....  5.77      ,
         5.9992    ,  6.8207    ]])
        y_train = array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[ 0.2127    ,  4.519     ,  1.50829073, ....  5.77      ,
         5.9992    ,  6.8207    ]]), y=array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.8)>
        Xt = array([[ 0.59778395,  0.4228699 ,  0.5777357 , ....  0.52129501,
         0.61607363,  0.83722479]])
        y = array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.8), X=array([[ 0.59778395,  0.4228699 ,  0.5777357 , ....  0.52129501,
         0.61607363,  0.83722479]]), y=array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(37970896)
        iteration = 0
        dtrain.handle = c_void_p(30977680)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 280, in search_regression_ml
    pipeline_param_grid=pipeline_param_grid
  File "train_test_utils.py", line 133, in train
    pipeline_2.fit(X_train, y_train)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 1190, in fit
    return self._fit(X, y, groups, sampled_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 564, in _fit
    for parameters in parameter_iterable
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 768, in __call__
    self.retrieve()
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 719, in retrieve
    raise exception
sklearn.externals.joblib.my_exceptions.JoblibXGBoostError: JoblibXGBoostError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in <module>()
    399         search_regression_ml(
    400             data=data.copy(),
    401             save_k_best=args.save_k_best,
    402             look_ahead_day=args.look_forward_days,
    403             split_date=datetime.datetime.strptime(args.split_date, "%Y%m%d").date(),
--> 404             validation_period_length=args.validation_period_length
    405         )
    406 
    407     # set the model results path
    408     results_path = os.path.join("./../results/model_history/", "regression_results_" + str(args.look_forward_days) + ".csv")

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in search_regression_ml(data=                 x1          x2         x3      ...NaN      NaN  3.0297  

[2183 rows x 105 columns], save_k_best=1, look_ahead_day=5, split_date=datetime.date(2017, 12, 18), validation_period_length=60)
    275                         reducer=PCA(n_components=10),  # temporarily not in use
    276                         model=model_dict[model_name],
    277                         X=data.copy(),
    278                         split_date=split_date - datetime.timedelta(days=validation_period_length),
    279                         pipeline_mode=model_pipeline_mode_dict[model_name],
--> 280                         pipeline_param_grid=pipeline_param_grid
        pipeline_param_grid = {'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]}
    281                     )
    282                     model_id = str(uuid.uuid4())
    283                     y_test_predict = test(
    284                         data.copy(),

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in train(imputer=ImputationMethod(method='directly'), engineer=FeatureExtract(changerate=True, diff=True, ind=[...
        look_forward_days=5, ma=[1, 2, 3, 4, 5]), selector=HardThresholdSelector(alpha=0.05, date_column='d...
           select_top_k=True, target_column='y'), scaler=MinMaxScaler(copy=True, feature_range=(0, 1)), reducer=PCA(copy=True, iterated_power='auto', n_componen...None,
  svd_solver='auto', tol=0.0, whiten=False), model=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), X=            x59_diff     x59   x59_log  x59_ind_...2017-10-18     3.5654  

[1508 rows x 22 columns], split_date=datetime.date(2017, 10, 19), pipeline_mode='random', pipeline_param_grid={'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]})
    128         search_pipeline=pipeline_2,
    129         pipeline_mode=pipeline_mode,
    130         param_grid=pipeline_param_grid
    131     )
    132 
--> 133     pipeline_2.fit(X_train, y_train)
        pipeline_2.fit = <bound method RandomizedSearchCV.fit of Randomiz...g='neg_mean_squared_error',
          verbose=3)>
        X_train = array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]])
        y_train = array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654])
    134     logger.info("It takes {:.2f} seconds to train this model.".format(time.time() - time_init))
    135     if pipeline_mode != "single":
    136         pipeline_2 = pipeline_2.best_estimator_
    137 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]]), y=array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654]), groups=None)
   1185             train/test set.
   1186         """
   1187         sampled_params = ParameterSampler(self.param_distributions,
   1188                                           self.n_iter,
   1189                                           random_state=self.random_state)
-> 1190         return self._fit(X, y, groups, sampled_params)
        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...g='neg_mean_squared_error',
          verbose=3)>
        X = array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]])
        y = array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654])
        groups = None
        sampled_params = <sklearn.model_selection._search.ParameterSampler object>
   1191 
   1192 
   1193 
   1194 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]]), y=array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
XGBoostError                                       Tue Dec 26 13:21:59 2017
PID: 105114                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]]), array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...44, 745, 746, 747, 748, 749, 750, 751, 752, 753]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 4, 'model__subsample': 0.8}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]]), array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), array([377, 378, 379, 380, 381, 382, 383, 384, 3...44, 745, 746, 747, 748, 749, 750, 751, 752, 753]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 4, 'model__subsample': 0.8})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[ 0.2127    ,  4.519     ,  1.50829073, ....  4.7475    ,
         4.5749    ,  3.1788    ]]), y=array([ 6.1644,  7.1468,  7.7249, ...,  2.986 ,  3.1493,  3.5654]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...67, 368, 369, 370, 371, 372, 373, 374, 375, 376]), test=array([377, 378, 379, 380, 381, 382, 383, 384, 3...44, 745, 746, 747, 748, 749, 750, 751, 752, 753]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 2, 'model__min_child_weight': 4, 'model__subsample': 0.8}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.8))])>
        X_train = array([[ 0.2127    ,  4.519     ,  1.50829073, ....  5.77      ,
         5.9992    ,  6.8207    ]])
        y_train = array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.8))]), X=array([[ 0.2127    ,  4.519     ,  1.50829073, ....  5.77      ,
         5.9992    ,  6.8207    ]]), y=array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.8)>
        Xt = array([[ 0.59778395,  0.4228699 ,  0.5777357 , ....  0.52129501,
         0.61607363,  0.83722479]])
        y = array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.8), X=array([[ 0.59778395,  0.4228699 ,  0.5777357 , ....  0.52129501,
         0.61607363,  0.83722479]]), y=array([  6.1644,   7.1468,   7.7249,   5.9792,  ... 8.2624,  11.6217,   9.2485,   7.5326,   7.4369]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 4, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(37970896)
        iteration = 0
        dtrain.handle = c_void_p(30977680)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[13:21:59] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 5, model_id: 90990fbc-9739-40fd-a76f-bf89e2ca447d,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 20.833333333333336using 1977.85 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.240379, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.239682, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.044096, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.232297, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.112881, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.138786, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.240450, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.117982, total=   0.0s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.240458, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.043833, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.112614, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.112908, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.044126, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.112911, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.044123, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.6s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 839.91 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 6, model_id: 1f1e2c08-5fd8-49e0-8a7d-fb6fdf0329ba,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 16.666666666666664using 1677.40 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.585239, total=   0.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.100943, total=   0.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.127081, total=   0.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.597749, total=   2.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.8s remaining:    2.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    3.8s remaining:    1.9s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    6.6s finished
INFO:__main__:It takes 853.46 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 7, model_id: 4efe2cab-f12d-4d2e-b20c-2eda2a7a7179,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 20.833333333333336using 1694.72 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[14:44:09] dmlc-core/include/dmlc/logging.h:235: [14:44:09] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[14:44:09] dmlc-core/include/dmlc/logging.h:235: [14:44:09] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[14:44:09] dmlc-core/include/dmlc/logging.h:235: [14:44:09] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[14:44:09] dmlc-core/include/dmlc/logging.h:235: [14:44:09] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[14:44:09] dmlc-core/include/dmlc/logging.h:235: [14:44:09] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[14:44:09] dmlc-core/include/dmlc/logging.h:235: [14:44:09] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.117849, total=   2.6s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.686631, total=   3.0s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.118221, total=   3.1s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0 
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.344923, total=   3.7s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0 
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.890484, total=   4.4s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.855252, total=   4.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.895760, total=   4.8s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.1s remaining:   20.3s
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 344, in __call__
    return self.func(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 238, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py", line 270, in fit
    self._final_estimator.fit(Xt, y, **fit_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py", line 251, in fit
    verbose_eval=verbose)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 205, in train
    xgb_model=xgb_model, callbacks=callbacks)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py", line 76, in _train_internal
    bst.update(dtrain, i, obj)
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 806, in update
    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
  File "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 127, in _check_call
    raise XGBoostError(_LIB.XGBGetLastError())
xgboost.core.XGBoostError: b'[14:44:09] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 353, in __call__
    raise TransportableException(text, e_type)
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 14:44:09 2017
PID: 110085                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]]), array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__min_child_weight': 8, 'model__subsample': 0.7}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]]), array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__min_child_weight': 8, 'model__subsample': 0.7})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]]), y=array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), test=array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__min_child_weight': 8, 'model__subsample': 0.7}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.7))])>
        X_train = array([[  2.12700000e-01,   4.51900000e+00,   2....150000e+00,   6.17276667e+00,   1.16217000e+01]])
        y_train = array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  2.12700000e-01,   4.51900000e+00,   2....150000e+00,   6.17276667e+00,   1.16217000e+01]]), y=array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.7)>
        Xt = array([[ 0.3836239 ,  0.24852672,  0.12053592, ....  0.691956  ,
         0.6521224 ,  1.        ]])
        y = array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.7), X=array([[ 0.3836239 ,  0.24852672,  0.12053592, ....  0.691956  ,
         0.6521224 ,  1.        ]]), y=array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(43751536)
        iteration = 0
        dtrain.handle = c_void_p(40541312)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[14:44:09] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 682, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/opt/anaconda3/lib/python3.6/multiprocessing/pool.py", line 608, in get
    raise self._value
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
XGBoostError                                       Tue Dec 26 14:44:09 2017
PID: 110085                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]]), array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__min_child_weight': 8, 'model__subsample': 0.7}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]]), array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__min_child_weight': 8, 'model__subsample': 0.7})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]]), y=array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), test=array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__min_child_weight': 8, 'model__subsample': 0.7}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.7))])>
        X_train = array([[  2.12700000e-01,   4.51900000e+00,   2....150000e+00,   6.17276667e+00,   1.16217000e+01]])
        y_train = array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  2.12700000e-01,   4.51900000e+00,   2....150000e+00,   6.17276667e+00,   1.16217000e+01]]), y=array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.7)>
        Xt = array([[ 0.3836239 ,  0.24852672,  0.12053592, ....  0.691956  ,
         0.6521224 ,  1.        ]])
        y = array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.7), X=array([[ 0.3836239 ,  0.24852672,  0.12053592, ....  0.691956  ,
         0.6521224 ,  1.        ]]), y=array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(43751536)
        iteration = 0
        dtrain.handle = c_void_p(40541312)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[14:44:09] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train_test_utils.py", line 404, in <module>
    validation_period_length=args.validation_period_length
  File "train_test_utils.py", line 280, in search_regression_ml
    pipeline_param_grid=pipeline_param_grid
  File "train_test_utils.py", line 133, in train
    pipeline_2.fit(X_train, y_train)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 1190, in fit
    return self._fit(X, y, groups, sampled_params)
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py", line 564, in _fit
    for parameters in parameter_iterable
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 768, in __call__
    self.retrieve()
  File "/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 719, in retrieve
    raise exception
sklearn.externals.joblib.my_exceptions.JoblibXGBoostError: JoblibXGBoostError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in <module>()
    399         search_regression_ml(
    400             data=data.copy(),
    401             save_k_best=args.save_k_best,
    402             look_ahead_day=args.look_forward_days,
    403             split_date=datetime.datetime.strptime(args.split_date, "%Y%m%d").date(),
--> 404             validation_period_length=args.validation_period_length
    405         )
    406 
    407     # set the model results path
    408     results_path = os.path.join("./../results/model_history/", "regression_results_" + str(args.look_forward_days) + ".csv")

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in search_regression_ml(data=                 x1          x2         x3      ...NaN      NaN  3.0297  

[2183 rows x 105 columns], save_k_best=1, look_ahead_day=2, split_date=datetime.date(2017, 12, 21), validation_period_length=60)
    275                         reducer=PCA(n_components=10),  # temporarily not in use
    276                         model=model_dict[model_name],
    277                         X=data.copy(),
    278                         split_date=split_date - datetime.timedelta(days=validation_period_length),
    279                         pipeline_mode=model_pipeline_mode_dict[model_name],
--> 280                         pipeline_param_grid=pipeline_param_grid
        pipeline_param_grid = {'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]}
    281                     )
    282                     model_id = str(uuid.uuid4())
    283                     y_test_predict = test(
    284                         data.copy(),

...........................................................................
/home/zhaoyi/code/repurchasing_in_production/train_test/train_test_utils.py in train(imputer=ImputationMethod(method='directly'), engineer=FeatureExtract(changerate=True, diff=True, ind=[...
        look_forward_days=2, ma=[1, 2, 3, 4, 5]), selector=HardThresholdSelector(alpha=0.05, date_column='d...
           select_top_k=True, target_column='y'), scaler=MinMaxScaler(copy=True, feature_range=(0, 1)), reducer=PCA(copy=True, iterated_power='auto', n_componen...None,
  svd_solver='auto', tol=0.0, whiten=False), model=XGBRegressor(base_score=0.5, colsample_bylevel=1...e_pos_weight=1, seed=0, silent=True, subsample=1), X=            x59_diff     x59  x59_ind_2  x59_ma_...20  2.9898     3.1493  

[1510 rows x 32 columns], split_date=datetime.date(2017, 10, 22), pipeline_mode='random', pipeline_param_grid={'model__colsample_bytree': [0, 0.1, 0.2, 0.3, 0.4, 0.5], 'model__learning_rate': [0.01, 0.1], 'model__max_depth': range(2, 12, 2), 'model__min_child_weight': range(2, 10, 2), 'model__subsample': [0.6, 0.7, 0.8, 0.9]})
    128         search_pipeline=pipeline_2,
    129         pipeline_mode=pipeline_mode,
    130         param_grid=pipeline_param_grid
    131     )
    132 
--> 133     pipeline_2.fit(X_train, y_train)
        pipeline_2.fit = <bound method RandomizedSearchCV.fit of Randomiz...g='neg_mean_squared_error',
          verbose=3)>
        X_train = array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]])
        y_train = array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493])
    134     logger.info("It takes {:.2f} seconds to train this model.".format(time.time() - time_init))
    135     if pipeline_mode != "single":
    136         pipeline_2 = pipeline_2.best_estimator_
    137 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]]), y=array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493]), groups=None)
   1185             train/test set.
   1186         """
   1187         sampled_params = ParameterSampler(self.param_distributions,
   1188                                           self.n_iter,
   1189                                           random_state=self.random_state)
-> 1190         return self._fit(X, y, groups, sampled_params)
        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...g='neg_mean_squared_error',
          verbose=3)>
        X = array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]])
        y = array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493])
        groups = None
        sampled_params = <sklearn.model_selection._search.ParameterSampler object>
   1191 
   1192 
   1193 
   1194 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=TimeSeriesSplit(n_splits=3...ng='neg_mean_squared_error',
          verbose=3), X=array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]]), y=array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)
    559                                   fit_params=self.fit_params,
    560                                   return_train_score=self.return_train_score,
    561                                   return_n_test_samples=True,
    562                                   return_times=True, return_parameters=True,
    563                                   error_score=self.error_score)
--> 564           for parameters in parameter_iterable
        parameters = undefined
        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>
    565           for train, test in cv_iter)
    566 
    567         # if one choose to see train score, "out" will contain train score info
    568         if self.return_train_score:

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)
    763             if pre_dispatch == "all" or n_jobs == 1:
    764                 # The iterable was consumed all at once by the above for loop.
    765                 # No need to wait for async callbacks to trigger to
    766                 # consumption.
    767                 self._iterating = False
--> 768             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    769             # Make sure that we get a last message telling us we are done
    770             elapsed_time = time.time() - self._start_time
    771             self._print('Done %3i out of %3i | elapsed: %s finished',
    772                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
XGBoostError                                       Tue Dec 26 14:44:09 2017
PID: 110085                         Python 3.6.1: /opt/anaconda3/bin/python
...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]]), array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__min_child_weight': 8, 'model__subsample': 0.7}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]]), array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493]), make_scorer(mean_squared_error, greater_is_better=False), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), 3, {'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__min_child_weight': 8, 'model__subsample': 0.7})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  0.2127    ,   4.519     ,  20.421361  ...4.2752    ,
          4.7509    ,   2.9898    ]]), y=array([ 3.9949,  4.1816,  4.8975, ...,  2.9898,  2.986 ,  3.1493]), scorer=make_scorer(mean_squared_error, greater_is_better=False), train=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 371, 372, 373, 374, 375, 376,
       377, 378]), test=array([379, 380, 381, 382, 383, 384, 385, 386, 3...46, 747, 748, 749, 750, 751, 752, 753, 754, 755]), verbose=3, parameters={'model__colsample_bytree': 0, 'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__min_child_weight': 8, 'model__subsample': 0.7}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')
    233 
    234     try:
    235         if y_train is None:
    236             estimator.fit(X_train, **fit_params)
    237         else:
--> 238             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...weight=1, seed=0, silent=True, subsample=0.7))])>
        X_train = array([[  2.12700000e-01,   4.51900000e+00,   2....150000e+00,   6.17276667e+00,   1.16217000e+01]])
        y_train = array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326])
        fit_params = {}
    239 
    240     except Exception as e:
    241         # Note fit time as time until error
    242         fit_time = time.time() - start_time

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaler', MinMaxScaler(copy=Tru..._weight=1, seed=0, silent=True, subsample=0.7))]), X=array([[  2.12700000e-01,   4.51900000e+00,   2....150000e+00,   6.17276667e+00,   1.16217000e+01]]), y=array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326]), **fit_params={})
    265         self : Pipeline
    266             This estimator
    267         """
    268         Xt, fit_params = self._fit(X, y, **fit_params)
    269         if self._final_estimator is not None:
--> 270             self._final_estimator.fit(Xt, y, **fit_params)
        self._final_estimator.fit = <bound method XGBModel.fit of XGBRegressor(base_...os_weight=1, seed=0, silent=True, subsample=0.7)>
        Xt = array([[ 0.3836239 ,  0.24852672,  0.12053592, ....  0.691956  ,
         0.6521224 ,  1.        ]])
        y = array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326])
        fit_params = {}
    271         return self
    272 
    273     def fit_transform(self, X, y=None, **fit_params):
    274         """Fit the model and transform with the final estimator

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py in fit(self=XGBRegressor(base_score=0.5, colsample_bylevel=1...pos_weight=1, seed=0, silent=True, subsample=0.7), X=array([[ 0.3836239 ,  0.24852672,  0.12053592, ....  0.691956  ,
         0.6521224 ,  1.        ]]), y=array([  3.9949,   4.1816,   4.8975,   6.1644,  ... 6.8207,   8.2624,  11.6217,   9.2485,   7.5326]), eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)
    246 
    247         self._Booster = train(params, trainDmatrix,
    248                               self.n_estimators, evals=evals,
    249                               early_stopping_rounds=early_stopping_rounds,
    250                               evals_result=evals_result, obj=obj, feval=feval,
--> 251                               verbose_eval=verbose)
        verbose = True
    252 
    253         if evals_result:
    254             for val in evals_result.items():
    255                 evals_result_key = list(val[1].keys())[0]

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in train(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result={}, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
    200 
    201     return _train_internal(params, dtrain,
    202                            num_boost_round=num_boost_round,
    203                            evals=evals,
    204                            obj=obj, feval=feval,
--> 205                            xgb_model=xgb_model, callbacks=callbacks)
        xgb_model = None
        callbacks = [<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>]
    206 
    207 
    208 class CVPack(object):
    209     """"Auxiliary datastruct to hold one fold of CV."""

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/training.py in _train_internal(params={'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 0, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 8, 'missing': nan, 'n_estimators': 100, ...}, dtrain=<xgboost.core.DMatrix object>, num_boost_round=100, evals=[], obj=None, feval=None, xgb_model=None, callbacks=[<function print_evaluation.<locals>.callback>, <function record_evaluation.<locals>.callback>])
     71                            rank=rank,
     72                            evaluation_result_list=None))
     73         # Distributed code: need to resume to this point.
     74         # Skip the first update if it is a recovery step.
     75         if version % 2 == 0:
---> 76             bst.update(dtrain, i, obj)
        bst.update = <bound method Booster.update of <xgboost.core.Booster object>>
        dtrain = <xgboost.core.DMatrix object>
        i = 0
        obj = None
     77             bst.save_rabit_checkpoint()
     78             version += 1
     79 
     80         assert(rabit.get_world_size() == 1 or version == rabit.version_number())

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in update(self=<xgboost.core.Booster object>, dtrain=<xgboost.core.DMatrix object>, iteration=0, fobj=None)
    801         if not isinstance(dtrain, DMatrix):
    802             raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))
    803         self._validate_features(dtrain)
    804 
    805         if fobj is None:
--> 806             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))
        self.handle = c_void_p(43751536)
        iteration = 0
        dtrain.handle = c_void_p(40541312)
    807         else:
    808             pred = self.predict(dtrain)
    809             grad, hess = fobj(pred, dtrain)
    810             self.boost(dtrain, grad, hess)

...........................................................................
/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py in _check_call(ret=-1)
    122     ----------
    123     ret : int
    124         return value from API calls
    125     """
    126     if ret != 0:
--> 127         raise XGBoostError(_LIB.XGBGetLastError())
    128 
    129 
    130 def ctypes2numpy(cptr, length, dtype):
    131     """Convert a ctypes pointer array to a numpy array.

XGBoostError: b'[14:44:09] src/tree/updater_colmaker.cc:161: Check failed: (n) > (0) colsample_bytree=0 is too small that no feature can be included'
___________________________________________________________________________
done
  File "train_test_utils.py", line 272
    pipeline = train(
                    ^
TabError: inconsistent use of tabs and spaces in indentation
  File "train_test_utils.py", line 272
    pipeline = train(
                    ^
TabError: inconsistent use of tabs and spaces in indentation
  File "train_test_utils.py", line 272
    pipeline = train(
                    ^
TabError: inconsistent use of tabs and spaces in indentation
  File "train_test_utils.py", line 272
    pipeline = train(
                    ^
TabError: inconsistent use of tabs and spaces in indentation
  File "train_test_utils.py", line 272
    pipeline = train(
                    ^
TabError: inconsistent use of tabs and spaces in indentation
  File "train_test_utils.py", line 272
    pipeline = train(
                    ^
TabError: inconsistent use of tabs and spaces in indentation
  File "train_test_utils.py", line 272
    pipeline = train(
                    ^
TabError: inconsistent use of tabs and spaces in indentation
  File "train_test_utils.py", line 272
    pipeline = train(
                    ^
TabError: inconsistent use of tabs and spaces in indentation
done
  File "train_test_utils.py", line 327
    time.time() - time_init
       ^
SyntaxError: invalid syntax
  File "train_test_utils.py", line 327
    time.time() - time_init
       ^
SyntaxError: invalid syntax
  File "train_test_utils.py", line 327
    time.time() - time_init
       ^
SyntaxError: invalid syntax
  File "train_test_utils.py", line 327
    time.time() - time_init
       ^
SyntaxError: invalid syntax
  File "train_test_utils.py", line 327
    time.time() - time_init
       ^
SyntaxError: invalid syntax
  File "train_test_utils.py", line 327
    time.time() - time_init
       ^
SyntaxError: invalid syntax
  File "train_test_utils.py", line 327
    time.time() - time_init
       ^
SyntaxError: invalid syntax
  File "train_test_utils.py", line 327
    time.time() - time_init
       ^
SyntaxError: invalid syntax
done
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 3
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 7
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 8
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 5
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 1
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 4
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 6
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/opt/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
INFO:__main__:Setting is_training to be true, we run grid search on look_forward_days to be 2
INFO:__main__:Tuning models, 20171226: 
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 11), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 11), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.705216, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.289847, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.260681, total=   1.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.713500, total=   2.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.290990, total=   3.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.268720, total=   3.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.720072, total=   6.4s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.6s remaining:    5.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.1s remaining:    2.1s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.0s finished
INFO:__main__:It takes 1305.60 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 11), y: (1510,)
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.904976, total=   0.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.313990, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.304251, total=   1.2s
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.195092, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.039935, total=   1.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.060982, total=   1.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.183753, total=   3.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.061720, total=   4.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.039199, total=   4.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.180070, total=   6.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.061650, total=   8.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.039463, total=   8.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.741772, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.187962, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.219520, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.735062, total=   3.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.219205, total=   5.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.188141, total=   4.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.735305, total=   6.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.191517, total=   8.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.221783, total=   8.6s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.0s remaining:    7.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.8s remaining:    2.9s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.2s finished
INFO:__main__:It takes 1314.24 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.4s remaining:    5.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.7s remaining:    2.3s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.0s finished
INFO:__main__:It takes 1317.49 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.516638, total=   0.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.096447, total=   0.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.139024, total=   0.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.536235, total=   2.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.104791, total=   2.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.136444, total=   3.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.104287, total=   7.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.530202, total=   4.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.135613, total=   8.2s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.0s remaining:    7.1s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.4s remaining:    2.7s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.0s finished
INFO:__main__:It takes 1318.29 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.0s remaining:    3.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    3.7s remaining:    1.8s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.7s finished
INFO:__main__:It takes 1318.52 seconds to train this model.
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-9.867802, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.390356, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.517589, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.765477, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.505959, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.369488, total=   1.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.744416, total=   2.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.363053, total=   3.8s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.5s remaining:    5.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.0s remaining:    2.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.6s finished
INFO:__main__:It takes 1325.60 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.5s remaining:    5.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.5s remaining:    2.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.4s finished
INFO:__main__:It takes 1326.59 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-9.362794, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.909992, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.337492, total=   0.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.334703, total=   3.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-9.433011, total=   2.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.924401, total=   2.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-9.291427, total=   3.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.335193, total=   5.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.916598, total=   4.7s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.0s remaining:    3.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    3.9s remaining:    1.9s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    6.2s finished
INFO:__main__:It takes 1332.61 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 8ff5020e-9b86-4565-b624-2a71e5c339d2,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 24.0using 2590.64 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 1b04f9f3-6f25-40dd-959b-8cd042570c80,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 32.0using 2593.57 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 1f05e10c-fdf6-4454-8cce-1a20b9943cd8,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 43.47826086956522using 2597.51 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 5d44635c-c143-4c58-bb9b-21522991f891,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 6.896551724137931using 2605.65 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: d917e4e8-458e-4db0-ba4b-2cf7808091e7,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 45.83333333333333using 2609.46 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: 69671f87-e337-46e6-9cb1-6e2415b27cbe,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 8.0using 2616.38 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: bcdcdbd4-379c-486e-a88b-8f37264872c6,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 3.571428571428571using 2621.03 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 1, model_id: dac33224-11f9-4ef5-b0a0-3d12a36db6ad,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 10.0using 2658.98 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.888721, total=   2.6s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.179067, total=   2.6s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.900911, total=   2.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.155883, total=   3.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.877632, total=   3.2s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.887945, total=   3.3s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.723498, total=   3.4s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.493031, total=   3.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.717430, total=   3.8s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.887120, total=   4.4s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.910044, total=   5.5s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.881420, total=   6.2s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 11), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.8s remaining:   18.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    3.7s remaining:    3.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    8.5s finished
INFO:__main__:It takes 1317.48 seconds to train this model.
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.734366, total=   3.6s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-2.037436, total=   3.7s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-2.121678, total=   3.8s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.888925, total=   4.3s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-2.082053, total=   4.4s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.207498, total=   4.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.622430, total=   4.8s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.844425, total=   5.2s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.211385, total=   5.2s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.828666, total=   5.3s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.889810, total=   5.3s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.251843, total=   6.2s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.891711, total=   6.5s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.726630, total=   8.0s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.8s remaining:   24.8s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.3s remaining:    4.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   10.3s finished
INFO:__main__:It takes 1335.51 seconds to train this model.
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.866837, total=   5.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.860340, total=   5.1s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.866914, total=   5.5s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.840349, total=   5.6s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.881499, total=   5.7s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.853615, total=   5.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.141166, total=   7.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.034495, total=   8.1s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.129321, total=   8.8s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.064765, total=   8.9s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.154868, total=   9.1s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.032937, total=   9.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.071265, total=   9.9s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.036202, total=  12.2s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.3s remaining:   34.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.3s remaining:    7.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.7s finished
INFO:__main__:It takes 1354.48 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.902006, total=   4.7s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.451709, total=   4.8s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.239251, total=   5.2s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.781583, total=   5.5s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.776303, total=   5.6s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.441983, total=   5.7s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.455305, total=   6.1s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.740843, total=   6.4s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.262858, total=   6.4s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-2.344609, total=   6.5s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.403214, total=   8.0s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.966350, total=   8.8s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.994978, total=  10.5s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.264628, total=  11.7s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.9s remaining:   32.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.5s remaining:    5.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.2s finished
INFO:__main__:It takes 1360.32 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.269617, total=   3.3s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.240269, total=   3.7s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.576761, total=   3.8s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.831917, total=   4.1s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.729132, total=   4.5s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-7.834909, total=   4.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.286250, total=   4.5s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.897421, total=   4.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.573848, total=   4.8s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.626340, total=   5.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.875807, total=   6.3s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-4.247434, total=   7.6s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.598084, total=   9.6s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.7s remaining:   24.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.9s remaining:    4.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   10.0s finished
INFO:__main__:It takes 1369.70 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 11), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.787429, total=   3.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.881555, total=   3.7s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.813213, total=   3.7s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.814718, total=   4.2s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.703636, total=   4.3s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.884442, total=   5.0s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.868147, total=   5.2s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.805761, total=   5.8s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.881079, total=   6.1s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.881377, total=   6.2s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.856705, total=   7.1s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.868230, total=   6.9s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.464131, total=  10.4s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.092824, total=  11.6s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.710326, total=   2.4s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.895013, total=   3.3s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-2.202138, total=   3.5s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.757993, total=   3.6s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-2.232228, total=   3.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.254473, total=   3.9s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.903500, total=   4.3s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.824232, total=   4.0s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.219073, total=   4.2s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.800227, total=   4.4s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-2.178991, total=   4.4s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.884866, total=   5.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.893385, total=   6.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.257897, total=  10.1s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.5s remaining:   22.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.4s remaining:    3.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   10.2s finished
INFO:__main__:It takes 1403.34 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.9s remaining:   25.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.8s remaining:    5.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   13.8s finished
INFO:__main__:It takes 1411.40 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.292103, total=   3.3s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.750949, total=   3.5s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.277689, total=   3.6s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-7.217888, total=   3.6s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-2.496272, total=   4.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.709094, total=   5.9s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-7.679660, total=   6.0s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-1.107006, total=   6.1s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.312308, total=   6.6s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.931492, total=   7.0s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-8.876629, total=  10.4s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-3.973388, total=  11.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.779586, total=  12.9s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.370376, total=  14.7s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.346690, total=  14.5s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.6s remaining:   23.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.3s remaining:    5.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.7s finished
INFO:__main__:It takes 1450.51 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: 35487c4f-3149-45d7-b98b-49a771244e8d,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 20.0using 2694.94 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: 416056c8-53a2-45e6-bd42-6dc9bd014f79,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 16.0using 2712.60 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: ad5e5ae4-8602-436c-bc89-14c1abc6afc8,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 34.78260869565217using 2711.71 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: 0bf93c36-45cb-47ee-b7f9-8fdd62b5eff0,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 10.344827586206897using 2713.63 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: 12f8dcb8-946b-484c-9cbf-675dd64559cf,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 0.0using 2716.86 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: 32ef0b27-0e22-4367-af02-e788a9883cba,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 20.0using 2729.64 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: ceee3076-b1e6-4659-8c75-28068cd7bb97,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 37.5using 2747.56 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 2, model_id: f9884fbc-d5b0-4aa5-9d50-0bc2cdeee7c0,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 10.0using 2781.49 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.328655, total=   0.4s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.167773, total=   0.4s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.323762, total=   0.3s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.151797, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.323773, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.323774, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.323664, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.101538, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.102052, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.101481, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.101480, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.158685, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.158684, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.4s remaining:    2.8s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.5s remaining:    0.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.5s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1314.01 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.096715, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.017152, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.096669, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.029072, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.094460, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.094403, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.052894, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.018252, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.055303, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.017157, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.055297, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.054731, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.096711, total=   0.1s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.017153, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.055302, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.4s finished
INFO:__main__:It takes 1300.48 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.323253, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.977577, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-1.004967, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-1.004934, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.309172, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.230499, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.309037, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-1.004934, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-1.005284, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.230588, total=   0.1s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.309039, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.310388, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.230592, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.230569, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.230592, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.0s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1293.87 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 11), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.162959, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.466360, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.171831, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.504738, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.243040, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.185526, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.514403, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.163034, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.179559, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.514878, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.184782, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.185528, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.514442, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.163789, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.3s finished
INFO:__main__:It takes 1312.51 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] ............. model__alpha=1e-07, score=-17.438781, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-2.302438, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-8.715487, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-2.302745, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............. model__alpha=1e-06, score=-17.425960, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-2.179855, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-2.299610, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............ model__alpha=0.0001, score=-15.845488, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-1.671704, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] ............. model__alpha=1e-05, score=-17.294270, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.383035, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.337571, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.382618, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.378406, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.304479, total=   0.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.5s finished
INFO:__main__:It takes 1305.46 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 11), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.211343, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.725196, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.254410, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.684908, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.205600, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.727219, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.247336, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.206093, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.725216, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.500745, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.254345, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.272001, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.206092, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.206033, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.205746, total=   0.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.5s finished
INFO:__main__:It takes 1312.22 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.049699, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.220675, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.220419, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.049886, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.220704, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.220702, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.233704, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.049681, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.049679, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.159339, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.108626, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.108636, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.108538, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.108635, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.117064, total=   0.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.0s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.3s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1309.60 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-1.816731, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.440207, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-2.297674, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] ............. model__alpha=0.001, score=-16.584129, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.537980, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] ............. model__alpha=1e-06, score=-28.286399, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-3.081659, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.519036, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-3.082282, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............. model__alpha=1e-08, score=-28.304340, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-3.082225, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.565985, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............. model__alpha=1e-07, score=-28.302709, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.567168, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.567060, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.0s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.3s finished
INFO:__main__:It takes 1344.59 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: 831a25f5-9b98-40eb-b521-befbfc1bd414,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 24.0using 2614.84 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: ec816041-9cad-4034-8df1-ead4da01e53a,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 10.344827586206897using 2590.52 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: 8fed63f8-5657-418b-977d-73fe41ef99f7,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 43.47826086956522using 2608.90 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: ce109b52-efc5-491e-a6da-90f5f7da73ab,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 16.0using 2615.77 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: a45fe886-3315-4529-9af7-8a2efa724206,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 7.142857142857142using 2618.75 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: 68d7ec61-34f6-45c1-af29-01359298387a,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 20.0using 2635.79 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: bd461261-10d3-4b0c-ae0a-0e0caeb1afe6,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 29.166666666666668using 2630.01 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 3, model_id: 51a1a1bf-a576-4986-9d34-feb2cfce39fa,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 6.666666666666667using 2665.31 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.586327, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.179345, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.219182, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.603819, total=   2.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.196695, total=   3.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.218405, total=   4.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.609513, total=   4.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.217490, total=   8.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.200577, total=   7.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.6s remaining:    5.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.0s remaining:    2.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.2s finished
INFO:__main__:It takes 1319.79 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 21), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.993576, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.626027, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.327265, total=   1.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.965759, total=   3.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.332736, total=   5.1s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.334036, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.709310, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.281230, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.723508, total=   3.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.323757, total=   3.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.289100, total=   5.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.727090, total=   6.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.5s remaining:    5.3s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.6s remaining:    2.8s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.2s finished
INFO:__main__:It takes 1333.44 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.5s remaining:    5.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.8s remaining:    2.9s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.9s finished
INFO:__main__:It takes 1325.34 seconds to train this model.
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.053468, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.210471, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.045694, total=   1.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.230699, total=   2.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.053733, total=   3.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.054864, total=   4.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.052562, total=   6.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.227975, total=   4.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.054907, total=   7.3s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.3s remaining:    4.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.2s remaining:    2.6s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.9s finished
INFO:__main__:It takes 1331.73 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.802156, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-9.243711, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.319551, total=   1.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-9.673041, total=   3.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.827450, total=   3.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.317408, total=   4.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-9.598685, total=   5.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.4s remaining:    4.9s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.2s remaining:    2.6s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.8s finished
INFO:__main__:It takes 1329.64 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 21), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.603966, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.129795, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.106597, total=   1.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.604966, total=   2.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.128733, total=   4.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.102737, total=   4.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.581294, total=   5.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.103884, total=   8.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.128792, total=   9.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.506366, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.330271, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.168370, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.178030, total=   3.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.482817, total=   4.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.325204, total=   5.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-1.151435, total=   5.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.473852, total=   7.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.4s remaining:    5.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.1s remaining:    2.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.9s finished
INFO:__main__:It takes 1336.19 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.5s remaining:    2.8s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.8s finished
INFO:__main__:It takes 1344.74 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-8.695883, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.150507, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.321461, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-8.851927, total=   2.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.102600, total=   4.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.318531, total=   4.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-1.104061, total=   7.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-8.716846, total=   5.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.318920, total=   7.6s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.4s remaining:    5.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.2s remaining:    2.6s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.2s finished
INFO:__main__:It takes 1381.11 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 34680693-f27a-43a5-b18a-26eccb3efaa2,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 24.0using 2633.51 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 2b500044-6031-4af6-9aa7-932708a0ed1c,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 13.793103448275861using 2634.75 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: efbf3789-9a87-439d-8f39-c214e41dc4a9,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 4.0using 2636.72 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 126d08a9-3e5f-45d8-ac5b-f1a4d67dadb6,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 26.08695652173913using 2642.60 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: f615bf8f-0df6-48b9-a961-c5b1063ddc43,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 7.142857142857142using 2631.56 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 1c76f4a6-781e-4b99-980e-c18198196750,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 25.0using 2638.53 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: 31c3c5ef-4e48-4e6a-af9e-bb97ec9f7a6d,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 12.0using 2664.66 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 4, model_id: f8a8c5e0-569a-463c-b92b-3bb59329f0d4,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 16.666666666666664using 2695.76 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.814520, total=   3.4s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.896886, total=   4.2s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.618830, total=   4.4s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.861175, total=   4.4s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.829767, total=   5.2s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.676274, total=   5.2s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.253695, total=   5.4s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.805339, total=   6.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.596411, total=   6.5s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.252921, total=   6.6s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.608185, total=   6.7s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.799221, total=   6.9s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.874710, total=   8.1s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.938092, total=   8.9s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.4s remaining:   28.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.2s remaining:    5.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   11.2s finished
INFO:__main__:It takes 1308.27 seconds to train this model.
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.893404, total=   4.6s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.572515, total=   4.7s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.861176, total=   4.8s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.185457, total=   5.5s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.610634, total=   6.0s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.573174, total=   6.2s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.858001, total=   6.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.863388, total=   6.7s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.582973, total=   6.9s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.198221, total=   7.6s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.890216, total=   7.5s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.899481, total=   7.7s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.532440, total=   9.4s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.154064, total=  10.7s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.8s remaining:   31.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.8s remaining:    6.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   11.6s finished
INFO:__main__:It takes 1338.91 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 21), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.561345, total=   3.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.725837, total=   3.8s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.373057, total=   3.9s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.875481, total=   4.7s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.638066, total=   4.9s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.254576, total=   5.8s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.727842, total=   6.6s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.689068, total=   7.1s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.904431, total=   7.5s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.689248, total=   7.5s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.261872, total=   8.6s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.348911, total=   8.8s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.876642, total=   9.9s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.897908, total=  10.5s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.0s remaining:   26.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.1s remaining:    6.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   11.9s finished
INFO:__main__:It takes 1348.10 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.167178, total=   2.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.053715, total=   3.5s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.058192, total=   3.6s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.842209, total=   3.8s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.060767, total=   4.2s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.232468, total=   4.5s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.898030, total=   5.2s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.626588, total=   5.2s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.718533, total=   5.4s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.851761, total=   5.7s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.874934, total=   6.0s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.043528, total=   6.2s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.057675, total=  10.9s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.040961, total=  12.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.208059, total=  14.6s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.7s remaining:   23.8s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.3s remaining:    4.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.7s finished
INFO:__main__:It takes 1364.45 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-8.226876, total=   2.7s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.710111, total=   2.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.441348, total=   3.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.190862, total=   3.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-4.054486, total=   3.8s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.749707, total=   3.9s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.603450, total=   4.0s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.243420, total=   4.1s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.215347, total=   4.1s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-8.302555, total=   4.2s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.257091, total=   4.3s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.684951, total=   5.9s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.712088, total=   4.8s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.210385, total=  12.9s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.926447, total=   9.8s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.9s remaining:   19.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.2s remaining:    3.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   13.0s finished
INFO:__main__:It takes 1365.48 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.624456, total=   4.7s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.541988, total=   4.9s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.851668, total=   5.2s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.606950, total=   5.3s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.830893, total=   5.6s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.530484, total=   5.8s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.859571, total=   5.8s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.124442, total=   5.9s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.868121, total=   6.0s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.889754, total=   6.2s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.124217, total=   6.6s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.888357, total=   7.3s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.090351, total=   8.4s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.1s remaining:   32.8s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.0s remaining:    5.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   12.0s finished
INFO:__main__:It takes 1397.84 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 21), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.876166, total=   3.4s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.556271, total=   3.7s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.753277, total=   4.2s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.593153, total=   6.7s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.870364, total=   6.7s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.883427, total=   7.2s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.672394, total=   7.3s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.912365, total=   7.6s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.913787, total=   9.8s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.221584, total=  10.1s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.382335, total=  10.4s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.583159, total=  10.7s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.751359, total=  11.2s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.740241, total=  13.5s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.273106, total=  17.4s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.8s remaining:   24.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.7s remaining:    6.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   17.5s finished
INFO:__main__:It takes 1417.99 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.673129, total=   2.6s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.564185, total=   3.5s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-7.551032, total=   3.5s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.784579, total=   3.9s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-2.883669, total=   4.1s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.244176, total=   4.3s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.264148, total=   4.8s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-2.962147, total=   5.2s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.298554, total=   5.2s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-5.917675, total=   5.8s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.263828, total=   5.9s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.886342, total=   6.3s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.888660, total=   6.8s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.737260, total=   7.4s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.291037, total=   8.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.6s remaining:   23.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.3s remaining:    4.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    8.1s finished
INFO:__main__:It takes 1405.15 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 5, model_id: 222775e6-5412-40e4-a922-bbd1449e946e,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 10.344827586206897using 2692.14 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 5, model_id: 87dc5c66-8518-4b59-8259-c09b0cf41fdc,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 16.0using 2715.56 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 5, model_id: 44266b54-64b3-4d2e-a727-165a97177aaf,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 12.0using 2718.26 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 5, model_id: 2cd908b6-1713-44e6-ae87-51231f902752,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 13.043478260869565using 2721.08 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 5, model_id: afac8295-0b27-40ae-9741-c8f0d243f3e5,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 0.0using 2714.53 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 5, model_id: 8406cef2-1797-4295-80b6-f89d60a805df,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 20.833333333333336using 2745.19 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 5, model_id: f049d58a-1c51-47f3-b5e1-0c2e4a935d1a,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 4.0using 2728.25 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 5, model_id: 4c75f3e8-9414-4cc1-a3d4-e3cc8b52f59d,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 0.0using 2738.88 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.802712, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.357643, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.802718, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.802785, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.529373, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.357630, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.428913, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.357507, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.803418, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.160899, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.193429, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.160899, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.160890, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.356325, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.160828, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.2s remaining:    1.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.3s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.5s finished
INFO:__main__:It takes 1311.23 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.346874, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.080168, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.156205, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.338201, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.352199, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.222407, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.078223, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.352196, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.161418, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.351828, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.160470, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.160961, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.078222, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.160965, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.078147, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.6s finished
INFO:__main__:It takes 1317.16 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 21), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.104168, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.104081, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.016993, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.055061, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.095335, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.016967, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.111050, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.055060, total=   0.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.025412, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.099121, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.016134, total=   0.4s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.067267, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.053456, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.062608, total=   0.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.6s finished
INFO:__main__:It takes 1307.86 seconds to train this model.
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.545150, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.545152, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.476253, total=   0.0s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.545150, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.133679, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.133679, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.133678, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.198495, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.176961, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.532295, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.162255, total=   0.1s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.135080, total=   0.1s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.176961, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.176958, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.172771, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.3s finished
INFO:__main__:It takes 1316.08 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-294.569613, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-155.279073, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-279.941729, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.391642, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-103.451070, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-151.916387, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-294.578925, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-7.514904, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-294.475591, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.464452, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.391786, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-155.285906, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-155.211368, total=   0.2s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.390207, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.317822, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.7s finished
INFO:__main__:It takes 1312.71 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 21), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.630095, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.475420, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.180247, total=   0.0s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.630092, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.548370, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.286021, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.224458, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.178125, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.224462, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.178125, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.178142, total=   0.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.206825, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.171275, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.630389, total=   0.1s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.224023, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.5s finished
INFO:__main__:It takes 1312.34 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.240457, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.239682, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.112614, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.232297, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.117982, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.138786, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.234357, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.043833, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.240379, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.044126, total=   0.1s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.043143, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.112911, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.044096, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.110368, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.112881, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.0s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.3s finished
INFO:__main__:It takes 1318.36 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-292.881206, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-355.403340, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-230.792124, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-254.576558, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-129.435727, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-344.344122, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.955810, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-32.103195, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-246.578209, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.765996, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.612597, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.719901, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-355.887416, total=   0.1s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-255.927203, total=   0.1s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.790549, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.6s finished
INFO:__main__:It takes 1347.03 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 6, model_id: 910a03ab-0b7d-48ef-9487-8c9d5bfdbc43,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 17.24137931034483using 2621.90 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 6, model_id: 5302c31f-871d-467a-b87b-b937117e2b4c,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 16.0using 2636.41 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 6, model_id: c4396c9b-7be1-42c6-b7c8-0dea81a64de9,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 34.78260869565217using 2615.28 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 6, model_id: 382d7034-22be-47c9-b69e-4595a9e7cccb,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 20.0using 2627.37 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 6, model_id: 62348feb-178d-4aaa-be2f-e8df10e54f4d,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 3.571428571428571using 2620.13 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 6, model_id: 460fb94c-1539-477e-b9b5-0826c7f7044c,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 20.833333333333336using 2639.46 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 6, model_id: 22b7ae9d-6bc4-4ab8-8385-b024a1259242,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 16.0using 2645.43 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 6, model_id: 66a0ec33-c24b-47f7-9a1b-a9591ca6b4fc,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 6.666666666666667using 2673.42 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.962848, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.638119, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.322485, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.963554, total=   3.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.634608, total=   4.7s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.7s remaining:    6.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.3s remaining:    3.1s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.6s finished
INFO:__main__:It takes 1329.61 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.577851, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.172562, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.217261, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.586460, total=   3.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.201097, total=   4.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.213150, total=   5.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.585926, total=   6.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.202063, total=   9.1s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.5s remaining:    5.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.4s remaining:    3.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.6s finished
INFO:__main__:It takes 1327.57 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 31), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.250297, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.054466, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.043562, total=   1.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.276494, total=   3.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.052130, total=   4.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.054221, total=   4.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.054314, total=  10.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.268050, total=   5.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.051156, total=   8.4s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.6s remaining:    5.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.5s remaining:    2.7s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.7s finished
INFO:__main__:It takes 1326.74 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.687763, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.273793, total=   1.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.345773, total=   1.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.709181, total=   2.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.273601, total=   5.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.340812, total=   4.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.699994, total=   6.2s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.5s remaining:    5.1s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.8s remaining:    2.9s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.1s finished
INFO:__main__:It takes 1329.84 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-6.017571, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.749704, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.292689, total=   1.5s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.3s remaining:    3.1s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.1s finished
INFO:__main__:It takes 1335.80 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 31), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.033699, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.525745, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.292169, total=   1.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.112199, total=   3.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.488569, total=   4.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.293566, total=   5.6s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.5s remaining:    5.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.0s remaining:    3.0s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.2s finished
INFO:__main__:It takes 1339.20 seconds to train this model.
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.585239, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.100943, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.127081, total=   1.6s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.3s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.4s remaining:    3.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.3s finished
INFO:__main__:It takes 1363.66 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-6.754105, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.781280, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.297442, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-7.203822, total=   3.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.813007, total=   4.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.294512, total=   5.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.3s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.4s remaining:    3.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.5s finished
INFO:__main__:It takes 1374.36 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 7, model_id: 1e4f0288-85cd-415e-a31b-230aa2b3c229,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 13.793103448275861using 2642.69 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 7, model_id: c0501ce0-dcf9-44c0-a9d8-0290e40e5491,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 16.0using 2640.58 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 7, model_id: a9a7aae9-a8fa-4153-9dd3-ec3c1e905668,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 17.391304347826086using 2634.89 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 7, model_id: 0f349aa3-ef06-45d7-94ab-7907ec21b877,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 12.0using 2639.40 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 7, model_id: eeab3857-0032-4324-8ed5-0ff41e342895,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 21.428571428571427using 2647.54 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 7, model_id: e6ca4656-fd23-40c6-9fe6-15bfe37a0501,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 12.0using 2638.22 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 7, model_id: a0e562eb-6841-4a68-8982-54c692c3bdc8,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 20.833333333333336using 2674.50 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 7, model_id: 6a3ee5de-b106-465a-9485-136509600ee7,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 10.0using 2699.25 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.732300, total=   7.0s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.936448, total=   7.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.772558, total=   8.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.709708, total=  10.9s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.764425, total=  10.9s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.952440, total=  12.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.882737, total=  13.0s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.871648, total=  13.2s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.243997, total=  13.6s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.704470, total=  14.5s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.633798, total=  15.9s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.244798, total=  14.8s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.482521, total=  23.7s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    7.7s remaining:   50.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   13.3s remaining:   11.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   28.2s finished
INFO:__main__:It takes 1371.81 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 31), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.582490, total=   4.1s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.203175, total=   4.1s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.323243, total=   4.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.628621, total=   5.7s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.865516, total=   5.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.628145, total=   6.7s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.853846, total=   7.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.888319, total=   7.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.893861, total=   9.5s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.675922, total=   9.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.575188, total=  13.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.368347, total=  15.1s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.268030, total=  16.9s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.2s remaining:   27.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.1s remaining:    7.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   20.8s finished
INFO:__main__:It takes 1361.22 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.611775, total=   6.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.519290, total=   6.7s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.876564, total=   7.1s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.909378, total=   7.4s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.146388, total=   8.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.175470, total=   8.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.909892, total=   9.0s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.892823, total=   9.2s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.480513, total=  10.1s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.436208, total=  10.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.491112, total=  10.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.181967, total=  16.8s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.144192, total=  11.1s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.168757, total=  13.5s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    6.9s remaining:   44.8s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    9.3s remaining:    8.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   19.8s finished
INFO:__main__:It takes 1397.13 seconds to train this model.
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.899841, total=   4.5s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.750174, total=   5.2s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.853460, total=   6.3s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.191627, total=   8.8s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.198863, total=  10.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.035932, total=  10.5s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.057675, total=  10.6s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.207532, total=  11.8s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.056846, total=  12.2s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.036417, total=  12.7s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.036464, total=  13.3s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.252417, total=  13.8s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.3s remaining:   34.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   12.0s remaining:   10.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   18.7s finished
INFO:__main__:It takes 1413.51 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-4.049157, total=   6.2s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.799955, total=   6.5s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.303375, total=   7.5s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.529696, total=   8.0s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.310141, total=   8.7s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.489100, total=   9.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.364137, total=   9.7s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.953059, total=  10.7s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-3.656239, total=  10.7s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.952714, total=  11.5s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-6.215145, total=  12.4s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.943109, total=  13.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.731257, total=  14.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.328547, total=  20.3s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.312646, total=  22.8s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    6.6s remaining:   42.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   10.8s remaining:    9.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   22.9s finished
INFO:__main__:It takes 1427.23 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 31), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.347015, total=   3.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.774846, total=   3.3s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.198619, total=   3.6s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.380688, total=   4.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.666182, total=   5.2s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.226613, total=   5.3s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.678573, total=   6.7s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.882986, total=   6.7s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.858630, total=   6.8s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.536065, total=   8.6s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.666918, total=  10.6s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.5s remaining:   22.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.0s remaining:    6.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   17.7s finished
INFO:__main__:It takes 1454.58 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.705213, total=   2.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.637836, total=   4.3s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.869441, total=   4.2s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.450783, total=   4.9s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.692054, total=   4.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.480402, total=   6.4s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.854365, total=   7.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.100690, total=   7.5s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.895227, total=   7.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.120519, total=   8.9s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.104793, total=   9.0s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.109746, total=   9.1s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.128708, total=  10.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.471226, total=  12.8s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.4s remaining:   28.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.7s remaining:    6.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   15.5s finished
INFO:__main__:It takes 1471.47 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.246108, total=   2.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.731505, total=   3.7s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.496776, total=   4.3s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-3.979852, total=   4.7s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-4.169249, total=   5.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.979503, total=   7.2s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.280589, total=   7.4s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.928060, total=   7.4s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.346306, total=   7.5s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.782085, total=   8.2s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-4.346386, total=   9.9s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-5.005683, total=  12.0s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.301164, total=  14.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.8s remaining:   24.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.6s remaining:    6.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   18.5s finished
INFO:__main__:It takes 1493.71 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 8, model_id: 04643b29-ba60-41b1-aa76-894abeaf1e42,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 10.344827586206897using 2790.13 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 8, model_id: 45a80257-2979-43d3-8e64-43e8a6f9b900,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 30.434782608695656using 2788.71 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 8, model_id: 0fc88699-29c8-48a9-8b8c-47ee15c4d24a,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 20.0using 2781.86 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 8, model_id: 04c0ecdd-2838-4786-a0d1-d517936a8848,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 16.0using 2799.60 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 8, model_id: 8ce3dc82-94ea-4077-a613-c5cb709d5ed8,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 0.0using 2791.36 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 8, model_id: 643f920f-50f6-4dac-9211-4b03e93dd444,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 16.0using 2802.34 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 8, model_id: 7e2bdad7-a77d-47e6-bd3a-f4a0417a5b45,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 25.0using 2811.33 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 8, model_id: fe562f2b-2af3-4a88-a9f2-b4abb4f0b854,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 0.0using 2837.15 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.531206, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.428913, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.193429, total=   0.1s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.756473, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.159101, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.632234, total=   0.5s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.756555, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.159205, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.430332, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.159190, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.336115, total=   0.8s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.172745, total=   0.9s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.428138, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.430562, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.757314, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.0s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.5s finished
INFO:__main__:It takes 1364.73 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.112777, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.112625, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.018048, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.111050, total=   0.2s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.062608, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.067267, total=   0.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.095853, total=   0.2s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.103565, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.025412, total=   0.4s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.053456, total=   0.6s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.015505, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.056095, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.053790, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.018084, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.056083, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.3s remaining:    1.8s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.4s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.3s finished
INFO:__main__:It takes 1338.89 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 31), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.279910, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.186460, total=   0.1s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.161009, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.158948, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.178760, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.398973, total=   0.8s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.542994, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.178271, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.544756, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.178813, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.160701, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.517666, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.161005, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.544590, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.174735, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.3s remaining:    2.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.0s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.2s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1369.92 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.222407, total=   0.7s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.088300, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.357288, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.337592, total=   1.1s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.164189, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.336234, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.164762, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.087036, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.088104, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.164762, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.088300, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.354682, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.160541, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.161418, total=   1.1s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.357285, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    1.1s remaining:    7.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.4s remaining:    1.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.7s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1367.23 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-172.187928, total=   0.6s
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-255.530090, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-242.353467, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.263802, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-242.316875, total=   0.8s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-242.317241, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.263936, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.207191, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-461.601488, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-461.599779, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-443.528993, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-379.577996, total=   1.4s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.246332, total=   1.4s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.263935, total=   1.5s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-461.411486, total=   1.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.9s remaining:    5.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.1s remaining:    1.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.8s finished
INFO:__main__:It takes 1380.21 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 31), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.495801, total=   1.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.596942, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.177207, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.177436, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.167848, total=   1.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.213479, total=   1.1s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.596933, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.268769, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    1.2s remaining:    7.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.3s remaining:    1.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.6s finished
INFO:__main__:It takes 1408.08 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.258634, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.048865, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.258395, total=   0.5s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.214757, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.105701, total=   0.5s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.116258, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.112914, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.044390, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.258632, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.116259, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.048865, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.116223, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.240000, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.8s remaining:    0.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.1s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1379.19 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-502.336593, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.185983, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.186062, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-391.320332, total=   0.7s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-502.348953, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-380.528671, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-380.642519, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-380.527636, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.370867, total=   0.8s
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-124.388094, total=   1.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.448256, total=   1.0s
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-363.088652, total=   0.8s
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-502.349051, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.186062, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.7s remaining:    4.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.0s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.7s finished
INFO:__main__:It takes 1382.63 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 9, model_id: d484557f-0a56-4053-a541-77364e73b113,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 39.130434782608695using 2654.18 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 9, model_id: 8c65c91f-f7a0-4e78-82c3-73b954b37d5b,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 20.689655172413794using 2759.43 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 9, model_id: 01f45b55-b9ed-418d-bae6-3a9842ff1d37,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 12.0using 2732.46 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 9, model_id: 820df049-f34c-41b4-8596-1b1d45f6ccc1,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 20.0using 2762.77 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 9, model_id: b5f7ffb4-6e6e-43ae-82a7-de630520a2fd,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 17.857142857142858using 2761.50 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 9, model_id: 50aa2efb-fd4a-4e89-a85f-a5d522b61e6c,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 20.0using 2776.06 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 9, model_id: 9d4fa018-0d8f-430d-b8f2-5a22367162ba,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 20.833333333333336using 2740.63 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 9, model_id: e77a282e-dc8e-45a0-980b-2f4b585aaf2f,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 10.0using 2780.33 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.271998, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.043809, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.053215, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.289842, total=   3.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.054091, total=   4.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.054660, total=   6.4s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.9s remaining:    6.8s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.9s remaining:    3.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.4s finished
INFO:__main__:It takes 1339.20 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.262295, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.653768, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.307853, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.273308, total=   3.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.314025, total=   6.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.662585, total=   9.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.308433, total=  12.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.1s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.3s remaining:    3.6s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   13.0s finished
INFO:__main__:It takes 1344.82 seconds to train this model.
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.213796, total=   1.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.565247, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.218585, total=   2.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.578820, total=   3.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.225714, total=   5.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.215782, total=   6.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.585259, total=   6.7s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.4s remaining:    8.3s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.3s remaining:    3.7s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   12.6s finished
INFO:__main__:It takes 1341.46 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 41), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.704307, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.264764, total=   1.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.365522, total=   1.5s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.9s remaining:    6.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.3s remaining:    3.7s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   12.2s finished
INFO:__main__:It takes 1363.47 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-5.962625, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.617513, total=   1.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.279659, total=   1.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.2s remaining:    7.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.7s remaining:    3.3s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.3s finished
INFO:__main__:It takes 1353.01 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 41), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.511658, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.129020, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.104877, total=   1.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.126262, total=   6.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.518308, total=   3.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.104293, total=   5.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.493756, total=   7.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.127322, total=  11.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.105536, total=  10.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.517362, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.293343, total=   2.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.962280, total=   1.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.951130, total=   3.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.503281, total=   4.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.296367, total=   6.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.515335, total=   9.9s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.7s remaining:    5.8s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.9s remaining:    3.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.9s finished
INFO:__main__:It takes 1367.39 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.4s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.9s remaining:    3.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   12.5s finished
INFO:__main__:It takes 1371.77 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-6.928261, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.752387, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.295431, total=   1.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.784520, total=   5.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-7.419385, total=   3.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-7.366430, total=   7.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.786915, total=   9.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.290273, total=  10.6s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.7s remaining:    6.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.6s remaining:    3.8s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.4s finished
INFO:__main__:It takes 1431.75 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 10, model_id: 075a600e-37bb-410d-b2b4-da12c2f10bf1,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 21.73913043478261using 2728.21 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 10, model_id: 4b0dccce-21f2-4c5f-a376-a8260eb44c67,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 16.0using 2750.13 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 10, model_id: e343f388-d931-4c79-916c-730888a074b6,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 17.24137931034483using 2762.84 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 10, model_id: 6eb4078f-0266-4674-ac03-03b419722b4f,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 16.0using 2767.99 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 10, model_id: 8831946e-32e4-4f5e-bfa1-ed70d264a572,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 14.285714285714285using 2759.53 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 10, model_id: 1ff4362a-f717-4cb8-a727-cde0ab9436fb,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 20.833333333333336using 2763.06 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 10, model_id: bd2693f1-3356-46d8-ae5f-82007226b52c,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 12.0using 2788.00 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 10, model_id: cc12f3a8-8706-4cae-bfec-8df426f5e7f9,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 6.666666666666667using 2859.66 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.644506, total=   2.4s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.860840, total=   3.5s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.859979, total=   3.7s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.683752, total=   6.2s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.628378, total=   6.6s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.649575, total=   7.3s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.901004, total=   8.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-1.376605, total=   8.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.244746, total=   8.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.889817, total=   9.7s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.802805, total=   9.8s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.882355, total=   9.9s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.985143, total=  10.7s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.6s remaining:   23.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    9.0s remaining:    7.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   11.6s finished
INFO:__main__:It takes 1308.46 seconds to train this model.
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.694469, total=   4.6s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.858504, total=   4.9s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.173717, total=   5.2s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.887527, total=   5.5s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.224866, total=   6.1s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.524882, total=   6.6s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.838546, total=   6.9s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.857109, total=   7.1s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.045532, total=   8.1s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.063163, total=   8.3s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.184673, total=   9.7s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.058153, total=  10.3s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.068641, total=  12.0s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.042928, total=  12.1s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.0s remaining:   32.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.5s remaining:    6.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.6s finished
INFO:__main__:It takes 1448.40 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.200105, total=   5.7s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.892628, total=   6.1s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.198615, total=   6.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.474159, total=   6.2s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.647664, total=   6.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.198061, total=   6.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.279062, total=   6.4s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.485062, total=   6.5s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.204364, total=   6.9s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.232108, total=   6.7s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.447987, total=   6.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.855198, total=   7.1s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.517351, total=   7.1s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.285895, total=   7.5s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    6.2s remaining:   40.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.7s remaining:    5.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    8.3s finished
INFO:__main__:It takes 1511.45 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.503341, total=   3.3s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.221631, total=   3.3s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-4.877456, total=   3.5s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.830400, total=   4.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.418583, total=   4.1s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.536617, total=   4.1s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-5.923663, total=   4.2s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.201174, total=   4.3s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.843837, total=   4.5s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.245756, total=   4.6s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.225449, total=   4.7s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.572161, total=   4.9s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.153984, total=   6.5s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.516335, total=   7.4s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.4s remaining:   22.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.3s remaining:    3.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    8.6s finished
INFO:__main__:It takes 1459.74 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 41), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.216504, total=   2.8s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.693053, total=   3.0s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.716338, total=   3.5s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.348940, total=   3.6s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.322861, total=   3.9s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.245675, total=   3.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.589877, total=   5.2s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.237017, total=   5.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.714185, total=   5.7s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.529627, total=   6.3s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.562216, total=   7.0s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.919680, total=   7.9s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.892392, total=   8.5s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.909588, total=   8.9s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.901290, total=   9.8s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.1s remaining:   20.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.5s remaining:    4.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    9.9s finished
INFO:__main__:It takes 1530.91 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.840194, total=   4.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.874392, total=   5.3s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.136451, total=   6.1s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.392768, total=   6.1s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.684706, total=   6.1s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.135009, total=   7.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.130493, total=   8.8s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.126668, total=   9.7s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.405832, total=  10.7s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.399468, total=  11.6s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.482840, total=  13.0s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.133594, total=  16.5s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.135775, total=  18.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.5s remaining:   35.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    9.8s remaining:    8.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   19.7s finished
INFO:__main__:It takes 1495.22 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 41), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.760863, total=   2.7s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.862274, total=   3.3s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.873090, total=   3.7s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.424684, total=   3.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.783668, total=   4.2s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.372737, total=   4.5s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.517499, total=   6.2s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.891991, total=   6.4s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.896578, total=   6.7s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.561707, total=  10.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.287399, total=  18.3s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.247359, total=  19.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.5s remaining:   22.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.5s remaining:    5.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   19.4s finished
INFO:__main__:It takes 1586.02 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.064718, total=   3.3s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.569717, total=   3.4s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.833943, total=   3.5s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.266824, total=   3.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.948792, total=   4.4s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.780226, total=   4.8s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-1.025795, total=   6.1s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.513519, total=   6.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-4.177644, total=   7.5s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.255330, total=   7.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.299199, total=   8.7s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.026094, total=  11.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-4.898265, total=  16.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.781887, total=  18.5s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.238804, total=  21.1s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.5s remaining:   22.8s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.6s remaining:    5.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   21.2s finished
INFO:__main__:It takes 1540.05 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 11, model_id: a94067b7-7276-45f8-a41d-fbcc8357ea04,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 6.896551724137931using 2696.47 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 11, model_id: 9d13f24b-41eb-4dc7-9ee7-8c026ac62067,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 17.391304347826086using 2935.72 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 11, model_id: 10184911-b781-4c3c-b9fd-bd625d13d612,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 20.0using 2975.26 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 11, model_id: 872d170c-364c-4dd0-9fc5-71040edf78e5,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 0.0using 2939.45 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 11, model_id: 7ceaa3c4-efca-44cd-b84c-fcbd5840d02c,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 20.0using 2996.34 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 11, model_id: 05b7b11b-1bea-4af1-9b80-b034d862705e,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 25.0using 2906.38 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 11, model_id: 4aa941ea-0a1e-47f3-a21b-6496c81a6fcd,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 20.0using 3075.74 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 11, model_id: 5e554788-32b6-450e-9eb2-cdc9fdcc712f,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 0.0using 2937.55 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.986103, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.547203, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.628231, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.347802, total=   0.1s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.161313, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.166763, total=   0.1s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.986108, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.980731, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.986057, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.547206, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.543465, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.547174, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.161313, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.160988, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.161310, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.3s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.5s finished
INFO:__main__:It takes 1349.26 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.100465, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.018835, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.101448, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.023255, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.058894, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.054655, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.059641, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.023249, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.022574, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.059635, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.025585, total=   1.1s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.102439, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.102429, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.053456, total=   1.3s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.096262, total=   1.4s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.2s remaining:    1.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.0s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.7s finished
INFO:__main__:It takes 1317.86 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.308036, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.127882, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.134917, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.168552, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.308198, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.134838, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.151341, total=   0.8s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.221092, total=   0.7s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.175756, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.321139, total=   0.8s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.157179, total=   0.8s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.296483, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.291327, total=   1.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.175889, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.160648, total=   1.1s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.8s remaining:    5.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.9s remaining:    0.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.3s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1333.73 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-409.620554, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.592179, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-269.143998, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-408.477600, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.592259, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-408.594586, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-269.212661, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-8.877771, total=   0.7s
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-105.134921, total=   0.9s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-269.212098, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.592180, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-268.185086, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-408.478658, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.288615, total=   1.4s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.588960, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.6s remaining:    3.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.9s remaining:    0.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.6s finished
INFO:__main__:It takes 1323.82 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 41), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.276656, total=   0.2s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.185633, total=   0.2s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.554062, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.554425, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.554422, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.236754, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.519170, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.186308, total=   0.2s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.226913, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.180276, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.236791, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.390687, total=   0.9s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.186415, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.236791, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.186416, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.3s remaining:    1.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.8s remaining:    0.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.3s finished
INFO:__main__:It takes 1333.10 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.211325, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.070155, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.211152, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.211324, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.083687, total=   0.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.198950, total=   0.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.106371, total=   0.1s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.070156, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.070029, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.124872, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.062295, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.119251, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.124943, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.200757, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.124942, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.2s remaining:    1.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.3s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.1s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1297.46 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 41), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.364636, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.180230, total=   0.4s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.361285, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.287166, total=   0.4s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.339211, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.179758, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.660882, total=   0.4s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.182416, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.657804, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.233991, total=   0.9s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.617930, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.182847, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.493517, total=   1.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.169070, total=   1.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.468990, total=   1.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.7s remaining:    4.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.9s remaining:    0.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.2s finished
INFO:__main__:It takes 1324.30 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-410.038345, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-410.022840, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-441.325319, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-411.260073, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-441.042626, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.372534, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-124.388094, total=   0.8s
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-32.393656, total=   0.9s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.372519, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-411.149142, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.372996, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.300743, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.448256, total=   1.2s
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-441.052398, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.4s remaining:    2.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.0s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.5s finished
INFO:__main__:It takes 1315.56 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 12, model_id: 2b3f60ee-4c5b-440e-b518-c89fbd05f6af,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 17.24137931034483using 2650.18 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 12, model_id: aa6fec19-1033-4d4c-82bd-de141d2f9dc9,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 39.130434782608695using 2606.37 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 12, model_id: 022f3830-0e17-42fe-a200-ff2d6195996c,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 16.0using 2660.65 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 12, model_id: dcc3846a-cb24-45aa-a174-cb1c0003a8fa,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 17.857142857142858using 2638.12 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 12, model_id: 83b977b4-e131-4ae4-a207-d04427045e66,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 25.0using 2582.80 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 12, model_id: ab4c85c3-0c09-4146-80da-ccd606045907,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 20.0using 2646.71 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 12, model_id: ba45a5c0-3427-41ab-8d21-df2bbd17eb8b,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 16.0using 2628.67 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 12, model_id: c1e7c02c-62d0-480b-b62f-2b735d98a5e4,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 10.0using 2654.19 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.484133, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.318106, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.795920, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.508547, total=   4.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.326483, total=   7.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.746015, total=   5.5s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.9s remaining:    6.8s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.7s remaining:    3.8s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   12.9s finished
INFO:__main__:It takes 1340.37 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.234262, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.045129, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.054448, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.249537, total=   2.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.055524, total=   5.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.055085, total=   6.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.246069, total=   6.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.054558, total=   9.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.055422, total=  11.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.4s remaining:    5.1s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.7s remaining:    3.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.7s finished
INFO:__main__:It takes 1314.52 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.114182, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.491362, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.130901, total=   1.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.113467, total=   4.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.470595, total=   4.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.129473, total=  10.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.6s remaining:    5.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.6s remaining:    3.8s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.4s finished
INFO:__main__:It takes 1298.00 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-5.857533, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.630499, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.283739, total=   1.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-6.728910, total=   3.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.646282, total=   5.1s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.6s remaining:    5.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.8s remaining:    3.9s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.2s finished
INFO:__main__:It takes 1348.21 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 51), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.639179, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.229374, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.224977, total=   1.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.612011, total=   3.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.231990, total=   4.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.221463, total=   6.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.601692, total=   6.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.885880, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.272535, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.392254, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.888290, total=   3.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.388943, total=   6.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.282676, total=   6.7s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.1s remaining:    3.6s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   12.5s finished
INFO:__main__:It takes 1344.60 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.7s remaining:    6.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.0s remaining:    3.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   14.5s finished
INFO:__main__:It takes 1398.52 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 51), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.148218, total=   0.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.574928, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.224613, total=   1.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.116262, total=   3.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.558983, total=   5.1s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.3s remaining:    4.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.6s remaining:    3.3s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.7s finished
INFO:__main__:It takes 1382.92 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-6.102117, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.785674, total=   1.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-6.543861, total=   2.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.776724, total=   5.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.294121, total=   5.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.286337, total=   1.2s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.3s remaining:    4.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.2s remaining:    3.1s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.3s finished
INFO:__main__:It takes 1351.68 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 13, model_id: 24b0cf5e-93e0-4117-bfa1-84db6e3e4775,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 6.896551724137931using 2620.35 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 13, model_id: 8f0742af-4e55-49b1-bf58-73b6ec30f2eb,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 17.391304347826086using 2581.01 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 13, model_id: de7ab085-6eda-4af8-9d6e-623d9a06d28f,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 25.0using 2465.11 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 13, model_id: e3a17c7f-ff27-47cd-8e94-3342c505af67,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 12.0using 2602.42 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 13, model_id: 2c74a247-dd8b-4e3c-ad42-576ed56ba875,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 10.714285714285714using 2602.57 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 13, model_id: 45b0b5b3-de6c-447e-a8c5-61118ce5c0e3,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 16.0using 2582.25 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 13, model_id: 9a279716-1b70-41e2-a59e-445523071806,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 12.0using 2546.92 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 13, model_id: b9440370-bec9-4058-8f9b-4a52dbacfc96,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 13.333333333333334using 2495.48 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.853088, total=   4.9s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.889922, total=   4.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.676252, total=   2.3s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.056817, total=   8.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.055643, total=   8.5s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.058607, total=   3.0s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.192782, total=   7.0s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.886304, total=   3.4s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.242387, total=   3.3s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.714217, total=   2.5s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.6s remaining:   16.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.3s remaining:    3.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    9.1s finished
INFO:__main__:It takes 1044.60 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.699867, total=   3.0s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.883888, total=   3.4s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-1.701551, total=   3.6s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.827424, total=   3.7s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.957900, total=   5.3s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.743268, total=   5.3s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.684306, total=   5.6s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.982505, total=   5.9s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.283704, total=   6.1s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.870537, total=   6.4s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.946777, total=   7.2s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.879598, total=   8.0s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-1.405360, total=   8.1s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.896345, total=   8.2s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.268447, total=   9.7s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.5s remaining:   22.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.0s remaining:    5.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    9.7s finished
INFO:__main__:It takes 1115.47 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.129367, total=   2.8s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.127561, total=   3.0s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.549026, total=   3.4s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.659469, total=   4.4s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.586106, total=   4.8s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.889667, total=   5.0s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.657364, total=   5.0s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.889117, total=   5.6s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.874670, total=   5.8s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.891951, total=   6.1s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.892312, total=   6.2s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.890670, total=   6.1s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.482636, total=  10.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.129784, total=  13.5s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.128088, total=  11.1s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.1s remaining:   20.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.7s remaining:    5.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   13.6s finished
INFO:__main__:It takes 1074.45 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.874424, total=   2.4s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.662635, total=   2.6s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.177084, total=   2.7s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.514923, total=   2.9s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.859859, total=   2.9s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.715359, total=   3.0s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.259097, total=   3.0s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.692929, total=   3.2s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.657972, total=   3.4s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.570409, total=   3.3s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.405024, total=   5.1s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.640961, total=   5.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.245598, total=   5.5s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.190533, total=   7.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.7s remaining:   17.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    3.3s remaining:    2.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    7.5s finished
INFO:__main__:It takes 1082.72 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.499923, total=   3.1s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.846915, total=   3.1s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.196489, total=   3.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.498987, total=   3.9s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.498704, total=   4.5s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.637314, total=   4.9s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.567125, total=   4.9s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.910111, total=   5.1s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-2.300645, total=   5.2s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.251583, total=   5.3s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.195265, total=   5.3s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.958789, total=   5.9s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.219487, total=   6.0s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.952407, total=   7.2s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.202505, total=   7.4s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.3s remaining:   21.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.2s remaining:    4.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    7.6s finished
INFO:__main__:It takes 1083.22 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 51), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.565329, total=   4.5s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.760114, total=   5.2s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.854846, total=   5.7s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.835990, total=   6.0s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.212312, total=   6.0s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.903953, total=   6.7s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.243125, total=   7.2s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.361008, total=   7.4s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.493828, total=   7.5s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.345504, total=   7.7s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.901423, total=   7.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.249576, total=   8.0s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.910906, total=   8.4s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.339382, total=  12.6s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.210158, total=  14.6s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.3s remaining:   34.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.6s remaining:    6.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.7s finished
INFO:__main__:It takes 1122.37 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 51), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.633587, total=   4.6s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.876863, total=   5.1s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.921864, total=   5.2s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.850834, total=   5.3s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.559541, total=   5.3s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.864224, total=   5.8s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.915213, total=   5.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.582948, total=   7.5s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.212817, total=   8.0s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.959587, total=   8.3s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.686862, total=   8.4s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.212905, total=   8.4s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.736411, total=   8.7s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.581775, total=  10.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.240743, total=  12.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.2s remaining:   33.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.6s remaining:    6.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   12.2s finished
INFO:__main__:It takes 1103.44 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-3.282113, total=   2.7s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.813733, total=   2.8s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.198110, total=   3.3s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-3.947697, total=   6.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.182704, total=   6.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-1.496057, total=   7.1s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-1.398955, total=   7.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.809846, total=   7.5s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-4.022782, total=   7.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.197415, total=   7.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.924213, total=   7.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.913767, total=   8.5s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.843471, total=   9.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.9s remaining:   18.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.7s remaining:    6.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   10.9s finished
INFO:__main__:It takes 1112.87 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 14, model_id: a74d1593-0c96-46e3-83f7-836ddc1f4e4b,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 30.434782608695656using 2152.04 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 14, model_id: 95d3f1a0-92d2-4321-a351-b3eeab69f879,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 10.344827586206897using 2214.66 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 14, model_id: d63da786-78eb-4252-b1c5-3aaf24b85008,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 29.166666666666668using 2154.01 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 14, model_id: 1bf5c0da-4efd-410b-b8c6-ecabe3d9e71f,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 16.0using 2158.20 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 14, model_id: c8ce2070-195b-481b-8170-95498701a8ba,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 0.0using 2149.88 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 14, model_id: 0e5ecc91-1696-4a60-935d-72ddcc66d88f,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 12.0using 2174.96 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 14, model_id: 181347b8-1839-4b89-b3df-d8d26617218a,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 12.0using 2152.34 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 14, model_id: 56a22a3e-53c9-44fe-a18e-93e15b77dfa6,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 6.666666666666667using 2144.40 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.026383, total=   1.5s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.096203, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.058674, total=   2.4s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.027779, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.055001, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.038500, total=   2.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.058679, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.106681, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.090828, total=   2.5s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.058679, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.106666, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.106683, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.038515, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.038514, total=   2.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.052930, total=   2.5s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.6s remaining:   17.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    2.7s remaining:    2.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.8s finished
INFO:__main__:It takes 1030.85 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.652474, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.951541, total=   0.3s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.670413, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.946591, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.711010, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.707737, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.155784, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.422937, total=   0.5s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.894485, total=   1.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.154805, total=   1.8s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.951537, total=   1.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.711012, total=   1.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.156418, total=   1.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.150075, total=   2.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.156419, total=   1.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.4s remaining:    2.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.6s remaining:    0.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.1s finished
INFO:__main__:It takes 1025.62 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.225224, total=   0.1s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.222173, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.124193, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.224355, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.116251, total=   0.1s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.119691, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.102797, total=   0.3s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.120441, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.120434, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.201586, total=   0.3s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.089564, total=   0.3s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.138553, total=   0.6s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.224333, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.125706, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.125691, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.5s remaining:    0.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.9s finished
INFO:__main__:It takes 1036.87 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.244918, total=   2.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.344614, total=   2.4s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.244917, total=   3.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.155212, total=   2.3s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.243026, total=   3.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.344616, total=   3.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.165718, total=   3.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.159309, total=   3.6s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.328647, total=   3.6s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.220403, total=   3.6s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.164378, total=   3.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.165720, total=   3.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.224696, total=   3.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.343084, total=   3.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.5s remaining:   16.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    3.8s remaining:    3.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    3.9s finished
INFO:__main__:It takes 1048.10 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-372.944627, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-373.490908, total=   2.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-372.872058, total=   2.3s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-346.567624, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-372.522191, total=   3.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-206.008748, total=   3.4s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.499796, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.238189, total=   3.4s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-346.423916, total=   3.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-381.841643, total=   3.4s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.499108, total=   3.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.498837, total=   3.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-351.547223, total=   3.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.435706, total=   3.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-347.701448, total=   3.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.3s remaining:   15.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    3.6s remaining:    3.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    3.7s finished
INFO:__main__:It takes 1049.15 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 51), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.496709, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.176088, total=   0.1s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.498846, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.272982, total=   0.2s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.406596, total=   0.8s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.155935, total=   0.8s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.168966, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.389155, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.386691, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.473148, total=   0.9s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.175156, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.360288, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.389391, total=   1.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.243860, total=   2.0s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.174216, total=   2.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.2s remaining:    1.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.0s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.8s finished
INFO:__main__:It takes 1064.75 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 51), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.602875, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.164320, total=   0.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.479874, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.257183, total=   0.1s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.172972, total=   5.1s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.521284, total=   5.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.172913, total=   5.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.652602, total=   5.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.496224, total=   5.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.652597, total=   5.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.521079, total=   5.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.168964, total=   5.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.521282, total=   5.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.172971, total=   5.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.652012, total=   5.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.7s remaining:    4.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.9s remaining:    5.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    6.0s finished
INFO:__main__:It takes 1130.80 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-123.993187, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.448000, total=   2.8s
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-32.478707, total=   2.8s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-468.948594, total=   2.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.342265, total=   2.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-382.143435, total=   2.8s
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-382.944480, total=   4.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-468.956993, total=   4.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.342380, total=   4.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.300920, total=   4.5s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.353594, total=   4.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-469.890730, total=   5.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-382.150138, total=   5.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-382.376908, total=   5.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-463.573242, total=   5.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.9s remaining:   18.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.6s remaining:    4.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    5.2s finished
INFO:__main__:It takes 1160.04 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 15, model_id: b15ea235-b57a-437a-a2b5-e0b0ae5c19a4,model_name: lasso, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 26.08695652173913using 1932.07 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 15, model_id: 84fa2191-b3cb-4bf2-aeba-37d6a2388cac,model_name: lasso, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 10.344827586206897using 2408.43 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 15, model_id: ab316239-49b0-412e-aaa5-f24a1c07ad87,model_name: lasso, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 20.833333333333336using 2314.13 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 15, model_id: 549eb647-1c5d-4cde-a6ea-41f7e4ffd24b,model_name: lasso, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 12.0using 1995.51 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 15, model_id: dd841b8a-d652-4299-95c8-b7deab8e98d6,model_name: lasso, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 20.0using 2412.79 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 15, model_id: a7c7c68b-061f-45ed-82a8-e4cb49f08c6d,model_name: lasso, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 17.857142857142858using 2518.15 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 101), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 15, model_id: 60f31020-a8ef-4751-916d-04e1091a875c,model_name: lasso, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 16.0using 2513.60 seconds
INFO:__main__:




impute_method: directly

[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.074258, total=   4.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.289131, total=   3.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.350095, total=   5.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.055123, total=   5.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.055541, total=   8.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.086906, total=  10.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.055500, total=  11.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.093008, total=  11.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.333506, total=   8.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    5.2s remaining:   18.3s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:   10.9s remaining:    5.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.7s finished
INFO:__main__:It takes 870.23 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 15, model_id: 86f629f8-b3b9-4d80-addb-609cb106f135,model_name: lasso, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 10.0using 2633.56 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 101), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.582615, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.198066, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.316416, total=   1.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.198607, total=   4.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.308762, total=   6.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.544280, total=   4.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-1.499561, total=   8.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.308862, total=  11.2s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.5s remaining:    5.1s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.4s remaining:    3.7s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.6s finished
INFO:__main__:It takes 890.08 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 16, model_id: f8fa0764-a5fa-4420-b456-c169ed67f8e1,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 34.78260869565217using 1717.12 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 101), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.864068, total=   2.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.081961, total=   2.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.226322, total=   3.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.837637, total=   3.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.035484, total=   6.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.240021, total=   7.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-1.848200, total=   7.5s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    3.4s remaining:   12.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.9s remaining:    4.0s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.9s finished
INFO:__main__:It takes 1354.12 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 101), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.730417, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.133192, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.312521, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.703551, total=   3.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.324757, total=   5.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.132760, total=   6.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.693997, total=   8.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.7s remaining:    6.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.9s remaining:    3.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   12.6s finished
INFO:__main__:It takes 1431.80 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 101), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 101), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 101), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.037739, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.787577, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.218692, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.049395, total=   4.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.714113, total=   6.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.522255, total=   1.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.839721, total=   1.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.260232, total=   2.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.469391, total=   6.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.829592, total=   9.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.260306, total=  13.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-1.440240, total=  14.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.857120, total=  17.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.257372, total=  21.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-5.313438, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.334059, total=   2.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.319681, total=   3.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-5.942230, total=   7.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.307747, total=  13.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.212145, total=  10.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-5.876062, total=  15.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-1.268172, total=  21.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.311470, total=  21.9s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    3.6s remaining:   12.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:   15.0s remaining:    7.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   22.8s finished
INFO:__main__:It takes 1432.19 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.7s remaining:    6.1s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    9.3s remaining:    4.6s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   22.3s finished
INFO:__main__:It takes 1549.49 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.4s remaining:    8.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:   14.4s remaining:    7.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   22.6s finished
INFO:__main__:It takes 1406.90 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 101), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-4.540902, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.224375, total=   2.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.946587, total=   1.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-4.945567, total=   5.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.026525, total=   8.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.230637, total=  10.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-4.857399, total=  12.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.226644, total=  17.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-1.005889, total=  14.3s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.5s remaining:    8.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:   10.8s remaining:    5.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   18.4s finished
INFO:__main__:It takes 1426.71 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 101), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.578218, total=   5.2s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.658242, total=   5.4s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.850787, total=   6.4s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.884401, total=   6.3s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.843174, total=   6.7s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.350626, total=   7.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.896084, total=   8.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.507727, total=   9.3s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.046841, total=   9.7s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.081447, total=   9.9s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.068654, total=  10.4s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.055834, total=  18.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.043723, total=  20.6s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.5s remaining:   35.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    9.4s remaining:    8.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   20.8s finished
INFO:__main__:It takes 1160.18 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 16, model_id: 31f8073c-b316-4a6d-a857-07bfa445363c,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 8.0using 2369.37 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 16, model_id: faf2da0e-79e7-41d7-9fef-e29138ea84a9,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 29.166666666666668using 2899.48 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 16, model_id: a5ccd2e1-bec1-41cd-959f-4334bb2356f2,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 10.344827586206897using 2936.53 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 16, model_id: ddbe61b8-54eb-48c5-b513-8a8f1683018b,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 3.571428571428571using 3022.72 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 16, model_id: ed9c088e-fc41-4bea-b743-bd8b7b3d1c61,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 16.0using 3138.30 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 16, model_id: cafa2a9b-4264-4542-9efc-127c51d85601,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 16.0using 2993.13 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 16, model_id: 1413a1c5-2cc2-494c-b709-2ec952b91fb4,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 3.3333333333333335using 3078.76 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 17, model_id: 151d13c5-5245-4894-b58d-ad41b65e666e,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 30.434782608695656using 2727.76 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 101), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-1.255283, total=   3.4s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.866590, total=   4.0s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.195574, total=   4.1s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.513618, total=   4.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.565536, total=   5.8s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.771314, total=   6.0s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.722026, total=   7.1s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.924393, total=   7.5s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-1.134324, total=   9.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-1.181341, total=   9.7s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-1.171958, total=  11.8s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.221220, total=  13.9s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.222186, total=  16.1s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-1.059705, total=  21.8s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.2s remaining:   27.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.9s remaining:    6.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   22.2s finished
INFO:__main__:It takes 1688.29 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 101), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.496298, total=   5.2s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.819113, total=   5.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.894888, total=   5.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.791975, total=   5.7s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.468790, total=   5.8s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.891866, total=   5.8s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.432663, total=   5.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.524801, total=   5.9s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.836192, total=   6.5s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.835596, total=   6.3s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.112567, total=   6.2s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.427407, total=   6.7s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.894992, total=   7.6s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.924185, total=   7.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.266337, total=   7.6s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.4s remaining:   34.8s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.3s remaining:    5.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    8.1s finished
INFO:__main__:It takes 1588.28 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 101), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.195765, total=   4.3s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-1.839261, total=   4.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.933609, total=   4.7s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.735233, total=   5.5s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-1.014189, total=   6.5s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.942743, total=   8.7s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.784682, total=   8.7s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-1.427120, total=   9.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.269541, total=  10.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.018280, total=  12.3s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.888322, total=  13.1s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.911657, total=  13.1s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-1.783390, total=  19.0s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-1.761494, total=  21.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.5s remaining:   29.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    9.9s remaining:    8.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   36.2s finished
INFO:__main__:It takes 1665.71 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 101), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.190341, total=   4.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-4.387669, total=   5.1s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-1.153905, total=   5.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.066072, total=   6.4s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-4.368920, total=   6.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-2.005460, total=   7.4s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.758863, total=   7.6s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.138659, total=   7.7s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.267012, total=   7.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.819163, total=   7.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.889556, total=   8.0s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-1.400688, total=  12.8s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-4.374880, total=  10.1s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.062793, total=  12.8s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.2s remaining:   33.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.8s remaining:    6.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   16.8s finished
INFO:__main__:It takes 1664.46 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 101), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.894557, total=   3.3s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.705281, total=   4.0s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.234148, total=   4.2s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.493909, total=   5.0s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.457912, total=   5.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.812315, total=   6.1s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.206634, total=   6.1s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.811073, total=   6.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.984513, total=   7.6s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.933087, total=   7.4s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.947507, total=   8.3s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.838791, total=   8.3s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.946243, total=   9.0s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.407803, total=  11.2s
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 101), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.4s remaining:   28.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.6s remaining:    5.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   13.2s finished
INFO:__main__:It takes 1702.55 seconds to train this model.
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.520528, total=   3.7s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-1.014725, total=   3.8s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.182342, total=   3.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.948835, total=   4.3s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.175083, total=   4.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.623559, total=   4.9s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.522160, total=   7.2s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.804260, total=   8.3s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.942376, total=   9.1s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.578000, total=  11.1s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.964335, total=  12.2s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.215314, total=  15.5s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-1.109496, total=  16.2s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.617376, total=  16.5s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.9s remaining:   25.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.6s remaining:    7.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   27.6s finished
INFO:__main__:It takes 1726.27 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 101), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.084718, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.127308, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.084371, total=   0.4s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.042837, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.052221, total=   0.4s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.084757, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.111050, total=   1.1s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.057273, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.057122, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.048776, total=   1.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.037713, total=   1.2s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.102620, total=   1.2s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.127415, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.126378, total=   1.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.057257, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.6s remaining:    3.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.4s remaining:    1.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.8s finished
INFO:__main__:It takes 1679.42 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 101), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.030656, total=   4.0s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.040071, total=   4.5s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.909277, total=   4.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.821253, total=   8.7s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-3.418842, total=   6.3s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-2.116464, total=   9.0s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.025967, total=  10.5s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.216220, total=  10.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.155819, total=  10.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-1.168658, total=  10.9s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-2.279223, total=  11.2s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-1.607163, total=  11.0s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.270432, total=  14.7s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-1.266018, total=  15.9s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.6s remaining:   29.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   10.9s remaining:    9.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   17.9s finished
INFO:__main__:It takes 1736.30 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 17, model_id: 08f68d96-ccb4-4b45-9210-601e3421560e,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 0.0using 3423.07 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 17, model_id: d9d88a18-ce42-4271-ba0e-9ceb297e3c75,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 29.166666666666668using 3283.51 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 17, model_id: 01c3df49-b44a-43e9-960f-6e019fe80b54,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 6.896551724137931using 3369.23 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 17, model_id: f14ca9f7-8649-4afd-a687-8ac6c1779394,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 3.571428571428571using 3293.38 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 17, model_id: 6443aa7c-0a2b-4e90-ace7-7b206b4a722b,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 8.0using 3307.36 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 17, model_id: f0d78a1e-5dde-468a-bdcd-db7474b6b5be,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 4.0using 3345.91 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 18, model_id: fc11abf1-f92c-44a9-8c5f-fb38f1751d8d,model_name: lasso, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 30.434782608695656using 3228.87 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 17, model_id: 1bd9022f-75e1-4dd2-a010-581cbb709e4a,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 0.0using 3348.34 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 101), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-1.016560, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.175373, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-1.043105, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.990514, total=   1.5s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.933205, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.990513, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-1.047865, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-1.047870, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.175371, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.173264, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-1.462568, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.689108, total=   1.2s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.156192, total=   1.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.140674, total=   1.7s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.991709, total=   2.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    1.6s remaining:   10.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.6s remaining:    1.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.3s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1650.12 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1510, 101), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.230742, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.077761, total=   0.1s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.332618, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.089588, total=   1.1s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.116758, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.289571, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.116522, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.290014, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.095206, total=   1.7s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.116760, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.328680, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.332582, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.289567, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.320532, total=   1.8s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.2s remaining:    1.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.8s remaining:    1.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.0s finished
INFO:__main__:It takes 1638.99 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 101), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.563554, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.337483, total=   0.2s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-1.212746, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-2.802182, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.412867, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-1.222542, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-2.342018, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-2.337617, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.489416, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-2.337121, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.488555, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-1.213533, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.489511, total=   1.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.177700, total=   1.8s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-1.213452, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.2s remaining:    1.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.5s remaining:    1.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.9s finished
INFO:__main__:It takes 1678.67 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 101), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.362400, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.119631, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.124066, total=   0.2s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.642390, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.962122, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.972148, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.699122, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.971151, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.168760, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.168792, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.972382, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.696458, total=   2.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.148929, total=   2.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    1.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.9s remaining:    0.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    3.0s finished
INFO:__main__:It takes 1592.04 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 101), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-500.662162, total=   0.1s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-521.276804, total=   0.2s
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-133.859044, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-522.011231, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.132610, total=   0.8s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.188094, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.188249, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-522.017901, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-961.223858, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.188235, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-961.119778, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-960.168175, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-521.944503, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-961.214389, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.2s remaining:    1.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.2s remaining:    1.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.8s finished
INFO:__main__:It takes 1630.89 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1509, 101), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.539016, total=   0.3s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.730550, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-1.622647, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.724908, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.202185, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-1.179452, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.170551, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.156613, total=   1.1s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.201784, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.202145, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-1.179915, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.136776, total=   1.6s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.731176, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-1.184129, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.401612, total=   1.8s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.7s remaining:    4.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.2s remaining:    1.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.9s finished
INFO:__main__:It takes 1700.98 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.056682, total=   1.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.179417, total=   2.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.061281, total=   1.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.072019, total=   4.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.158213, total=   2.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.164760, total=   5.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.056676, total=   5.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.070887, total=   6.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.056811, total=   8.6s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.2s remaining:    7.8s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.1s remaining:    3.0s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.9s finished
INFO:__main__:It takes 1709.58 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 101), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-424.774404, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-400.536945, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ........... model__alpha=1e-07, score=-1802.773455, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ........... model__alpha=1e-08, score=-1802.838142, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.932983, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-424.810782, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.934817, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.914645, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.186847, total=   0.8s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-424.411743, total=   0.7s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.733373, total=   0.8s
[CV] model__alpha=1e-06 ..............................................
[CV] ........... model__alpha=1e-06, score=-1802.169613, total=   0.5s
[CV] model__alpha=0.0001 .............................................
[CV] .......... model__alpha=0.0001, score=-1693.387972, total=   1.0s
[CV] model__alpha=1e-05 ..............................................
[CV] ........... model__alpha=1e-05, score=-1799.112638, total=   0.9s
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-421.526105, total=   1.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.4s remaining:    2.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.0s remaining:    0.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.2s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 1760.99 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 10 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 18, model_id: ea192434-710d-4f0b-87d9-24c66c244baf,model_name: lasso, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 12.0using 3505.73 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (24, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 18, model_id: eba4a887-7285-4afd-a9ab-9f4be55de855,model_name: lasso, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 20.833333333333336using 3367.09 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 18, model_id: 2da98559-41a0-41e5-b0e5-1b07b1c0da24,model_name: lasso, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 13.793103448275861using 3476.18 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 18, model_id: 1b40bfed-55c1-4230-b3fa-e94baf9ea042,model_name: lasso, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 8.0using 3251.59 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (28, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 18, model_id: e01958d4-5108-496d-8b94-6468bab00c07,model_name: lasso, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 21.428571428571427using 3391.12 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (25, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 18, model_id: 3da22f8a-3dc5-437d-b8c4-920d121f9b16,model_name: lasso, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 16.0using 3429.07 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 19, model_id: 34556e90-faee-42c3-848d-4452858a987e,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 34.78260869565217using 3430.24 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 101)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 18, model_id: b07947bc-c0ba-4ee7-970a-c52eec58c94e,model_name: lasso, impute_method: directly, model_selector: hard_threshold_100, eval_metric: 10.0using 3481.98 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 11), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.331257, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.523730, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-9.997555, total=   1.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.504163, total=   3.2s
[CV] model__n_estimators=500 .........................................
[CV] ........ model__n_estimators=500, score=-10.333475, total=   3.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.326708, total=   3.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.328707, total=   6.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.500262, total=   6.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.2s remaining:    4.3s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.0s remaining:    2.0s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    6.8s finished
INFO:__main__:It takes 1811.88 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.548218, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.107119, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.144040, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.113262, total=   2.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.568779, total=   2.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.139916, total=   3.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.140838, total=   5.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.581015, total=   3.9s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.6s remaining:    5.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.4s remaining:    2.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.0s finished
INFO:__main__:It takes 1765.88 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.002331, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-8.925681, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.336382, total=   1.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-8.899941, total=   2.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.336898, total=   4.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.987867, total=   3.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-8.848635, total=   5.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.333593, total=   7.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.993068, total=   5.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.5s remaining:    5.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.2s remaining:    2.6s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.0s finished
INFO:__main__:It takes 1921.39 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.696291, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.203589, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.233400, total=   1.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.211671, total=   3.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.625945, total=   2.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.233290, total=   3.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-1.726902, total=   4.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.214751, total=   5.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.236645, total=   6.9s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.3s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.4s remaining:    2.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.6s finished
INFO:__main__:It takes 1805.69 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-9.692940, total=   0.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.903983, total=   0.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.335485, total=   0.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-9.747049, total=   2.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.837880, total=   3.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.334084, total=   3.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.835241, total=   7.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-9.717152, total=   4.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.336753, total=   7.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.0s remaining:    3.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    3.6s remaining:    1.8s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.8s finished
INFO:__main__:It takes 1814.54 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 11), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-5.493033, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.348706, total=   1.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-5.466348, total=   3.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.345005, total=   3.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.293015, total=   4.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.343158, total=   6.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-5.556337, total=   5.6s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.6s remaining:    5.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.9s remaining:    2.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.5s finished
INFO:__main__:It takes 1808.16 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.047359, total=   4.0s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.168190, total=   4.5s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.067769, total=   4.5s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.799533, total=   4.7s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.819971, total=   4.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.842210, total=   5.5s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.847656, total=   5.5s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.854269, total=   6.3s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.896728, total=   6.5s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.168859, total=   6.8s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.047304, total=   7.2s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.074344, total=   8.4s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.066938, total=   9.0s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.056669, total=   9.2s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.204438, total=  10.1s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.6s remaining:   29.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.4s remaining:    5.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   10.2s finished
INFO:__main__:It takes 1773.44 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.062971, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-8.878506, total=   1.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.314992, total=   1.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-8.877925, total=   3.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-8.738859, total=   3.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.318389, total=   4.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.102417, total=   3.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-1.118305, total=   5.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.317303, total=   6.3s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.3s remaining:    4.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.8s remaining:    2.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.1s finished
INFO:__main__:It takes 1816.07 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 19, model_id: d14a5fce-49a0-4f4d-a5f6-5552e44cfcdf,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 8.0using 3790.10 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 19, model_id: 44e1e0ba-411e-4310-97f1-226f47deb7e1,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 41.66666666666667using 3608.52 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 19, model_id: ae662027-28b6-44cb-b26e-fbdc9531481b,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 28.000000000000004using 3663.93 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 19, model_id: 617259d0-2214-4921-b902-ce2d1de0a284,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 13.793103448275861using 3859.42 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 19, model_id: 568179fd-ffa0-48e9-bd7e-f322cfb2fbff,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 7.142857142857142using 3660.76 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 19, model_id: 5afa0886-6908-4010-b529-78e30e6e9cd7,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 16.0using 3665.08 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 20, model_id: 8e9f1a5f-5210-4e47-97c6-0b4a8132b7fa,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 26.08695652173913using 3619.41 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 19, model_id: 3b3b5168-c482-45ae-a5ff-fa24e0c665bc,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 10.0using 3636.84 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.390194, total=   3.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.682651, total=   4.4s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.933473, total=   4.7s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.869023, total=   5.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.345967, total=   6.5s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.941678, total=   7.0s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.088291, total=   7.5s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.778795, total=   8.0s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.114330, total=   8.4s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.684128, total=   8.6s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.126056, total=   9.5s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.101217, total=   9.9s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.102277, total=  10.8s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.816564, total=  11.1s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.5s remaining:   29.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.1s remaining:    7.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   13.5s finished
INFO:__main__:It takes 1785.72 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 11), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.833245, total=   5.5s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.777715, total=   5.5s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.632065, total=   5.9s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.900304, total=   5.9s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.787354, total=   6.2s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.974954, total=   6.4s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.094464, total=   6.7s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.892958, total=   6.7s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.083134, total=   7.3s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.238988, total=   8.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.308710, total=   9.2s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-1.454406, total=  10.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.288717, total=  12.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.6s remaining:   36.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.7s remaining:    5.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.3s finished
INFO:__main__:It takes 1936.51 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.709179, total=   2.8s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.015944, total=   3.3s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.008776, total=   4.6s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-1.726402, total=   5.5s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.179369, total=   6.8s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.182602, total=   7.1s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.894518, total=   7.2s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.814247, total=   7.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.249668, total=   7.3s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.169264, total=   7.4s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.164008, total=   8.7s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.167308, total=   8.7s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.892408, total=   9.1s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.4s remaining:   22.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.3s remaining:    6.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    9.9s finished
INFO:__main__:It takes 1883.23 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.361378, total=   2.3s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.798836, total=   2.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.190677, total=   2.7s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.644650, total=   3.1s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.994045, total=   3.2s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.002102, total=   4.1s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.557252, total=   4.5s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.911230, total=   5.0s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-1.806428, total=   5.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.875712, total=   5.5s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.252116, total=   5.6s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.066092, total=   6.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.542235, total=   7.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.7s remaining:   17.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.2s remaining:    4.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    9.5s finished
INFO:__main__:It takes 1863.50 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.774470, total=   3.9s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.747021, total=   3.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.080702, total=   4.0s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.748909, total=   4.1s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.917498, total=   4.3s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.069831, total=   4.7s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.262712, total=   5.5s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.786727, total=   6.1s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.735055, total=   6.3s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.864316, total=   8.0s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.052425, total=   9.3s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.161533, total=   9.7s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-4.495611, total=  10.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.289192, total=  13.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.1s remaining:   26.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.1s remaining:    5.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.4s finished
INFO:__main__:It takes 1993.23 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 11), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.879645, total=   3.4s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.709670, total=   4.4s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.082024, total=   5.2s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.701657, total=   5.2s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.863101, total=   6.0s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.635948, total=   6.1s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.875140, total=   6.7s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.039540, total=   6.8s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.033364, total=   7.0s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.096107, total=   7.1s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.883222, total=   7.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.036835, total=   7.4s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.684114, total=   8.0s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.111834, total=   8.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.5s remaining:   29.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.9s remaining:    6.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    8.6s finished
INFO:__main__:It takes 2022.56 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.097666, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.022544, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.022857, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.098035, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.054731, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.051033, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.022889, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.024138, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.105070, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.098071, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.054291, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.094856, total=   0.3s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.054354, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.054428, total=   2.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.054442, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.0s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.3s finished
INFO:__main__:It takes 1904.37 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.710461, total=   4.0s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.003622, total=   5.3s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.752923, total=   5.6s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.650757, total=   6.3s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.211198, total=   6.3s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.636838, total=   6.4s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.857239, total=   6.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-1.237254, total=   7.0s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.717632, total=   7.5s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.804756, total=   7.6s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-1.248541, total=   8.1s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.220131, total=   8.4s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.286883, total=   8.4s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.864755, total=  11.7s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.222725, total=   9.9s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.6s remaining:   36.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.1s remaining:    6.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   11.7s finished
INFO:__main__:It takes 1941.18 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 20, model_id: 7c209f74-4ac9-491f-890d-870c8017c2c3,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 37.5using 3746.82 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 20, model_id: c23a87f6-db82-4121-8897-5526fe0a8ce3,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 12.0using 4042.83 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 20, model_id: 6dd6ebd7-5112-471d-a6ab-76553f9e84c1,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 40.0using 3784.10 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 20, model_id: 067868f8-a69e-4f5e-a75c-c6042fe30788,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 3.571428571428571using 3743.33 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 20, model_id: 287ec1b2-f411-4efc-96b8-dc97f8ef1c49,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 0.0using 4039.65 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 20, model_id: b2cf8d25-6f1a-4084-8109-1051262ff8f6,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 0.0using 3936.55 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 21, model_id: 0c4e541a-6027-4bfc-8114-2371acbf91f7,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 39.130434782608695using 3859.86 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 20, model_id: 146c4511-7907-4704-aeb1-370ef482996a,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 10.0using 3924.84 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.052615, total=   0.3s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.427223, total=   0.3s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.095937, total=   0.1s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.095882, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.453484, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.339930, total=   0.3s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.090481, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.112494, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.105096, total=   0.3s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.453090, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.453480, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.052197, total=   0.4s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.110698, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.112513, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.112676, total=   0.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.3s remaining:    2.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.4s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.4s finished
INFO:__main__:It takes 1970.54 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 11), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.142707, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.715230, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.142092, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.715179, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.685683, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.088642, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.714736, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.136602, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.714327, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.145916, total=   1.7s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.161401, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.150654, total=   1.6s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.097353, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.161158, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.0s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.7s remaining:    1.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.8s finished
INFO:__main__:It takes 2039.84 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 11), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-1.308813, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.938673, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.272001, total=   0.0s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.256877, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-1.289314, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.204837, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-1.308973, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.256068, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.228896, total=   3.3s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.209029, total=   3.2s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.205591, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.191943, total=   0.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-1.236106, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.212795, total=   0.0s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.205829, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.3s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    4.0s finished
INFO:__main__:It takes 2298.52 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.224432, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-1.643159, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.351928, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-1.643165, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-1.643005, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.352961, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.224194, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.342782, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-1.510668, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.296110, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-1.643165, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.352951, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.235061, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.222661, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.224430, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.4s finished
INFO:__main__:It takes 2039.24 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 11), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.971591, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.188695, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.188701, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.182424, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.971590, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.971594, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.180150, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.188637, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.971916, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.147749, total=   1.1s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.974164, total=   1.1s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.182118, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.182137, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.182139, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.171451, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.0s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.1s remaining:    1.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.2s finished
INFO:__main__:It takes 2059.58 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-1.987191, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.470458, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-1.924278, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-1.421470, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.358146, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.439391, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-1.811791, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.369927, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-1.987535, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.457786, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.263380, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.232431, total=   0.0s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.252254, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.257496, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.248891, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.0s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.1s finished
INFO:__main__:It takes 2198.30 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 21, model_id: 8e23059e-005e-49db-b0fe-d9e86126c44c,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 37.5using 3125.05 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.059864, total=   2.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.058736, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.182511, total=   1.4s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.1s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.1s remaining:    3.1s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.5s finished
INFO:__main__:It takes 2033.42 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 11), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-2.282383, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-2.282265, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-2.282268, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.598879, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.445174, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.583862, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-2.282293, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.598729, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.597363, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-2.101790, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.272266, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.274440, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.270378, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.3s finished
INFO:__main__:It takes 2061.32 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 21, model_id: cee1103f-84ba-4479-b1b3-6a1016122c64,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 32.0using 4010.47 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 21, model_id: b414e0ee-e865-46ac-ad8e-8393f2e1d7c8,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 4.0using 4321.31 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 21, model_id: 74e1e6f0-21ee-4c7a-8c10-b3e78d50191a,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 3.571428571428571using 4037.14 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 21, model_id: fbe08759-4934-4be3-bdbc-1de169a422d4,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 20.0using 4081.51 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 21, model_id: 05927872-9fac-4af1-9c5f-f0cfcf1c3ce2,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 0.0using 4405.60 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 22, model_id: 187db136-0729-4ad9-9630-45da4f94a863,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 26.08695652173913using 4055.11 seconds
INFO:__main__:




impute_method: directly

[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.743625, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.101726, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.141516, total=   1.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.105792, total=   3.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.773675, total=   3.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.141621, total=   6.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.141521, total=   5.5s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.5s remaining:    5.4s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.2s remaining:    3.1s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.1s finished
INFO:__main__:It takes 2098.51 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 11)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 21, model_id: e2234356-698a-4d2c-90be-00a60a81a818,model_name: lasso, impute_method: directly, model_selector: hard_threshold_10, eval_metric: 6.666666666666667using 4095.70 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-2.034884, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.225993, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.240492, total=   3.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-2.107148, total=   4.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.239635, total=   5.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.221141, total=   3.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.228150, total=   7.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.6s remaining:    9.1s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.5s remaining:    3.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.8s finished
INFO:__main__:It takes 2024.91 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-9.275369, total=   3.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.813214, total=   2.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.316142, total=   5.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.320723, total=   5.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-9.631294, total=   5.5s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    5.4s remaining:   18.9s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.2s remaining:    3.1s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    8.0s finished
INFO:__main__:It takes 2017.65 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 21), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-8.807229, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.636738, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.355701, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-9.686467, total=   4.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.655789, total=   5.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.332542, total=   8.3s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.3s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.6s remaining:    3.3s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.5s finished
INFO:__main__:It takes 2308.79 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 21), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-4.469845, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.423274, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.329358, total=   1.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.341500, total=   6.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-4.695794, total=   7.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.448287, total=   7.1s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.7s remaining:    5.8s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.9s remaining:    3.9s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   14.2s finished
INFO:__main__:It takes 2035.46 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 22, model_id: d3006855-73e9-4661-ba73-0efbafa5836d,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 50.0using 4119.58 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.025306, total=   5.7s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.839685, total=   5.8s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.806971, total=   6.2s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.800288, total=   6.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.857511, total=   6.5s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.140857, total=   7.5s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.012500, total=   7.5s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.086632, total=   8.6s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.332336, total=   8.9s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.063898, total=   9.2s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.311002, total=  10.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.056466, total=  13.4s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.065752, total=  14.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.8s remaining:   37.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.7s remaining:    7.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   15.5s finished
INFO:__main__:It takes 2104.47 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.335918, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.922472, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-8.712691, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-8.776402, total=   3.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.326177, total=   4.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.969317, total=   4.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-8.773217, total=   5.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.323017, total=   8.4s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.4s remaining:    8.3s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.1s remaining:    3.0s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.3s finished
INFO:__main__:It takes 2279.78 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-8.682213, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.316981, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-1.175771, total=   1.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-8.851598, total=   2.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-1.122897, total=   4.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.317800, total=   4.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-8.709169, total=   6.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.317994, total=   8.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-1.113513, total=   7.5s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.9s remaining:    6.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.4s remaining:    2.7s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.8s finished
INFO:__main__:It takes 2044.55 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 22, model_id: ec30a370-0a44-4e17-8abc-a98b995ef1a3,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 28.000000000000004using 3965.55 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 22, model_id: ad00d9ef-5807-45a5-af0a-b17e2ade32f5,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 10.714285714285714using 3934.91 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 22, model_id: 9e80325e-4faa-40e8-85bc-03006ce3cf36,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 16.0using 3925.12 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 22, model_id: c74448f0-2944-4a3e-a8e9-30770ec40943,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 8.0using 4484.46 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 23, model_id: 3e668daf-1624-43f0-a6b5-53b922ec6a87,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 34.78260869565217using 3979.80 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.223110, total=   2.3s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.916939, total=   2.8s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.707387, total=   3.0s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.194080, total=   3.7s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.939828, total=   4.0s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.851337, total=   4.5s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.090238, total=   5.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-2.588465, total=   6.4s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.124535, total=   9.1s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.115764, total=  10.3s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.145431, total=  11.8s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-1.135886, total=  11.8s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-1.787639, total=  12.5s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.098500, total=  15.2s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.131876, total=  17.5s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.9s remaining:   19.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.6s remaining:    5.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   17.7s finished
INFO:__main__:It takes 2166.69 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 22, model_id: 14bd8a42-3262-42bf-896e-3a2122f4aec0,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 16.666666666666664using 4000.88 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 22, model_id: 812db3f9-a2a1-452e-8044-4c850f29f2ae,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 10.344827586206897using 4418.12 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-5.863521, total=   4.0s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.205294, total=   4.9s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.751300, total=   5.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.191691, total=   5.2s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.530112, total=   5.2s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.869853, total=   5.5s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.554278, total=   6.0s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.866808, total=   6.1s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.048846, total=   6.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.056250, total=   6.8s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.860949, total=   6.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-4.825425, total=   7.2s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.023955, total=   7.1s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.242996, total=  10.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.1s remaining:   33.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.1s remaining:    5.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   10.4s finished
INFO:__main__:It takes 1908.64 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.834255, total=   3.3s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.199820, total=   3.6s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.722328, total=   3.9s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-8.602857, total=   3.9s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.753709, total=   3.9s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.252082, total=   4.2s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-6.410497, total=   5.5s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.252026, total=   5.5s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.603569, total=   5.8s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.601836, total=   5.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.663622, total=   7.1s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-6.490142, total=   7.6s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.894900, total=   8.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.284435, total=  11.1s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.202554, total=   9.6s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.8s remaining:   24.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.6s remaining:    4.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   11.3s finished
INFO:__main__:It takes 1890.85 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 21), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.014968, total=   2.7s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.533783, total=   2.8s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.731168, total=   3.6s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.707530, total=   4.5s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.842103, total=   4.5s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.127749, total=   6.5s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-6.331785, total=   6.7s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.272688, total=   8.2s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-6.011135, total=   8.8s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.273512, total=   9.2s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.322446, total=   9.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-6.252668, total=   9.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.403941, total=  11.1s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.9s remaining:   19.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.3s remaining:    7.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   16.5s finished
INFO:__main__:It takes 1836.31 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 21), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.209205, total=   4.3s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.851643, total=   4.7s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.568345, total=   4.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.573279, total=   5.5s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.896592, total=   5.6s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.074286, total=   5.5s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.977969, total=   5.7s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.879128, total=   5.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.079103, total=   6.8s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-7.666321, total=   8.4s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-6.239621, total=   8.9s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.269178, total=  11.5s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.249127, total=  16.5s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.116266, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.118326, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.106990, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.107170, total=   3.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.054672, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.107188, total=   3.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.084230, total=   3.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.054840, total=   3.1s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.054875, total=   2.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.022896, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.083960, total=   3.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    3.5s remaining:    3.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    4.0s finished
INFO:__main__:It takes 1883.04 seconds to train this model.
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.8s remaining:   31.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.0s remaining:    5.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   16.7s finished
INFO:__main__:It takes 2060.67 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 23, model_id: 91443d12-89d9-4e45-b38a-03a7f6c45cc2,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 41.66666666666667using 4000.86 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.775200, total=   3.7s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.624925, total=   3.3s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.350981, total=   4.4s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.112173, total=   3.8s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.864301, total=   4.8s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.127469, total=   4.9s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.779247, total=   7.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.838504, total=   7.3s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-5.016026, total=   8.0s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.984664, total=   8.0s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.853188, total=   8.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.272452, total=  10.3s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.400887, total=  11.6s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.254296, total=  12.4s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-2.161991, total=  13.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.8s remaining:   24.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.3s remaining:    6.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   13.4s finished
INFO:__main__:It takes 1888.60 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.773375, total=   3.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.544651, total=   4.2s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.197910, total=   4.5s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-3.036688, total=   5.4s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.226186, total=   5.7s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.243290, total=   5.8s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.833352, total=   6.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-5.157076, total=   6.2s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.245770, total=   6.3s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.661851, total=   6.6s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.744199, total=   7.2s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.113912, total=   7.9s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-1.819781, total=   8.5s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.713158, total=   9.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.241651, total=   9.9s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.3s remaining:   27.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.3s remaining:    5.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   10.0s finished
INFO:__main__:It takes 1982.79 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 23, model_id: 85ec528c-8f3f-4f39-8291-e6c241b3202c,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 0.0using 3883.37 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 23, model_id: 2ef113dc-0adb-4ff8-a7c0-fb79b21cfac6,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 0.0using 3829.85 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 23, model_id: 73d74860-6dca-4cc3-ab77-ab1fa093fa82,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 0.0using 3746.29 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 24, model_id: 8799c0dd-031f-46ca-b3eb-650cb4bb9445,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 52.17391304347826using 3917.84 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.106352, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.111228, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ............ model__alpha=0.0001, score=-59.169498, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-13.836495, total=   1.8s
[CV] model__alpha=0.0001 .............................................
[CV] ............ model__alpha=0.0001, score=-66.997909, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............. model__alpha=1e-05, score=-86.294599, total=   1.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............. model__alpha=0.001, score=-74.851410, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] ............. model__alpha=0.001, score=-21.525963, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.113512, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............. model__alpha=1e-08, score=-50.332265, total=   1.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............. model__alpha=1e-08, score=-88.950774, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............. model__alpha=1e-05, score=-50.878946, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.731157, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.099786, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.110720, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.7s remaining:    4.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    2.0s remaining:    1.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.1s finished
INFO:__main__:It takes 2027.39 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 23, model_id: 875fc535-cea9-413c-9dcf-b7c703f3a840,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 0.0using 4318.12 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 23, model_id: d20ba653-b91c-4580-8f8b-206ead7ef7cf,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 0.0using 3898.55 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 23, model_id: 85e41df7-0ad4-4d08-9d37-23feda272b05,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 0.0using 4215.67 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 21), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-133.411400, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-132.453951, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-146.771311, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-129.457675, total=   2.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.178344, total=   1.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.178885, total=   1.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-132.454801, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-132.548249, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-135.620128, total=   2.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.160465, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-135.949739, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.173452, total=   2.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-135.952739, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    2.9s remaining:    2.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    3.3s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 2043.27 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-292.441830, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-250.252541, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-151.327068, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-280.314234, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-140.775381, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-292.334506, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-103.448979, total=   0.0s
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-150.858743, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.385445, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.694313, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-7.515377, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.384017, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.464260, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-151.287868, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.4s remaining:    0.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.5s finished
INFO:__main__:It takes 2057.97 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 21), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-2.725481, total=   0.3s
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-226.780423, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-226.822395, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-62.840549, total=   0.7s
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-203.392167, total=   0.9s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-164.579326, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-226.784670, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.214133, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............. model__alpha=0.001, score=-81.382057, total=   0.9s
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-164.552655, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-164.555299, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.246662, total=   0.7s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.213565, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.271040, total=   0.8s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.214077, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.8s remaining:    5.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.9s remaining:    0.8s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.8s finished
INFO:__main__:It takes 2331.49 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.060947, total=   0.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.052577, total=   2.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.061358, total=   2.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.185931, total=   3.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.060554, total=   3.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.201337, total=   4.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.206766, total=   5.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.061476, total=   5.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.060183, total=   6.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    3.3s remaining:   11.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.8s remaining:    2.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    7.3s finished
INFO:__main__:It takes 2108.96 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 24, model_id: dcf4f17e-1f2c-4d4b-b137-66ea62b61561,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 37.5using 4103.59 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-344.474807, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-352.114357, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-351.864589, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-242.954111, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-351.862032, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-292.981846, total=   0.0s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.955865, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-248.388341, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.778550, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.778776, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.754050, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-248.383720, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.626770, total=   0.1s
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-247.873823, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-230.804751, total=   0.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.3s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.0s finished
INFO:__main__:It takes 2144.32 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 21), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-284.167864, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-284.170424, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-284.142073, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-103.752644, total=   0.0s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-165.353759, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.261698, total=   1.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-284.170680, total=   2.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-165.353460, total=   1.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.261707, total=   1.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-165.386445, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.358584, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.260690, total=   2.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-2.462370, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-165.356746, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.261606, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.0s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    2.2s remaining:    1.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.5s finished
INFO:__main__:It takes 2505.93 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 21), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-320.616822, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-320.672306, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-310.370787, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.593496, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-178.480660, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-320.678207, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-319.934031, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.595434, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-178.723397, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.511149, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-185.416118, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.595647, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.574273, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-179.615157, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-178.455122, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.2s remaining:    0.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.1s finished
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
INFO:__main__:It takes 2109.81 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 24, model_id: 794b21fa-fb09-494a-88fc-f58c47a831c4,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 28.000000000000004using 4136.71 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 24, model_id: e947cb67-f900-4142-be5f-cedc574a5f70,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 3.571428571428571using 4203.63 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 24, model_id: b2d9b436-5314-475f-aced-4ce5337a2009,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 20.0using 4486.22 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 25, model_id: f5754894-927b-4531-883d-b0741b08525b,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 21.73913043478261using 4263.64 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 24, model_id: 097c2dd4-c74b-4d6a-85c2-f473035cd54e,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 6.666666666666667using 4310.47 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.838373, total=   0.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.104861, total=   0.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.129298, total=   0.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.867976, total=   3.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.104742, total=   5.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.127254, total=   6.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.126510, total=   9.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.8s remaining:    2.9s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.5s remaining:    3.3s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.6s finished
INFO:__main__:It takes 2465.72 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 24, model_id: e7d11322-e313-4db1-99cc-ac245c87d491,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 3.4482758620689653using 4548.29 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 21)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 24, model_id: 02b30b2a-b76f-4b47-84a3-1e9fbdf2c461,model_name: lasso, impute_method: directly, model_selector: hard_threshold_20, eval_metric: 8.0using 5025.59 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-3.448746, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.226964, total=   1.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.201170, total=   2.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-2.765485, total=   2.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.242013, total=   4.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-3.022935, total=   4.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.199775, total=   5.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.2s remaining:    7.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.5s remaining:    2.7s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.6s finished
INFO:__main__:It takes 2184.24 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.676973, total=   3.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-5.816410, total=   3.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.296433, total=   3.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.297946, total=   8.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-6.816753, total=   4.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.641237, total=   8.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-6.848727, total=   9.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.295343, total=  10.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.648345, total=   9.6s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    4.0s remaining:   14.1s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.9s remaining:    4.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   13.1s finished
INFO:__main__:It takes 2119.43 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 31), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-4.214166, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.260792, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.455773, total=   1.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-4.152624, total=   4.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.435240, total=   5.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.257128, total=   6.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.438287, total=   9.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-4.528341, total=   6.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.260012, total=  10.1s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.9s remaining:    6.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.3s remaining:    3.6s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.7s finished
INFO:__main__:It takes 2146.96 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.841895, total=   6.0s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.787350, total=   6.4s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.825969, total=   6.6s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.841729, total=   6.7s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.740151, total=   7.1s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.731102, total=   7.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.919595, total=   7.5s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.846939, total=   7.6s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.020243, total=   7.7s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.919519, total=   7.8s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.730066, total=   8.1s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.916578, total=   8.3s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.053263, total=   8.5s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.206480, total=  14.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    6.4s remaining:   41.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.7s remaining:    6.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.9s finished
INFO:__main__:It takes 2152.67 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-6.357493, total=   1.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.823923, total=   2.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.287999, total=   2.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-6.686548, total=   3.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.856422, total=   4.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.294035, total=   6.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-6.689566, total=   5.9s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.8s remaining:    9.9s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.4s remaining:    3.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.2s finished
INFO:__main__:It takes 2128.94 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 25, model_id: da23e307-db35-4e87-a9f5-33f2c233420d,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 25.0using 4589.79 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 25, model_id: 7ff6cecd-b38f-4e7e-85be-2896949bf628,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 14.285714285714285using 4172.87 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 25, model_id: 288a206d-3e2d-4784-b347-bf9369c91be5,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 16.0using 4285.73 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-6.367035, total=   3.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-6.708314, total=   2.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.736949, total=   4.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.285033, total=   4.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-6.712557, total=   6.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.745540, total=   6.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.297078, total=   7.6s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.749277, total=   8.9s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    3.9s remaining:   13.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.4s remaining:    3.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.4s finished
INFO:__main__:It takes 2402.75 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 31), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-6.578362, total=   0.7s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.604049, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.268908, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.574498, total=   3.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-7.063575, total=   2.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.277014, total=   5.2s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.6s remaining:    5.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.7s remaining:    2.8s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   13.6s finished
INFO:__main__:It takes 2453.79 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 25, model_id: b0832e85-fa91-4ce9-8a24-0ec6ae6a9657,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 28.000000000000004using 4235.30 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 26, model_id: 1dcfc716-fd76-496c-99bf-d890a252932e,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 26.08695652173913using 4230.26 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 25, model_id: f629994e-477a-4088-a869-ae4df85d230d,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 13.333333333333334using 4171.19 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-1.840258, total=   2.5s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.110951, total=   4.2s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.112133, total=   4.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.302827, total=   4.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.926994, total=   4.7s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.707048, total=   4.7s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.240644, total=   5.2s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.119014, total=   5.7s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-1.268414, total=   6.6s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.874777, total=   6.6s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.880231, total=   6.8s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.958094, total=   7.0s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.966714, total=   7.4s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.123235, total=   8.2s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.171404, total=   8.1s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.6s remaining:   30.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.0s remaining:    6.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    9.4s finished
INFO:__main__:It takes 2119.68 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-3.437959, total=   4.7s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.479291, total=   5.1s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.249105, total=   5.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.669226, total=   6.0s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.482012, total=   6.7s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.313910, total=   6.9s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.530928, total=   7.2s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.955812, total=   8.6s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.962169, total=   8.8s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.336253, total=   8.7s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.379346, total=   8.8s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.505093, total=  10.0s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.933624, total=  11.8s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-3.423060, total=  12.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.2s remaining:   33.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.7s remaining:    7.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   16.4s finished
INFO:__main__:It takes 2079.95 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.182438, total=   3.6s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-5.121089, total=   3.8s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.178883, total=   4.1s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.254638, total=   4.1s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-3.533435, total=   4.2s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.163196, total=   4.2s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.694971, total=   5.3s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.890953, total=   5.8s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.059254, total=   6.6s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-2.313945, total=   6.8s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.185540, total=   7.7s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.185083, total=   8.0s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.168275, total=   9.1s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-2.225462, total=  10.7s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.9s remaining:   25.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.9s remaining:    5.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   12.7s finished
INFO:__main__:It takes 2167.33 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 25, model_id: 10ae63a4-f46e-4022-92e0-b38d96c3eac6,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 3.4482758620689653using 4556.84 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 25, model_id: 23a2692a-70f3-4c87-8cf0-66e5b6c6149a,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 28.000000000000004using 4991.68 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 31), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.538383, total=   5.0s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.867108, total=   5.9s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.700481, total=   6.1s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.872180, total=   6.2s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.197078, total=   6.3s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.878338, total=   7.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.713530, total=   7.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.237294, total=   7.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.276844, total=   8.0s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-5.663895, total=   8.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.067370, total=   8.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.996972, total=   8.2s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.313625, total=   8.5s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.012099, total=   9.9s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.9s remaining:   38.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.9s remaining:    6.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   10.6s finished
INFO:__main__:It takes 2502.57 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.126492, total=   5.4s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.058099, total=   5.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.202770, total=   6.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.024205, total=   6.2s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.130321, total=   6.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.056049, total=   6.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.052857, total=   6.2s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.207973, total=   6.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.057908, total=   6.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.117691, total=   6.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.208566, total=   6.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.116266, total=   6.2s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.133242, total=   6.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.050230, total=   6.3s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.048168, total=   6.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.4s remaining:   35.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    6.4s remaining:    5.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    6.5s finished
INFO:__main__:It takes 2225.67 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.567367, total=   3.3s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.505541, total=   3.4s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.225658, total=   4.3s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.190957, total=   4.3s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.898328, total=   4.4s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.856507, total=   4.5s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.765960, total=   5.5s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.894853, total=   5.5s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.739807, total=   6.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.066460, total=   6.2s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.894889, total=   7.0s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-4.945609, total=   8.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.5s remaining:   22.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.6s remaining:    4.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.0s finished
INFO:__main__:It takes 2249.09 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 26, model_id: 4855c11d-3fa2-4857-9fbb-fc15c4e766b6,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 25.0using 4299.71 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 26, model_id: 105ccae4-72b0-4226-897f-86ac162155b5,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 3.571428571428571using 4221.96 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 26, model_id: 3170914f-866b-4fca-81c0-35ae2ecf5549,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 28.000000000000004using 4323.45 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.219942, total=   2.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-3.450063, total=   3.0s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.612229, total=   3.7s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-3.072760, total=   5.4s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-1.015779, total=   6.0s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.316274, total=   7.0s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-3.337591, total=   7.1s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.504613, total=   7.9s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.230985, total=   9.5s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.943666, total=   9.8s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.846210, total=   9.9s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.298432, total=  10.1s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.716653, total=  16.2s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-3.163862, total=  16.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.2s remaining:   20.8s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.0s remaining:    7.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   18.2s finished
INFO:__main__:It takes 2474.16 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 31), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.477935, total=   6.6s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.895220, total=   7.2s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-3.921899, total=   7.5s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.627755, total=   7.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.312704, total=   8.3s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-3.806116, total=   8.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-5.112719, total=   8.8s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.321876, total=   9.5s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.575365, total=   9.8s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.360903, total=   9.9s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.185400, total=  10.0s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-4.323747, total=  13.1s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    7.4s remaining:   47.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    9.6s remaining:    8.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.4s finished
INFO:__main__:It takes 2471.03 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 26, model_id: 452e84ea-54b7-48f7-9ef9-71bb571fca09,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 0.0using 4617.17 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 27, model_id: ec8bb5d5-785c-4afe-aaad-64808f371d6c,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 52.17391304347826using 4401.37 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 26, model_id: b3ccf1b0-3798-4590-8636-6a38f394d55f,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 0.0using 4413.67 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] ............. model__alpha=1e-07, score=-96.745219, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............. model__alpha=1e-05, score=-72.212120, total=   1.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.098192, total=   2.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-18.926867, total=   2.7s
[CV] model__alpha=1e-06 ..............................................
[CV] ............. model__alpha=1e-06, score=-73.914766, total=   2.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.114878, total=   2.7s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-1.385489, total=   2.7s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.099317, total=   2.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............. model__alpha=1e-09, score=-74.120295, total=   2.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.099198, total=   2.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............. model__alpha=1e-09, score=-96.739750, total=   2.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............. model__alpha=1e-05, score=-97.309352, total=   2.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.099330, total=   2.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............. model__alpha=1e-06, score=-96.795096, total=   2.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............. model__alpha=1e-07, score=-74.099839, total=   2.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.3s remaining:   15.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    2.9s remaining:    2.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    3.1s finished
INFO:__main__:It takes 2164.41 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-317.335718, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-217.273234, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-217.261585, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.234109, total=   1.3s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.285073, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.276948, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-317.539352, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-312.415689, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-230.991514, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-317.537496, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-218.495196, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-150.795570, total=   1.6s
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-268.180822, total=   1.7s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.203387, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.284997, total=   2.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    1.3s remaining:    8.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.6s remaining:    1.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.7s finished
INFO:__main__:It takes 2019.97 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 31), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-205.817137, total=   0.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.219247, total=   1.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-114.937634, total=   2.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-209.827158, total=   2.0s
[CV] model__alpha=0.001 ..............................................
[CV] ............. model__alpha=0.001, score=-42.142080, total=   2.0s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.218889, total=   2.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-205.822123, total=   2.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.219283, total=   2.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-112.065745, total=   2.2s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-114.773532, total=   2.2s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-114.954040, total=   2.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-205.872304, total=   2.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-221.690735, total=   2.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.152559, total=   2.3s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.131511, total=   2.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.0s remaining:   13.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    2.4s remaining:    2.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.5s finished
INFO:__main__:It takes 2056.18 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 26, model_id: d1cfe360-de46-4e1c-ab08-72b490ea0ef0,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 0.0using 4520.66 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.189618, total=   4.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.062484, total=   4.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.051856, total=   4.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.194045, total=   5.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.059079, total=   4.3s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    4.8s remaining:   16.6s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.5s remaining:    4.3s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.4s finished
INFO:__main__:It takes 2050.96 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 26, model_id: 8c126ce1-b6b3-4022-92c7-6c23a2d669e0,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 0.0using 4843.98 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 31), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-258.230566, total=   0.5s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.160835, total=   0.7s
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.374158, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-294.165904, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-295.569362, total=   1.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.382696, total=   1.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-152.607489, total=   2.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-294.010821, total=   2.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.381801, total=   2.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-152.778407, total=   2.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.224317, total=   2.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-300.703317, total=   2.6s
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-167.892978, total=   2.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-154.421244, total=   2.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............. model__alpha=0.001, score=-75.811886, total=   2.9s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.8s remaining:    5.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    2.5s remaining:    2.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    3.1s finished
INFO:__main__:It takes 2337.05 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-109.840285, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-32.390640, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.448281, total=   0.0s
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-356.169956, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-356.125540, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-342.105772, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.191943, total=   0.3s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.191763, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.189711, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.161092, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-344.009880, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-358.452279, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-342.279465, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-345.458348, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-355.663569, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.4s remaining:    0.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.6s finished
INFO:__main__:It takes 2066.59 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 27, model_id: ab0d72e5-b64d-4c19-b1b8-37b978dc1a57,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 25.0using 4238.68 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 27, model_id: 26ccc993-eba6-43ca-9518-7df8238162b2,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 17.857142857142858using 4080.60 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 27, model_id: c5bb45b9-5a73-460e-aba5-2fff0242a935,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 16.0using 4150.73 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 31), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-347.580138, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-263.464922, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.183003, total=   1.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.233417, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-347.611075, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-263.463511, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.278862, total=   1.2s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-347.580418, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-279.041358, total=   1.2s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.233109, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-221.817153, total=   1.3s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.233415, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-339.045008, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-263.619838, total=   1.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-276.217966, total=   1.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    1.3s remaining:    8.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.3s remaining:    1.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.0s finished
INFO:__main__:It takes 2357.86 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 28, model_id: 74766678-bd53-49b9-bfea-18215a65a1a4,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 30.434782608695656using 4141.28 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 31), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.429432, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.199342, total=   0.7s
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.266276, total=   1.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-186.873975, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-324.458340, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-324.615298, total=   1.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.430639, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-208.258017, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-325.591282, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-113.590341, total=   1.1s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-186.641086, total=   1.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-299.180633, total=   1.2s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-4.984770, total=   1.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.221511, total=   1.1s
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-110.236330, total=   1.4s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    1.0s remaining:    6.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.6s remaining:    1.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.8s finished
INFO:__main__:It takes 2096.98 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 27, model_id: 3fc217ca-2b77-43e4-a83b-5cb56661e8ae,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 8.0using 4420.15 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 27, model_id: 14a97797-17e5-4540-998c-ea1946249e31,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 10.0using 4240.91 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.806303, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.128988, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.109804, total=   2.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.843866, total=   3.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.129190, total=   5.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.106429, total=   4.3s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.4s remaining:    4.9s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    5.8s remaining:    2.9s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.2s finished
INFO:__main__:It takes 2108.25 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-5.841590, total=   0.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.593308, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.284808, total=   0.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.592747, total=   4.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-6.660913, total=   2.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.287898, total=   6.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-6.645911, total=   7.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.593677, total=  10.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.284751, total=  12.1s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.0s remaining:    3.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.5s remaining:    3.8s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   13.2s finished
INFO:__main__:It takes 2112.92 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-2.191613, total=   3.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.218569, total=   3.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.196440, total=   4.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-2.166240, total=   5.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.220619, total=   7.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.206924, total=   8.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.223962, total=   9.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-2.254629, total=   9.1s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    4.3s remaining:   15.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.8s remaining:    4.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   13.2s finished
INFO:__main__:It takes 2192.16 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 27, model_id: 8c61e9e9-700f-49f0-8890-6d1ac3d3b8d4,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 10.344827586206897using 4425.04 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.050904, total=   5.8s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.229717, total=   6.2s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.054586, total=   6.3s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.798477, total=   6.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.772307, total=   7.1s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.851268, total=   7.4s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.868776, total=   8.1s
[CV] model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.923550, total=   8.7s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.947444, total=   9.3s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.279068, total=  13.8s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.072368, total=  14.2s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.059780, total=  17.5s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.063103, total=  19.4s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.079406, total=  17.7s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    6.3s remaining:   40.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.8s remaining:    7.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   19.5s finished
INFO:__main__:It takes 2077.93 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.707879, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.293457, total=   0.8s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-6.676452, total=   2.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-7.158096, total=   3.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.293544, total=   7.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.730391, total=   5.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-7.097712, total=   5.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.736691, total=   9.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.290689, total=  10.7s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.1s remaining:    7.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    6.5s remaining:    3.2s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   11.2s finished
INFO:__main__:It takes 2106.79 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 28, model_id: fe781077-159e-41fb-ba1d-7b5d915229d1,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 29.166666666666668using 4208.25 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 41), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-4.015874, total=   0.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.381480, total=   1.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.251468, total=   1.3s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.3s remaining:    4.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.1s remaining:    3.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   12.4s finished
INFO:__main__:It takes 2411.54 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 31)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 27, model_id: 6f2c7641-4233-4c72-8355-aa58572fd4a8,model_name: lasso, impute_method: directly, model_selector: hard_threshold_30, eval_metric: 20.0using 4557.70 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 28, model_id: 610f02d5-16a2-4550-9f44-0cf26fa08a27,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 7.142857142857142using 4144.65 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 28, model_id: 20426fe0-a660-418f-bb3b-505b99c5663d,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 20.0using 4217.49 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-6.531186, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.279773, total=   1.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.666694, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.671849, total=   6.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.292066, total=   7.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-6.863598, total=   7.3s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.287240, total=  12.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-6.841485, total=   4.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.7s remaining:    5.8s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.0s remaining:    4.0s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   13.5s finished
INFO:__main__:It takes 2274.01 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 29, model_id: 4733ec07-f067-426a-b77c-aa411ed088f6,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 30.434782608695656using 4072.79 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 28, model_id: bd108776-f021-4c21-94c0-11a16e537e4e,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 10.0using 4121.06 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 28, model_id: 738a6d45-803b-4461-8162-7250b3915d88,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 20.0using 4360.28 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.177874, total=   3.6s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.888963, total=   4.0s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.704110, total=   4.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-1.266356, total=   4.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.111215, total=   4.4s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.868808, total=   4.8s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.116900, total=   4.8s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.078901, total=   5.2s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.230622, total=   5.8s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.862551, total=   6.2s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.937603, total=   6.3s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.939565, total=   7.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.132931, total=  18.1s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-1.616615, total=  18.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.0s remaining:   26.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.3s remaining:    4.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   18.4s finished
INFO:__main__:It takes 2032.27 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 41), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-6.144269, total=   1.4s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-6.596659, total=   3.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.503862, total=   1.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.272074, total=   7.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.524218, total=   5.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.262248, total=   1.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-6.736137, total=   8.3s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.6s remaining:    5.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.0s remaining:    4.0s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   12.9s finished
INFO:__main__:It takes 2295.39 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-7.521804, total=   3.8s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.459568, total=   3.8s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.240198, total=   4.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.872527, total=   4.5s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.289202, total=   6.1s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.928578, total=   6.4s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.512780, total=   7.5s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.271406, total=   7.4s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.975296, total=   8.2s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.480010, total=   8.9s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.252194, total=   9.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-3.584348, total=   9.3s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.060659, total=  11.0s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.9s remaining:   25.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.7s remaining:    6.7s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   13.0s finished
INFO:__main__:It takes 2019.40 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.168468, total=   3.2s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.602422, total=   3.8s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.898066, total=   4.0s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.952844, total=   4.0s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.708426, total=   4.1s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-2.630692, total=   4.3s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.179193, total=   4.3s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.001765, total=   4.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.697754, total=   4.6s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.855720, total=   4.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.003914, total=   5.1s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.842894, total=   5.9s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.713347, total=   6.7s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.0s remaining:   25.8s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.6s remaining:    4.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   13.3s finished
INFO:__main__:It takes 1979.11 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.117148, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.048168, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.052857, total=   0.1s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.163608, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.161052, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.138141, total=   0.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.035077, total=   0.1s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.704959, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.050664, total=   0.1s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.070190, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.163889, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.239542, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.072890, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.890897, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.2s remaining:    1.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.4s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.7s finished
INFO:__main__:It takes 1776.08 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 28, model_id: a5210aff-04a0-469d-b264-781706f20d6b,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 6.896551724137931using 4161.68 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.514501, total=   4.5s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.281561, total=   4.7s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.691865, total=   4.8s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.963534, total=   5.3s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.524315, total=   6.0s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.154228, total=   6.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.973523, total=   6.7s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.303899, total=   6.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.543833, total=   7.0s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.035455, total=   8.5s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.239681, total=   8.5s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.609933, total=   9.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.009484, total=  10.7s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.0s remaining:   32.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.0s remaining:    6.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   19.0s finished
INFO:__main__:It takes 1762.61 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 29, model_id: c16aab8a-9c55-4415-bc11-2b5ff47ec744,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 12.5using 3740.57 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 41), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.677655, total=   5.2s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.713554, total=   5.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.003310, total=   6.1s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.074288, total=   6.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.891009, total=   6.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.850967, total=   6.9s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.505748, total=   8.1s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-3.351727, total=   8.4s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.898435, total=   9.7s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.191567, total=  11.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.434820, total=  12.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.499379, total=  12.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-3.422447, total=  13.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.262696, total=  14.1s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.239595, total=  14.2s
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    6.1s remaining:   39.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.6s remaining:    7.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.5s finished
INFO:__main__:It takes 1778.63 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 28, model_id: a2818ed9-6044-4dbb-8e1e-1298c6dbdc4c,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 24.0using 3959.29 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 29, model_id: 1c5329e6-d847-46c3-88fa-bbfd8861f741,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 3.571428571428571using 3647.33 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 29, model_id: aaeba245-88f6-4db7-b709-afcdc66cee5b,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 0.0using 3593.47 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 30, model_id: c70b42ea-789a-4727-9b8c-87ae3283271e,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 47.82608695652174using 3386.64 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.678606, total=   4.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-3.456864, total=   4.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.699555, total=   5.7s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.569062, total=   5.6s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.208941, total=   6.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.950288, total=   7.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.353761, total=   7.2s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-4.939080, total=   8.3s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.730644, total=   9.0s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.268384, total=   9.8s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.012933, total=  10.7s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.286426, total=  11.5s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-5.380203, total=  17.1s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.761726, total=  21.2s
[CV] model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.236125, total=  22.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.0s remaining:   32.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.6s remaining:    7.5s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   22.4s finished
INFO:__main__:It takes 1678.01 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-18.926867, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-1.385489, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.114878, total=   0.1s
[CV] model__alpha=1e-05 ..............................................
[CV] ............. model__alpha=1e-05, score=-78.953784, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-124.176782, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-139.707873, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-123.726270, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.138032, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............ model__alpha=0.0001, score=-64.448297, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............. model__alpha=1e-06, score=-81.153834, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.120265, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-123.735889, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............. model__alpha=1e-09, score=-81.397863, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.137328, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.3s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.7s finished
INFO:__main__:It takes 1624.54 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 29, model_id: 350b6fef-ea78-4869-a915-2162e7a94a47,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 0.0using 3386.62 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 29, model_id: 9ea09fd7-15f9-4aa0-bbef-5294bc576976,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 0.0using 3420.80 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 41), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.553405, total=   6.1s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-7.558149, total=   6.3s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.475312, total=   7.9s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.321725, total=   8.2s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-5.029929, total=   8.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.282322, total=   9.4s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.577480, total=   9.9s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-4.554184, total=  11.7s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.948605, total=  13.2s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-4.071717, total=  15.6s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.669628, total=  16.4s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.294496, total=  19.6s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.671315, total=  18.7s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.304234, total=  25.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    6.5s remaining:   42.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   11.8s remaining:   10.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   25.5s finished
INFO:__main__:It takes 1658.16 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-430.976979, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-101.929421, total=   0.0s
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-429.932421, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.289458, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-8.875453, total=   0.1s
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-282.622402, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-430.986450, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-284.706468, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.558506, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-418.986723, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.550773, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-298.656663, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.455536, total=   0.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-282.602009, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.558587, total=   0.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    1.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.3s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.0s finished
INFO:__main__:It takes 1634.16 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 41), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-279.025092, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-138.507492, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-279.041936, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-279.025164, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-138.358010, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-278.112502, total=   0.1s
[CV] model__alpha=0.001 ..............................................
[CV] ............. model__alpha=0.001, score=-50.884613, total=   0.1s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.309247, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-138.506145, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.131823, total=   0.1s
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-279.430011, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.309181, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.309246, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-137.017596, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.308524, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.2s remaining:    1.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.3s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.6s finished
INFO:__main__:It takes 1631.41 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.258358, total=   1.3s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.056332, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.060214, total=   2.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.245282, total=   4.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.060575, total=   6.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.063765, total=   5.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.255518, total=   6.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.063324, total=  11.2s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.0s remaining:    7.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    7.0s remaining:    3.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   13.0s finished
INFO:__main__:It takes 1654.87 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 29, model_id: 0fd9402e-3e2a-4e14-b32e-5d5127c93dfd,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 0.0using 3278.90 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 30, model_id: 44a0262c-0038-482f-84bc-9f3f0e8e5c86,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 25.0using 3256.91 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 41), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-4.281872, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-72.303474, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.169560, total=   0.1s
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-195.085218, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-399.674652, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-391.241863, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-337.333252, total=   0.2s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.162289, total=   0.2s
[CV] model__alpha=0.001 ..............................................
[CV] ............. model__alpha=0.001, score=-85.462170, total=   0.2s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-389.097411, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ........... model__alpha=0.0001, score=-213.416671, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.0001 .............................................
[CV] ............. model__alpha=0.0001, score=-0.407578, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.598768, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-192.908342, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.600559, total=   0.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.3s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.0s finished
INFO:__main__:It takes 1626.76 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-410.879846, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-460.386628, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-391.436476, total=   0.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.343709, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-123.992515, total=   0.0s
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-32.390640, total=   0.0s
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-460.322474, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-370.284863, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.448281, total=   0.1s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.355630, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-459.632631, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-411.190899, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.354943, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-414.507133, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.2s remaining:    1.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.3s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.6s finished
INFO:__main__:It takes 1659.89 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 29, model_id: 2d26f4f0-67a8-40d5-a78c-f751152a8f9c,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 0.0using 3286.46 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 30, model_id: 8b0cd374-0348-44b1-83a4-12818f4e3006,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 17.857142857142858using 3246.86 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 30, model_id: be17866a-2d6f-4925-9555-87f0a31a4c34,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 16.0using 3259.14 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 31, model_id: 6a4f7186-e765-4654-856d-ab505d62f355,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 39.130434782608695using 3405.15 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 41), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.5s remaining:    3.6s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    3.5s remaining:    3.1s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    4.7s finished
INFO:__main__:It takes 1794.05 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 30, model_id: 191faaf3-a725-4d39-b64e-a769336f84be,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 10.0using 3490.34 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 30, model_id: 821191c8-2660-4300-b800-55cd31e0a245,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 12.0using 3583.84 seconds
INFO:__main__:




impute_method: directly

[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.738536, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.128181, total=   1.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.105962, total=   2.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.817142, total=   3.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.126754, total=   8.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.103715, total=   6.7s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.836701, total=   8.4s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.3s remaining:    8.0s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.9s remaining:    4.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   13.8s finished
INFO:__main__:It takes 1979.69 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 41), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=0.01 ...............................................
[CV] ............. model__alpha=0.01, score=-104.544426, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-4.984770, total=   0.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.221511, total=   0.1s
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-435.459009, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-435.459621, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-234.732600, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-435.459064, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-435.840349, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-234.771750, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.703091, total=   2.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-234.736159, total=   2.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.703098, total=   2.5s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.694846, total=   2.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.703028, total=   2.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-238.686186, total=   3.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.1s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.3s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    4.0s finished
INFO:__main__:It takes 1942.09 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.570826, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-5.736730, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.286107, total=   2.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-6.577387, total=   3.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.287403, total=   9.0s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.571171, total=   5.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-6.581620, total=   8.0s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.1s remaining:    7.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.9s remaining:    4.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   14.2s finished
INFO:__main__:It takes 1971.98 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-2.067114, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.214390, total=   1.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.194980, total=   1.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-2.046340, total=   4.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.213867, total=   5.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.206178, total=   7.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-2.163659, total=   8.5s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.1s remaining:    7.5s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.0s remaining:    4.0s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   15.4s finished
INFO:__main__:It takes 2007.50 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.540194, total=   2.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.057423, total=   2.7s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.982320, total=   3.8s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.047192, total=   4.1s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.355815, total=   5.1s
[CV] model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.559580, total=   5.2s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.648770, total=   5.5s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.088647, total=   5.6s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.860951, total=   5.9s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-1.097050, total=   6.0s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.807020, total=   6.3s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.1, score=-0.829999, total=   6.8s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.081058, total=  15.5s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.374542, total=  16.3s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.058524, total=  21.6s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.9s remaining:   19.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    5.7s remaining:    5.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   21.7s finished
INFO:__main__:It takes 1914.59 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 30, model_id: 8e322bea-7b9f-4f8d-b558-3d7b3373246e,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 6.896551724137931using 3646.81 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-7.020885, total=   1.0s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.650816, total=   1.4s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.297982, total=   1.6s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-7.460402, total=   4.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.686491, total=   6.1s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.295446, total=   7.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-7.369954, total=   8.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.695424, total=  12.4s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.7s remaining:    4.3s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   15.1s finished
INFO:__main__:It takes 1764.73 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 31, model_id: 6a661129-33f0-4747-904e-a94b0defeba3,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 29.166666666666668using 3716.27 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 51), y: (1509,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-3.708893, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.251192, total=   2.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.401122, total=   1.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-3.857498, total=   4.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.380983, total=   6.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.246023, total=   8.1s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-4.233269, total=   8.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.379795, total=  12.0s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.245790, total=  13.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.2s remaining:    7.7s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.7s remaining:    4.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   14.6s finished
INFO:__main__:It takes 1767.27 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 41)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 30, model_id: fc2fa1b3-0958-482f-8298-a31350dc678e,model_name: lasso, impute_method: directly, model_selector: hard_threshold_40, eval_metric: 20.0using 3633.83 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 31, model_id: 8ffa06d8-d3eb-462c-8153-ca8108de5e93,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 14.285714285714285using 3651.46 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 31, model_id: 812bac78-1e68-46c6-8004-ec18550a282a,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 12.0using 3701.18 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 32, model_id: 1e0d911f-1115-4205-9a46-a4f7f0c5b075,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 17.391304347826086using 3536.25 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-6.487288, total=   0.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.684221, total=   1.5s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.285075, total=   1.8s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-6.809357, total=   3.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.294675, total=   8.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.669453, total=   8.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.289513, total=  12.5s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.657851, total=   9.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-6.814068, total=   8.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.8s remaining:    6.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    9.0s remaining:    4.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   13.2s finished
INFO:__main__:It takes 1685.37 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 31, model_id: 0d3c3918-3a73-4dd9-83a9-af74b27fbac7,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 6.666666666666667using 3402.15 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 31, model_id: 19e977fa-62a0-4ed2-91ae-f879ce24eb55,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 16.0using 3393.96 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.204077, total=   6.2s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.408026, total=   6.4s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.204077, total=   6.4s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.876368, total=   6.6s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.113678, total=   7.5s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.941286, total=   7.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.876368, total=   8.0s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.941286, total=   8.1s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-1.774979, total=   9.0s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.870235, total=   9.2s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.947797, total=  10.3s
[CV] model__subsample=0.6, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.119364, total=  11.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    6.5s remaining:   42.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.3s remaining:    7.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   19.7s finished
INFO:__main__:It takes 1719.80 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 51), y: (1508,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-5.958338, total=   1.2s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.544533, total=   1.6s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.254947, total=   1.9s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-6.536317, total=   3.7s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.527350, total=   6.2s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.265528, total=   8.2s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-6.642059, total=   8.8s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    2.0s remaining:    6.8s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    8.7s remaining:    4.4s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   14.4s finished
INFO:__main__:It takes 1662.67 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.228515, total=   3.3s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.565024, total=   3.6s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.865854, total=   4.5s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.299729, total=   6.6s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.509824, total=   7.0s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-5.060637, total=   7.3s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.802720, total=   7.8s
[CV] model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.9, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-5.263183, total=   8.2s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-2.627574, total=   9.2s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.707568, total=   9.8s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.941629, total=  10.4s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.149810, total=  10.5s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.251716, total=  10.6s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    3.7s remaining:   24.1s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.4s remaining:    7.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   18.6s finished
INFO:__main__:It takes 1696.06 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.753598, total=   5.5s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-2.342201, total=   5.6s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.256378, total=   6.2s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-2.148566, total=   6.3s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.657057, total=   7.1s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.376332, total=   7.2s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.851888, total=   7.3s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.187324, total=   7.9s
[CV] model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.6, model__min_child_weight=8, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.039837, total=   8.0s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.878408, total=   8.2s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.203939, total=   8.8s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-2.635152, total=   9.3s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.1, score=-0.193707, total=  12.6s
[CV] model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=8, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.066884, total=  10.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.8s remaining:   37.5s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.2s remaining:    7.2s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   15.0s finished
INFO:__main__:It takes 1722.59 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.145946, total=   2.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-1.268881, total=   2.8s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.230469, total=   2.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.458914, total=   2.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.445603, total=   2.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.052857, total=   2.9s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.144790, total=   2.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.052699, total=   2.8s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.054252, total=   2.7s
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-1.262944, total=   2.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.338927, total=   2.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.146267, total=   2.9s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.146074, total=   2.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.088598, total=   2.8s
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-1.268288, total=   3.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    2.9s remaining:   18.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    3.0s remaining:    2.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    3.1s finished
INFO:__main__:It takes 1683.75 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (29, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 31, model_id: 0189db17-e1b5-41a8-853c-b9a9ffae5bb4,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 6.896551724137931using 3350.01 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.217046, total=   4.0s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-5.619254, total=   4.2s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-5.034364, total=   4.5s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.547598, total=   4.5s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.619915, total=   4.9s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.213118, total=   4.9s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.598387, total=   7.3s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.002946, total=   7.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.244355, total=   8.8s
[CV] model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.219460, total=   9.2s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-5.265469, total=   9.4s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.749551, total=  12.5s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-4.670261, total=  15.1s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.5, score=-0.591641, total=  24.4s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.5s remaining:   29.0s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    7.5s remaining:    6.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   33.5s finished
INFO:__main__:It takes 1824.06 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1509, 51), y: (1509,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.539571, total=   6.0s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.910188, total=   6.9s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-4.463589, total=   6.9s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.530208, total=   7.1s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.403606, total=   7.0s
[CV] model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=8, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.220619, total=   7.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.510254, total=   7.9s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-0.882848, total=   8.2s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-0.929304, total=   9.2s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.201327, total=   9.5s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.2, score=-1.108876, total=  10.5s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.384210, total=  11.4s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=10, model__learning_rate=0.01, model__colsample_bytree=0.3, score=-1.193121, total=  13.9s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-3.163902, total=  12.1s
[CV] model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.7, model__min_child_weight=6, model__max_depth=8, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.246631, total=  14.5s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    7.0s remaining:   45.3s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    8.5s remaining:    7.4s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.7s finished
INFO:__main__:It takes 1815.39 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (24, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 32, model_id: dcfa5943-f770-4e60-a924-9760fd6df92b,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 20.833333333333336using 3486.36 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 31, model_id: 45fc81f1-6eeb-46e2-8033-ef85d1ec4a52,model_name: random_forest, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 20.0using 3445.88 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_test: (28, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 32, model_id: 93c5395a-5b70-4589-bdc1-2189cb2824a1,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 3.571428571428571using 3447.23 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 32, model_id: 76b29001-cda0-4e3b-8d2a-3014e20d37c0,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 0.0using 3517.10 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (23, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 33, model_id: 75aae248-867a-4cf4-8116-a8fdb50674f2,model_name: lasso, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 47.82608695652174using 3541.93 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-3.633070, total=   5.2s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.774190, total=   5.3s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-2.824130, total=   7.5s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.214638, total=   7.6s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.680455, total=   8.5s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-0.547202, total=   8.3s
[CV] model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.8, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.232242, total=   9.3s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.026263, total=   9.2s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-3.753231, total=   9.6s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=8, model__learning_rate=0.01, model__colsample_bytree=0.5, score=-1.354742, total=  10.8s
[CV] model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.9, model__min_child_weight=2, model__max_depth=6, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.276696, total=  13.4s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=10, model__learning_rate=0.1, model__colsample_bytree=0.4, score=-0.246595, total=  20.3s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    5.6s remaining:   36.2s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    9.5s remaining:    8.3s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   27.1s finished
INFO:__main__:It takes 2048.41 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (25, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 32, model_id: ad1ef41b-ae83-43b0-8146-c50791c8c6a7,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 0.0using 3734.17 seconds
INFO:__main__:




impute_method: directly

INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_test: (30, 51)
train_test_utils.py:190: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  X_copy['predict_y'] = y_predict
INFO:__main__:Model 32, model_id: 42c2a45d-a728-42a3-ba7e-0aaad7dafb09,model_name: xgboost, impute_method: directly, model_selector: hard_threshold_50, eval_metric: 0.0using 3835.67 seconds
INFO:__main__:




impute_method: directly

/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-103.267386, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-101.365245, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............. model__alpha=1e-07, score=-41.790993, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.145887, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.145859, total=   1.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.114878, total=   1.9s
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-101.345639, total=   1.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.142929, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............. model__alpha=1e-09, score=-41.794790, total=   1.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............. model__alpha=0.001, score=-17.754804, total=   1.9s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-1.385489, total=   1.9s
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-18.926867, total=   1.9s
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-147.201759, total=   2.1s
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.101481, total=   2.2s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.6s remaining:    3.7s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    2.1s remaining:    1.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.3s finished
INFO:__main__:It takes 1932.72 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1508, 51), y: (1508,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-3.524731, total=   3.8s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.794744, total=   3.7s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.504311, total=   3.8s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.121564, total=   4.1s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-6.811257, total=   4.1s
[CV] model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=2, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-1.121564, total=   3.9s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.497318, total=   4.3s
[CV] model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4 
[CV]  model__subsample=0.6, model__min_child_weight=4, model__max_depth=2, model__learning_rate=0.01, model__colsample_bytree=0.4, score=-0.794360, total=   4.3s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.231392, total=   4.4s
[CV] model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3 
[CV]  model__subsample=0.8, model__min_child_weight=6, model__max_depth=2, model__learning_rate=0.1, model__colsample_bytree=0.3, score=-0.381331, total=   4.5s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.535001, total=   4.8s
[CV] model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2 
[CV]  model__subsample=0.7, model__min_child_weight=4, model__max_depth=4, model__learning_rate=0.1, model__colsample_bytree=0.2, score=-0.235134, total=   8.8s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    4.1s remaining:   26.4s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    4.4s remaining:    3.9s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   12.7s finished
INFO:__main__:It takes 1959.46 seconds to train this model.
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
INFO:__main__:X_train: (1505, 51), y: (1505,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-324.201192, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-324.201671, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-324.254163, total=   0.3s
[CV] model__alpha=1e-09 ..............................................
[CV] ............ model__alpha=1e-09, score=-233.415984, total=   0.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] ............ model__alpha=1e-06, score=-233.723470, total=   0.3s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.514057, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-90.210236, total=   1.7s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-7.865427, total=   1.7s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.291509, total=   1.7s
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-233.446577, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] .............. model__alpha=1e-07, score=-0.513992, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-06 ..............................................
[CV] .............. model__alpha=1e-06, score=-0.513237, total=   1.2s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-07 ..............................................
[CV] ............ model__alpha=1e-07, score=-324.206459, total=   1.7s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.514051, total=   1.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-233.418766, total=   1.8s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.6s remaining:    3.9s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.8s remaining:    1.6s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.9s finished
INFO:__main__:It takes 1931.23 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 51), y: (1510,)
Fitting 3 folds for each of 5 candidates, totalling 15 fits
[CV] model__alpha=1e-05 ..............................................
[CV] ............. model__alpha=1e-05, score=-76.621080, total=   0.3s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-0.134028, total=   0.1s
[CV] model__alpha=1e-08 ..............................................
[CV] ............ model__alpha=1e-08, score=-197.209981, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-08 ..............................................
[CV] ............. model__alpha=1e-08, score=-74.848367, total=   0.1s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] .............. model__alpha=1e-05, score=-0.304057, total=   0.6s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-05 ..............................................
[CV] ............ model__alpha=1e-05, score=-199.807461, total=   1.0s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=1e-09 ..............................................
[CV] ............. model__alpha=1e-09, score=-74.846807, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.01 ...............................................
[CV] .............. model__alpha=0.01, score=-33.563628, total=   0.8s
[CV] model__alpha=1e-09 ..............................................
[CV] .............. model__alpha=1e-09, score=-0.310194, total=   0.9s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] ............. model__alpha=0.001, score=-46.125230, total=   1.0s
[CV] model__alpha=1e-08 ..............................................
[CV] .............. model__alpha=1e-08, score=-0.310190, total=   0.4s
/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
[CV] model__alpha=0.001 ..............................................
[CV] .............. model__alpha=0.001, score=-0.131883, total=   1.1s
[CV] model__alpha=0.01 ...............................................
[CV] ............... model__alpha=0.01, score=-2.498574, total=   0.8s
[CV] model__alpha=0.001 ..............................................
[CV] ............ model__alpha=0.001, score=-266.497872, total=   1.1s
[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:    0.6s remaining:    3.8s
[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    1.2s remaining:    1.0s
[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.3s finished
INFO:__main__:It takes 1979.90 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
/opt/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1574: RuntimeWarning: invalid value encountered in greater
  return (S > tol).sum(axis=-1)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide
  return self.params / self.bse
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less
  return (self.a < x) & (x < self.b)
/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 & (x <= self.a)
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars
  return np.sqrt(eigvals[0]/eigvals[-1])
/opt/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1396: RuntimeWarning: divide by zero encountered in double_scalars
  return self.ess/self.df_model
INFO:__main__:X_train: (1510, 101), y: (1510,)
Fitting 3 folds for each of 3 candidates, totalling 9 fits
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.413441, total=   3.9s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.050276, total=   6.1s
[CV] model__n_estimators=100 .........................................
[CV] ......... model__n_estimators=100, score=-0.057603, total=   5.8s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.447887, total=  15.9s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.062746, total=  12.5s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.056485, total=  12.3s
[CV] model__n_estimators=500 .........................................
[CV] ......... model__n_estimators=500, score=-0.441730, total=  12.4s
[CV] model__n_estimators=1000 ........................................
[CV] ........ model__n_estimators=1000, score=-0.055856, total=  13.4s
[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    8.4s remaining:   29.2s
[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:   13.1s remaining:    6.5s
[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   16.5s finished
INFO:__main__:It takes 2014.17 seconds to train this model.
INFO:feature_selecting.hard_thresholding:There are in total 1148 columns, while we only need 20 columns
